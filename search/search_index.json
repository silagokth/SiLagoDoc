{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SiLago Documentation Abstract This website hosts the all the documentation of SiLago project. Repos Fabric Repo Vesyla Repo Tool Chain Vesyla tutorial Vesyla programming guide","title":"Home"},{"location":"#welcome-to-silago-documentation","text":"Abstract This website hosts the all the documentation of SiLago project.","title":"Welcome to SiLago Documentation"},{"location":"#repos","text":"Fabric Repo Vesyla Repo","title":"Repos"},{"location":"#tool-chain","text":"Vesyla tutorial Vesyla programming guide","title":"Tool Chain"},{"location":"About/About/","text":"About Contributors Yu Yang : yuyang2@kth.se Dimitrios Stathis : stathis@kth.se","title":"About"},{"location":"About/About/#about","text":"","title":"About"},{"location":"About/About/#contributors","text":"Yu Yang : yuyang2@kth.se Dimitrios Stathis : stathis@kth.se","title":"Contributors"},{"location":"About/License/","text":"License This documentation is licensed under GNU Free Documentation License . A full legal document is listed below. You can also check the license contents from the official website: https://www.gnu.org/licenses/fdl.html GNU Free Documentation License Version 1.3, 3 November 2008 Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc. <https://fsf.org/> Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. 0. PREAMBLE The purpose of this License is to make a manual, textbook, or other functional and useful document \"free\" in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others. This License is a kind of \"copyleft\", which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software. We have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference. 1. APPLICABILITY AND DEFINITIONS This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The \"Document\", below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as \"you\". You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law. A \"Modified Version\" of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language. A \"Secondary Section\" is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document's overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them. The \"Invariant Sections\" are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none. The \"Cover Texts\" are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words. A \"Transparent\" copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not \"Transparent\" is called \"Opaque\". Examples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only. The \"Title Page\" means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, \"Title Page\" means the text near the most prominent appearance of the work's title, preceding the beginning of the body of the text. The \"publisher\" means any person or entity that distributes copies of the Document to the public. A section \"Entitled XYZ\" means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as \"Acknowledgements\", \"Dedications\", \"Endorsements\", or \"History\".) To \"Preserve the Title\" of such a section when you modify the Document means that it remains a section \"Entitled XYZ\" according to this definition. The Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License. 2. VERBATIM COPYING You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3. You may also lend copies, under the same conditions stated above, and you may publicly display copies. 3. COPYING IN QUANTITY If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document's license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects. If the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages. If you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public. It is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document. 4. MODIFICATIONS You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version: A. Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission. B. List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement. C. State on the Title page the name of the publisher of the Modified Version, as the publisher. D. Preserve all the copyright notices of the Document. E. Add an appropriate copyright notice for your modifications adjacent to the other copyright notices. F. Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below. G. Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document's license notice. H. Include an unaltered copy of this License. I. Preserve the section Entitled \"History\", Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled \"History\" in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence. J. Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the \"History\" section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission. K. For any section Entitled \"Acknowledgements\" or \"Dedications\", Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein. L. Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles. M. Delete any section Entitled \"Endorsements\". Such a section may not be included in the Modified Version. N. Do not retitle any existing section to be Entitled \"Endorsements\" or to conflict in title with any Invariant Section. O. Preserve any Warranty Disclaimers. If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version's license notice. These titles must be distinct from any other section titles. You may add a section Entitled \"Endorsements\", provided it contains nothing but endorsements of your Modified Version by various parties--for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard. You may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one. The author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version. 5. COMBINING DOCUMENTS You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers. The combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work. In the combination, you must combine any sections Entitled \"History\" in the various original documents, forming one section Entitled \"History\"; likewise combine any sections Entitled \"Acknowledgements\", and any sections Entitled \"Dedications\". You must delete all sections Entitled \"Endorsements\". 6. COLLECTIONS OF DOCUMENTS You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects. You may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document. 7. AGGREGATION WITH INDEPENDENT WORKS A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the copyright resulting from the compilation is not used to limit the legal rights of the compilation's users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document. If the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document's Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate. 8. TRANSLATION Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail. If a section in the Document is Entitled \"Acknowledgements\", \"Dedications\", or \"History\", the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title. 9. TERMINATION You may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your rights under this License. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a copy of some or all of the same material does not give you any rights to use it. 10. FUTURE REVISIONS OF THIS LICENSE The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See https://www.gnu.org/licenses/. Each version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can decide which future versions of this License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Document. 11. RELICENSING \"Massive Multiauthor Collaboration Site\" (or \"MMC Site\") means any World Wide Web server that publishes copyrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody can edit is an example of such a server. A \"Massive Multiauthor Collaboration\" (or \"MMC\") contained in the site means any set of copyrightable works thus published on the MMC site. \"CC-BY-SA\" means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons Corporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as future copyleft versions of that license published by that same organization. \"Incorporate\" means to publish or republish a Document, in whole or in part, as part of another Document. An MMC is \"eligible for relicensing\" if it is licensed under this License, and if all works that were first published under this License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1) had no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008. The operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any time before August 1, 2009, provided the MMC is eligible for relicensing. ADDENDUM: How to use this License for your documents To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page: Copyright (c) YEAR YOUR NAME. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled \"GNU Free Documentation License\". If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the \"with...Texts.\" line with this: with the Invariant Sections being LIST THEIR TITLES, with the Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST. If you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation. If your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.","title":"License"},{"location":"About/License/#license","text":"This documentation is licensed under GNU Free Documentation License . A full legal document is listed below. You can also check the license contents from the official website: https://www.gnu.org/licenses/fdl.html GNU Free Documentation License Version 1.3, 3 November 2008 Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc. <https://fsf.org/> Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. 0. PREAMBLE The purpose of this License is to make a manual, textbook, or other functional and useful document \"free\" in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others. This License is a kind of \"copyleft\", which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software. We have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference. 1. APPLICABILITY AND DEFINITIONS This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The \"Document\", below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as \"you\". You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law. A \"Modified Version\" of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language. A \"Secondary Section\" is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document's overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them. The \"Invariant Sections\" are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none. The \"Cover Texts\" are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words. A \"Transparent\" copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not \"Transparent\" is called \"Opaque\". Examples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only. The \"Title Page\" means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, \"Title Page\" means the text near the most prominent appearance of the work's title, preceding the beginning of the body of the text. The \"publisher\" means any person or entity that distributes copies of the Document to the public. A section \"Entitled XYZ\" means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as \"Acknowledgements\", \"Dedications\", \"Endorsements\", or \"History\".) To \"Preserve the Title\" of such a section when you modify the Document means that it remains a section \"Entitled XYZ\" according to this definition. The Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License. 2. VERBATIM COPYING You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3. You may also lend copies, under the same conditions stated above, and you may publicly display copies. 3. COPYING IN QUANTITY If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document's license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects. If the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages. If you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public. It is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document. 4. MODIFICATIONS You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version: A. Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission. B. List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement. C. State on the Title page the name of the publisher of the Modified Version, as the publisher. D. Preserve all the copyright notices of the Document. E. Add an appropriate copyright notice for your modifications adjacent to the other copyright notices. F. Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below. G. Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document's license notice. H. Include an unaltered copy of this License. I. Preserve the section Entitled \"History\", Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled \"History\" in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence. J. Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the \"History\" section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission. K. For any section Entitled \"Acknowledgements\" or \"Dedications\", Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein. L. Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles. M. Delete any section Entitled \"Endorsements\". Such a section may not be included in the Modified Version. N. Do not retitle any existing section to be Entitled \"Endorsements\" or to conflict in title with any Invariant Section. O. Preserve any Warranty Disclaimers. If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version's license notice. These titles must be distinct from any other section titles. You may add a section Entitled \"Endorsements\", provided it contains nothing but endorsements of your Modified Version by various parties--for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard. You may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one. The author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version. 5. COMBINING DOCUMENTS You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers. The combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work. In the combination, you must combine any sections Entitled \"History\" in the various original documents, forming one section Entitled \"History\"; likewise combine any sections Entitled \"Acknowledgements\", and any sections Entitled \"Dedications\". You must delete all sections Entitled \"Endorsements\". 6. COLLECTIONS OF DOCUMENTS You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects. You may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document. 7. AGGREGATION WITH INDEPENDENT WORKS A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the copyright resulting from the compilation is not used to limit the legal rights of the compilation's users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document. If the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document's Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate. 8. TRANSLATION Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail. If a section in the Document is Entitled \"Acknowledgements\", \"Dedications\", or \"History\", the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title. 9. TERMINATION You may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your rights under this License. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a copy of some or all of the same material does not give you any rights to use it. 10. FUTURE REVISIONS OF THIS LICENSE The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See https://www.gnu.org/licenses/. Each version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can decide which future versions of this License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Document. 11. RELICENSING \"Massive Multiauthor Collaboration Site\" (or \"MMC Site\") means any World Wide Web server that publishes copyrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody can edit is an example of such a server. A \"Massive Multiauthor Collaboration\" (or \"MMC\") contained in the site means any set of copyrightable works thus published on the MMC site. \"CC-BY-SA\" means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons Corporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as future copyleft versions of that license published by that same organization. \"Incorporate\" means to publish or republish a Document, in whole or in part, as part of another Document. An MMC is \"eligible for relicensing\" if it is licensed under this License, and if all works that were first published under this License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1) had no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008. The operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any time before August 1, 2009, provided the MMC is eligible for relicensing. ADDENDUM: How to use this License for your documents To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page: Copyright (c) YEAR YOUR NAME. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled \"GNU Free Documentation License\". If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the \"with...Texts.\" line with this: with the Invariant Sections being LIST THEIR TITLES, with the Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST. If you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation. If your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.","title":"License"},{"location":"Docs/Application/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Application/SiLagoDSP/Fast-Fourier-Projection/","text":"Warning Documentation is not complete!","title":"Fast Fourier Projection"},{"location":"Docs/Fabric/Overview/","text":"Overview Please check the specification of DRRA: DRRA Specification","title":"Overview"},{"location":"Docs/Fabric/Overview/#overview","text":"Please check the specification of DRRA: DRRA Specification","title":"Overview"},{"location":"Docs/Fabric/Style-guide/","text":"Style Guide VHDL Style","title":"Style Guide"},{"location":"Docs/Fabric/Style-guide/#style-guide","text":"","title":"Style Guide"},{"location":"Docs/Fabric/Style-guide/#vhdl-style","text":"","title":"VHDL Style"},{"location":"Docs/Fabric/DRRA/RACCU/","text":"Run-time Address Constraint Computing Unit Function Run-time Address Constraint Computing Unit (RACCU) is used for computing address constraint for Address Generation Unit (AGU). AGU can deal with maximum 2-level affine address function. Affine address function is a function that can be expressed by equation below: \\begin{align} y = ax+b \\end{align} \\begin{align} y = ax+b \\end{align} where a and b are constraints. 2-level affine address function can then be expressed as: \\begin{align} y = c(ax+b)+d \\end{align} \\begin{align} y = c(ax+b)+d \\end{align} where a , b , c and d are constraints. Address constraint can be immediate value or a number generated at run-time according to a given function. The resources which deal with the constraint generation is the RACCU. Specification Info Old RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints and temporary variables will be stored inside this register file. The data register is always exposed to Sequencer to read. Another register file in RACCU is used to manage the loops. The depth depends on maximum nested loop RACCU can handle, by default it's 4 . Each entry in loop management register file has 3 fields: Loop id Loop counter Loop end flag The loop id will be identify the entry location in the loop management register file. Loop counter will be initialized by the first LOOP_HEADER instruction and be changed periodically by LOOP_TAIL instruction. The comparison between the loop conter and loop bound is carried out by LOOP_HEADER instruction. If they are equal, loop end flag will be set to true and exits the loop. RACCU has a computation unit which is similar to a mini-DPU. It has 5 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_ADD_WITH_LOOP_INDEX Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Info New RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints, temporary variables and loop iterators will be stored inside this register file. The data register is always exposed to Sequencer to read. Loop iterator will be assigned from the beginning of the register file according to the order of loop while RACCU variables will be assigned from the end of register file. Once the loop iterators or the RACCU variables are not needed, they can be freed by moving the stack/heap pointer 1 position back. The assignment of register location is managed by the Vesyla compiler. RACCU has a computation unit which is similar to a mini-DPU. It has 8 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_LOG2 Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Related Instructions RACCU instruction LOOP_HEADER instruction LOOP_TAIL instruction Interface Info Old RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output loop_reg out raccu_loop_array_ty Loop register output Info New RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output","title":"Run-time Address Constraint Computing Unit"},{"location":"Docs/Fabric/DRRA/RACCU/#run-time-address-constraint-computing-unit","text":"","title":"Run-time Address Constraint Computing Unit"},{"location":"Docs/Fabric/DRRA/RACCU/#function","text":"Run-time Address Constraint Computing Unit (RACCU) is used for computing address constraint for Address Generation Unit (AGU). AGU can deal with maximum 2-level affine address function. Affine address function is a function that can be expressed by equation below: \\begin{align} y = ax+b \\end{align} \\begin{align} y = ax+b \\end{align} where a and b are constraints. 2-level affine address function can then be expressed as: \\begin{align} y = c(ax+b)+d \\end{align} \\begin{align} y = c(ax+b)+d \\end{align} where a , b , c and d are constraints. Address constraint can be immediate value or a number generated at run-time according to a given function. The resources which deal with the constraint generation is the RACCU.","title":"Function"},{"location":"Docs/Fabric/DRRA/RACCU/#specification","text":"Info Old RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints and temporary variables will be stored inside this register file. The data register is always exposed to Sequencer to read. Another register file in RACCU is used to manage the loops. The depth depends on maximum nested loop RACCU can handle, by default it's 4 . Each entry in loop management register file has 3 fields: Loop id Loop counter Loop end flag The loop id will be identify the entry location in the loop management register file. Loop counter will be initialized by the first LOOP_HEADER instruction and be changed periodically by LOOP_TAIL instruction. The comparison between the loop conter and loop bound is carried out by LOOP_HEADER instruction. If they are equal, loop end flag will be set to true and exits the loop. RACCU has a computation unit which is similar to a mini-DPU. It has 5 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_ADD_WITH_LOOP_INDEX Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Info New RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints, temporary variables and loop iterators will be stored inside this register file. The data register is always exposed to Sequencer to read. Loop iterator will be assigned from the beginning of the register file according to the order of loop while RACCU variables will be assigned from the end of register file. Once the loop iterators or the RACCU variables are not needed, they can be freed by moving the stack/heap pointer 1 position back. The assignment of register location is managed by the Vesyla compiler. RACCU has a computation unit which is similar to a mini-DPU. It has 8 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_LOG2 Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin.","title":"Specification"},{"location":"Docs/Fabric/DRRA/RACCU/#related-instructions","text":"","title":"Related Instructions"},{"location":"Docs/Fabric/DRRA/RACCU/#raccu-instruction","text":"","title":"RACCU instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#loop_header-instruction","text":"","title":"LOOP_HEADER instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#loop_tail-instruction","text":"","title":"LOOP_TAIL instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#interface","text":"Info Old RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output loop_reg out raccu_loop_array_ty Loop register output Info New RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output","title":"Interface"},{"location":"Docs/Fabric/RISCV/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/BLAS/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/BLAS/L3/gemm/","text":"GEMM Function gemm computes a matrix-matrix product with general matrices. The gemm routines compute a scalar-matrix-matrix product and add the result to a scalar-matrix product, with general matrices. The operation is defined as C \\leftarrow \\alpha *A*B + \\beta *C C \\leftarrow \\alpha *A*B + \\beta *C where: \\alpha \\alpha and \\beta \\beta are scalars, A A , B B and C C are matrices: A A is an m-by-k matrix, B B is a k-by-n matrix, C C is an m-by-n matrix. Parameters m m : The number of rows in A A and C C . k k : The number of columns in A A and the number of rows in B B . n n : The number of columns in C C . Mapping One-Column Mapping Memory Mapping m m , k k and n n are multiple of DiMArch row width (16). A A and C C stored in DiMArch in row-major fashion and B B stored in DiMArch in col-major fashion. The first 16 words in register file in DRRA cell [0,0] is reserved for elements in A A . The second half register file (16 words) is reserved for elements in B B . The first 16 words in register file in DRRA cell [1,0] is for elements in C C . The register space for A A is also used temporarily for storing \\alpha \\alpha and \\beta \\beta . One of the internal register in DRRA cell [0,0] is also used for holding \\alpha \\alpha in order to perform the axpy() function. Function Mapping Scaling Cost Metrics","title":"GEMM"},{"location":"Docs/Library/BLAS/L3/gemm/#gemm","text":"","title":"GEMM"},{"location":"Docs/Library/BLAS/L3/gemm/#function","text":"gemm computes a matrix-matrix product with general matrices. The gemm routines compute a scalar-matrix-matrix product and add the result to a scalar-matrix product, with general matrices. The operation is defined as C \\leftarrow \\alpha *A*B + \\beta *C C \\leftarrow \\alpha *A*B + \\beta *C where: \\alpha \\alpha and \\beta \\beta are scalars, A A , B B and C C are matrices: A A is an m-by-k matrix, B B is a k-by-n matrix, C C is an m-by-n matrix.","title":"Function"},{"location":"Docs/Library/BLAS/L3/gemm/#parameters","text":"m m : The number of rows in A A and C C . k k : The number of columns in A A and the number of rows in B B . n n : The number of columns in C C .","title":"Parameters"},{"location":"Docs/Library/BLAS/L3/gemm/#mapping","text":"","title":"Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#one-column-mapping","text":"","title":"One-Column Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#memory-mapping","text":"m m , k k and n n are multiple of DiMArch row width (16). A A and C C stored in DiMArch in row-major fashion and B B stored in DiMArch in col-major fashion. The first 16 words in register file in DRRA cell [0,0] is reserved for elements in A A . The second half register file (16 words) is reserved for elements in B B . The first 16 words in register file in DRRA cell [1,0] is for elements in C C . The register space for A A is also used temporarily for storing \\alpha \\alpha and \\beta \\beta . One of the internal register in DRRA cell [0,0] is also used for holding \\alpha \\alpha in order to perform the axpy() function.","title":"Memory Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#function-mapping","text":"","title":"Function Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#scaling","text":"","title":"Scaling"},{"location":"Docs/Library/BLAS/L3/gemm/#cost-metrics","text":"","title":"Cost Metrics"},{"location":"Docs/Library/FFT/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/Interleaver/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/NN/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Start/Overview/","text":"Getting start Source code Find the source code Source code organization Read and contribute to the source code Quick guide for code documentation Quick guide for naming system","title":"Getting start"},{"location":"Docs/Start/Overview/#getting-start","text":"","title":"Getting start"},{"location":"Docs/Start/Overview/#source-code","text":"","title":"Source code"},{"location":"Docs/Start/Overview/#find-the-source-code","text":"Source code organization","title":"Find the source code"},{"location":"Docs/Start/Overview/#read-and-contribute-to-the-source-code","text":"Quick guide for code documentation Quick guide for naming system","title":"Read and contribute to the source code"},{"location":"Docs/Start/Quick-guide-for-code-documentation/","text":"Warning Documentation is not complete! Quick guide for code documentation SiLago project try to use doxygen to generate reference manual for its source code. The comment is crutial for the quality of generated documentation. Therefore, we make some guidelines for commenting the source code. C++ Comment environment Use QT's commenting style to form a doxygen readable comment block. As shown in the example below. /*! * This is a block comment */ Single line comment is also allowed and should using style like this: //! This is a single line comment Comment a file Every header file should be documented with a short description about the role of this file. Additional information like author, license, modification history, etc should also be included inside the comment block. Example: /*! * \\file Global.hpp * * Defines all the global variables. * * Author: author <author@domain.com> * Licese: MIT * Modification: * 2017-01-03 author created * 2017-02-05 user1 add feature of xxx * 2017-02-07 user2 fix bug xxx */ Comment a class Every class should be documented right before its defination. Description of the function of the class is very important. Example: /*! * Description of class A */ class A : public B { .... }; Comment a method/function Method function should be documented right before its declaration. The description, parameters, return type should be included inside the comment block. Example: class A : public B { public : /*! * Constructor */ A (); /*! * Some other function * * \\param p0 some input * \\param p1 the second input * \\return the calculate result */ int func ( int p0 , int p1 ); };","title":"Quick guide for code documentation"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#quick-guide-for-code-documentation","text":"SiLago project try to use doxygen to generate reference manual for its source code. The comment is crutial for the quality of generated documentation. Therefore, we make some guidelines for commenting the source code.","title":"Quick guide for code documentation"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#c","text":"","title":"C++"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#comment-environment","text":"Use QT's commenting style to form a doxygen readable comment block. As shown in the example below. /*! * This is a block comment */ Single line comment is also allowed and should using style like this: //! This is a single line comment","title":"Comment environment"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#comment-a-file","text":"Every header file should be documented with a short description about the role of this file. Additional information like author, license, modification history, etc should also be included inside the comment block. Example: /*! * \\file Global.hpp * * Defines all the global variables. * * Author: author <author@domain.com> * Licese: MIT * Modification: * 2017-01-03 author created * 2017-02-05 user1 add feature of xxx * 2017-02-07 user2 fix bug xxx */","title":"Comment a file"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#comment-a-class","text":"Every class should be documented right before its defination. Description of the function of the class is very important. Example: /*! * Description of class A */ class A : public B { .... };","title":"Comment a class"},{"location":"Docs/Start/Quick-guide-for-code-documentation/#comment-a-methodfunction","text":"Method function should be documented right before its declaration. The description, parameters, return type should be included inside the comment block. Example: class A : public B { public : /*! * Constructor */ A (); /*! * Some other function * * \\param p0 some input * \\param p1 the second input * \\return the calculate result */ int func ( int p0 , int p1 ); };","title":"Comment a method/function"},{"location":"Docs/Start/Quick-guide-for-naming-system/","text":"Warning Documentation is not complete!","title":"Quick guide for naming system"},{"location":"Docs/Start/Source-code-organization/","text":"Warning Documentation is not complete!","title":"Source code organization"},{"location":"Docs/ToolChain/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/ToolChain/Sylva/Overview/","text":"Sylva New version of Sylva documentation: Sylva documentation","title":"Sylva"},{"location":"Docs/ToolChain/Sylva/Overview/#sylva","text":"New version of Sylva documentation: Sylva documentation","title":"Sylva"},{"location":"Docs/ToolChain/Vesyla/Cadfg/","text":"CADFG - Control Address Data-Flow Graph CADFG is a DAG(directed acyclic graph)-based data structure used as an intermediate representation (IR) by Vesyla. Conventional High-level synthesis (HLS) tools typically model high-level program as control and dataflow graph (CDFG) as the intermediate representation (IR). This representation was appropriate because HLS tools synthesize an FSMD (FSM+Datapath) as the target architecture, deal with scalars and do not differentiate between functional, address and address constraints computation. Vesyla-II, in contrast generates distributed two-level FSM control scheme, deals with vectors and differentiates between the three categories of computation. These differences are reflected in the the IR used by Vesyla-II called Control, Address and Dataflow Graph (CADFG). CADFG is derived from the abstract syntax tree (AST). By a series of refinement, it transforms to Instruction Dependent Graph (IDG) as the back-end IR. In this section, we focus on elaborating some of the critical vertices of CADFG. Vertices There are several broad categories of vertices in CADFG: Source and Sink vertices : create and terminate data flow. Read and Write vertices : slice vector to scalar and pack scalar to vector. Address and Address Constraint vertices : generates the address sequence for slicing and packing and address constraints. Function vertex : does general data computation. Control vertices : handle branches and loops. Source and Sink Vertices Source vertices doesn't have any input port and sink vertices doesn't have any output port. Both types of vertices support both vector and scalar data type. In figure ??, p1 to p5 and X are all source vertices, while y is sink vertex. Read and Write Vertices Read vertex slices the vector variable to its each individual element and sending out them one at a time. On the contrary, write vertex packs the time distributed scalar data sequence to vector variable. Both vertices need an address vertex attach to them in order to decide the address sequence. In figure ??, vertex R is an example of read vertex. Address and Address Constraint Vertices Address and Address Constraint Vertices are the key differentiator compared to conventional CDFGs. These vertices embody the policy of differentiating address and address constraints as separate computation category and mapping them to dedicated spatially distributed resources. This manifests in the read vertex getting its addresses from a function that models the address computation as a two-level affine function with five operands as shown and explained with an example in Figure ??. An implication of such an address function is that read vertex does not read a scalar but a vector. The address constraints are also explicitly identified to enable their computation to be also mapped to custom spatially distributed computation resource. In following figure, vertex A is an address vertex. When Vesyla encounters higher order address functions beyond two levels affine function, it repeatedly computes the constraints of the inner two-level loops in a pipelined fashion. Computation in pipelined fashion deserves some explanation. Let us call one instance of innermost two loops as an epoch. While the functional computation and address computation of the innermost two loops are working on epoch i, the address constraints for the next epoch, i+1, are computed in parallel on an independent machine as shown in the following figure. Function Vertex Function vertices are responsible for the actual computation on input data. They are usually bind to arithmetic units inside DRRA cells. Function vertices only accept scalar inputs and generate scalar outputs. That's why we have the read and write nodes to break down the vector variables. Function vertex can be chained together to form more complex arithmetic operation. Control Vertex Control vertices model the control hierarchy and in this respective they are similar to the control vertices in typical CDFGs. These vertices model the main algorithmic level control and not the control for fine grained address and address constraints computation. In CADFG, we do not have explicit control edges to model control dependencies. This is implicitly represented by the hierarchy of the control blocks. All nodes inside a control block are implicitly triggered if the control condition and the data dependency condition of the control block is fulfilled. When an algorithm is parallelized, parts of control hierarchy are replicated to represent the parallelism. Loops in Vesyla are not dynamic, they are either compile time or parametrically static. The latter implies that once the parameter for the loop bounds and increment are decided, these parameters remain static until the loop is complete. The dedicated resources for address constraints computation also serve to manage the loop parameters or constraints. For this reason, CADFG loop vertices are composite, i.e., they do not have any separate datapath vertex for loop condition comparison. Typical HLS tools, on the other hand, instantiate comparators and incrementors/adders to implement loop control verteices. Control Vertices include branch vertex, loop vertex, merge vertex, etc. Edges There are two broad categories of edges in CADFG: Dataflow edge : represents the flow of data, either scalar or vector. Dependency edge : represents the dependency relation between the predicessor and successor. Dataflow Edge Like in conventional CDFG, dataflow edge shows the flow of data. It's a directed edge with predicessor and successor. Data flows from predicessor to successor. Dataflow edge can be either scalar or vector. Dataflow edge automatically embeds the information of dependency. The successor cannot be scheduled earlier than the predicessor. Dependency Edge Dependency edge is a more sophiscated way to describe dependencies among vertices. Vesyla uses dependency edges because in order to solve some hazzards such as \"WAR\" and \"WAW\", extra dependency information is needed and these information can't be provided by normal dataflow edges. A dependency edge is also a directed edge. A timing period is associated with each dependency edge to indicate that the successor should start after the predicessor after some time t t and t t should be bounded by the timing period associated with the dependency edge. Each terminal of the edge also has a property indicating the moment the dependency edge will start to apply. The property can be PROCESS BEGIN or PROCESS END . Thus, a dependency edge a \\rightarrow{} b a \\rightarrow{} b can express 4 different types of dependencies. b b starts after a a starts. b b starts after a a ends. b b ends after a a starts. b b ends after a a ends. Example Lines 1 to 4 are the symbolic parameters that control the dimension of the algorithm and also the allocation and binding. These parameters influence the dimension of the CADFG. For instance, the parameter Col decides the degree of parallelism. The CADFG shown in figure corresponds to Col=1 case. If Col > 1, Vesyla would replicate the CADFG Col times to represent the parallelism. Lines 5 to 8 define the allocation and binding for the storage. This information is stored as attributes in the source and destination nodes of the read/write nodes in the CADFG. Lines 9 to 16 decide the dimension and structure of the CADFG. The control hierarchy is represented by hierarchy of control blocks that serves as containers. In CADFG, there are no explicit control arcs but being inside a control block implies having a control arc from the parent control block. Line 9 refers to spatial iteration, i.e., parallelism and as stated above, decides the number of replications of CADFG. Line 10 is the highest control node that will be executed in each thread; CADFG in figure has a single thread with Col=1. Inside this control block, there are three sub-control blocks, each representing a vector operation on lines 11, 12 and 14. Two of these control blocks enclose read nodes and one write node. Besides these three read/write nodes, there is a functional computation node to represent the functionality on line 13. The read/write nodes that model the vector movement in lines 11, 12 and 14 all have the address and address constraints computation nodes for both LHS and RHS. Potentially, all three nodes could involve three sets of spatially distributed FSMs for address and address computations. Later, factoring in the allocation, binding and the data dependenncies, Vesyla synthesizes strucutures and details for scheduling and synchronizing these FSMs, some of them could be mapped to the same FSM. A simplification process in Vesyla transforms the symbolic expressions in Matlab to numerical values for loop and address constraints. A boxed note in figure explains one such example for address constraints for LHS of line 11. In the example under consideration, there is only one functional computation node on line 13 and as can be seen its inputs and outputs are also vectorizing read/write nodes. Also, the functional computational node is also associated with an allocation and binding pragmas that is duly recorded as part of building the CADFG. While building the CADFG, Vesyla, like other HLS tools also creates explicit data dependencies that crosses control block boundaries. Vesyla also detect hazards and records them with additional dependency arcs. This is explained next.","title":"CADFG - Control Address Data-Flow Graph"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#cadfg-control-address-data-flow-graph","text":"CADFG is a DAG(directed acyclic graph)-based data structure used as an intermediate representation (IR) by Vesyla. Conventional High-level synthesis (HLS) tools typically model high-level program as control and dataflow graph (CDFG) as the intermediate representation (IR). This representation was appropriate because HLS tools synthesize an FSMD (FSM+Datapath) as the target architecture, deal with scalars and do not differentiate between functional, address and address constraints computation. Vesyla-II, in contrast generates distributed two-level FSM control scheme, deals with vectors and differentiates between the three categories of computation. These differences are reflected in the the IR used by Vesyla-II called Control, Address and Dataflow Graph (CADFG). CADFG is derived from the abstract syntax tree (AST). By a series of refinement, it transforms to Instruction Dependent Graph (IDG) as the back-end IR. In this section, we focus on elaborating some of the critical vertices of CADFG.","title":"CADFG - Control Address Data-Flow Graph"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#vertices","text":"There are several broad categories of vertices in CADFG: Source and Sink vertices : create and terminate data flow. Read and Write vertices : slice vector to scalar and pack scalar to vector. Address and Address Constraint vertices : generates the address sequence for slicing and packing and address constraints. Function vertex : does general data computation. Control vertices : handle branches and loops.","title":"Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#source-and-sink-vertices","text":"Source vertices doesn't have any input port and sink vertices doesn't have any output port. Both types of vertices support both vector and scalar data type. In figure ??, p1 to p5 and X are all source vertices, while y is sink vertex.","title":"Source and Sink Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#read-and-write-vertices","text":"Read vertex slices the vector variable to its each individual element and sending out them one at a time. On the contrary, write vertex packs the time distributed scalar data sequence to vector variable. Both vertices need an address vertex attach to them in order to decide the address sequence. In figure ??, vertex R is an example of read vertex.","title":"Read and Write Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#address-and-address-constraint-vertices","text":"Address and Address Constraint Vertices are the key differentiator compared to conventional CDFGs. These vertices embody the policy of differentiating address and address constraints as separate computation category and mapping them to dedicated spatially distributed resources. This manifests in the read vertex getting its addresses from a function that models the address computation as a two-level affine function with five operands as shown and explained with an example in Figure ??. An implication of such an address function is that read vertex does not read a scalar but a vector. The address constraints are also explicitly identified to enable their computation to be also mapped to custom spatially distributed computation resource. In following figure, vertex A is an address vertex. When Vesyla encounters higher order address functions beyond two levels affine function, it repeatedly computes the constraints of the inner two-level loops in a pipelined fashion. Computation in pipelined fashion deserves some explanation. Let us call one instance of innermost two loops as an epoch. While the functional computation and address computation of the innermost two loops are working on epoch i, the address constraints for the next epoch, i+1, are computed in parallel on an independent machine as shown in the following figure.","title":"Address and Address Constraint Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#function-vertex","text":"Function vertices are responsible for the actual computation on input data. They are usually bind to arithmetic units inside DRRA cells. Function vertices only accept scalar inputs and generate scalar outputs. That's why we have the read and write nodes to break down the vector variables. Function vertex can be chained together to form more complex arithmetic operation.","title":"Function Vertex"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#control-vertex","text":"Control vertices model the control hierarchy and in this respective they are similar to the control vertices in typical CDFGs. These vertices model the main algorithmic level control and not the control for fine grained address and address constraints computation. In CADFG, we do not have explicit control edges to model control dependencies. This is implicitly represented by the hierarchy of the control blocks. All nodes inside a control block are implicitly triggered if the control condition and the data dependency condition of the control block is fulfilled. When an algorithm is parallelized, parts of control hierarchy are replicated to represent the parallelism. Loops in Vesyla are not dynamic, they are either compile time or parametrically static. The latter implies that once the parameter for the loop bounds and increment are decided, these parameters remain static until the loop is complete. The dedicated resources for address constraints computation also serve to manage the loop parameters or constraints. For this reason, CADFG loop vertices are composite, i.e., they do not have any separate datapath vertex for loop condition comparison. Typical HLS tools, on the other hand, instantiate comparators and incrementors/adders to implement loop control verteices. Control Vertices include branch vertex, loop vertex, merge vertex, etc.","title":"Control Vertex"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#edges","text":"There are two broad categories of edges in CADFG: Dataflow edge : represents the flow of data, either scalar or vector. Dependency edge : represents the dependency relation between the predicessor and successor.","title":"Edges"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#dataflow-edge","text":"Like in conventional CDFG, dataflow edge shows the flow of data. It's a directed edge with predicessor and successor. Data flows from predicessor to successor. Dataflow edge can be either scalar or vector. Dataflow edge automatically embeds the information of dependency. The successor cannot be scheduled earlier than the predicessor.","title":"Dataflow Edge"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#dependency-edge","text":"Dependency edge is a more sophiscated way to describe dependencies among vertices. Vesyla uses dependency edges because in order to solve some hazzards such as \"WAR\" and \"WAW\", extra dependency information is needed and these information can't be provided by normal dataflow edges. A dependency edge is also a directed edge. A timing period is associated with each dependency edge to indicate that the successor should start after the predicessor after some time t t and t t should be bounded by the timing period associated with the dependency edge. Each terminal of the edge also has a property indicating the moment the dependency edge will start to apply. The property can be PROCESS BEGIN or PROCESS END . Thus, a dependency edge a \\rightarrow{} b a \\rightarrow{} b can express 4 different types of dependencies. b b starts after a a starts. b b starts after a a ends. b b ends after a a starts. b b ends after a a ends.","title":"Dependency Edge"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#example","text":"Lines 1 to 4 are the symbolic parameters that control the dimension of the algorithm and also the allocation and binding. These parameters influence the dimension of the CADFG. For instance, the parameter Col decides the degree of parallelism. The CADFG shown in figure corresponds to Col=1 case. If Col > 1, Vesyla would replicate the CADFG Col times to represent the parallelism. Lines 5 to 8 define the allocation and binding for the storage. This information is stored as attributes in the source and destination nodes of the read/write nodes in the CADFG. Lines 9 to 16 decide the dimension and structure of the CADFG. The control hierarchy is represented by hierarchy of control blocks that serves as containers. In CADFG, there are no explicit control arcs but being inside a control block implies having a control arc from the parent control block. Line 9 refers to spatial iteration, i.e., parallelism and as stated above, decides the number of replications of CADFG. Line 10 is the highest control node that will be executed in each thread; CADFG in figure has a single thread with Col=1. Inside this control block, there are three sub-control blocks, each representing a vector operation on lines 11, 12 and 14. Two of these control blocks enclose read nodes and one write node. Besides these three read/write nodes, there is a functional computation node to represent the functionality on line 13. The read/write nodes that model the vector movement in lines 11, 12 and 14 all have the address and address constraints computation nodes for both LHS and RHS. Potentially, all three nodes could involve three sets of spatially distributed FSMs for address and address computations. Later, factoring in the allocation, binding and the data dependenncies, Vesyla synthesizes strucutures and details for scheduling and synchronizing these FSMs, some of them could be mapped to the same FSM. A simplification process in Vesyla transforms the symbolic expressions in Matlab to numerical values for loop and address constraints. A boxed note in figure explains one such example for address constraints for LHS of line 11. In the example under consideration, there is only one functional computation node on line 13 and as can be seen its inputs and outputs are also vectorizing read/write nodes. Also, the functional computational node is also associated with an allocation and binding pragmas that is duly recorded as part of building the CADFG. While building the CADFG, Vesyla, like other HLS tools also creates explicit data dependencies that crosses control block boundaries. Vesyla also detect hazards and records them with additional dependency arcs. This is explained next.","title":"Example"},{"location":"Docs/ToolChain/Vesyla/DeadCodeElimination/","text":"","title":"DeadCodeElimination"},{"location":"Docs/ToolChain/Vesyla/DependencyAnalysis/","text":"Dependency Analysis Dependencies created in CADFG don't take the address range of vector variable read/write operations into account. To add such information and fine tune the dependencies, we need to have this dependency analysis process. Here, dependency analysis only refers to the dependency checking for vector operations. Data dependencies between vector variables are more complex than scalar variables because it not only involves the variables but also their read and write access patterns. There are many sophisticated techniques to analyse dependencies among vector operations. Many great works have been done in this research field. However, Vesyla, as a proof-of-concept tool, doesn\u2019t explore all those advanced methods for optimization purpose. It broadly categorizes data dependency among vector variables as strong dependency , weak dependency and fake dependency . Strong dependency requires the successor starts no earlier than the end of its predecessor. Weak dependency only requires the successor starts no earlier than the start of its predecessor. Fake dependency indicates there is no actual data hazard between predecessor and successor, the dependency edge can be removed. As shown in the following figure, If the predecessor and successor of a dependency edge has non-overlapping access patterns the dependency edge is fake because the two nodes will never access the same location. If the predecessor and successor have the same pattern or the successor has a pattern that is a simple shift of the predecessor pattern, the dependency is weak because the predecessor will always access the location before the successor, thus the successor can start one cycle later than the starting of predecessor. For all other cases, Vesyla-II considers the dependency edge strong since this is the most conservative assumption.","title":"Dependency Analysis"},{"location":"Docs/ToolChain/Vesyla/DependencyAnalysis/#dependency-analysis","text":"Dependencies created in CADFG don't take the address range of vector variable read/write operations into account. To add such information and fine tune the dependencies, we need to have this dependency analysis process. Here, dependency analysis only refers to the dependency checking for vector operations. Data dependencies between vector variables are more complex than scalar variables because it not only involves the variables but also their read and write access patterns. There are many sophisticated techniques to analyse dependencies among vector operations. Many great works have been done in this research field. However, Vesyla, as a proof-of-concept tool, doesn\u2019t explore all those advanced methods for optimization purpose. It broadly categorizes data dependency among vector variables as strong dependency , weak dependency and fake dependency . Strong dependency requires the successor starts no earlier than the end of its predecessor. Weak dependency only requires the successor starts no earlier than the start of its predecessor. Fake dependency indicates there is no actual data hazard between predecessor and successor, the dependency edge can be removed. As shown in the following figure, If the predecessor and successor of a dependency edge has non-overlapping access patterns the dependency edge is fake because the two nodes will never access the same location. If the predecessor and successor have the same pattern or the successor has a pattern that is a simple shift of the predecessor pattern, the dependency is weak because the predecessor will always access the location before the successor, thus the successor can start one cycle later than the starting of predecessor. For all other cases, Vesyla-II considers the dependency edge strong since this is the most conservative assumption.","title":"Dependency Analysis"},{"location":"Docs/ToolChain/Vesyla/DiMArch/","text":"DiMArch Reading and Writing To read from DiMArch cell or write to DiMArch cell, we need several collaborating instructions. They are ROUTE instruction, REFI instruction and SRAM_R / SRAM_W instruction. Read (DiMArch -> Register file) When reading from DiMArch to Register file, a path should be routed first by ROUTE instruction. ROUTE instruction has 2 critical timestamps: issue and end . ROUTE instruction will occupy the DiMArch NoC resource of all cells on the routed path until it's end timestamp reached. During the time when the DiMArch NoC path is guaranteed by ROUTE instruction, a SRAM_R instruction is applied to configure the AGU on DiMArch side. SRAM_R instruction has 4 critical timestamps: issue , arrive , active and end . Issue time represents the cycle when sequencer issue the instruction, arrive time represents the instruction reaches the destination DiMArch cell, active time represents the time point when the instruction starts outputing readed data, and end time indicates the instruction stops reading data. At the same time, a REFI instruction should be activated in order to store the data from DiMArch to register file entries. REFI instruction has 3 critical timestamps: issue , active and end . The timing relationship of those 3 instructions are shown in figure below: {% dot sram_read_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; sram_active -> refi_active[label=\"=#hop\"] } %} Write (Register file -> DiMArch) Writing data from Register file to DiMArch share the same set of instruction with the same timestamps as reading operation. The only difference comes from the dependency arrows. The timing relationship of those 3 instructions are shown in figure below: {% dot sram_write_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; refi_active -> sram_active[label=\"=#hop\"] } %}","title":"DiMArch Reading and Writing"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#dimarch-reading-and-writing","text":"To read from DiMArch cell or write to DiMArch cell, we need several collaborating instructions. They are ROUTE instruction, REFI instruction and SRAM_R / SRAM_W instruction.","title":"DiMArch Reading and Writing"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#read-dimarch-register-file","text":"When reading from DiMArch to Register file, a path should be routed first by ROUTE instruction. ROUTE instruction has 2 critical timestamps: issue and end . ROUTE instruction will occupy the DiMArch NoC resource of all cells on the routed path until it's end timestamp reached. During the time when the DiMArch NoC path is guaranteed by ROUTE instruction, a SRAM_R instruction is applied to configure the AGU on DiMArch side. SRAM_R instruction has 4 critical timestamps: issue , arrive , active and end . Issue time represents the cycle when sequencer issue the instruction, arrive time represents the instruction reaches the destination DiMArch cell, active time represents the time point when the instruction starts outputing readed data, and end time indicates the instruction stops reading data. At the same time, a REFI instruction should be activated in order to store the data from DiMArch to register file entries. REFI instruction has 3 critical timestamps: issue , active and end . The timing relationship of those 3 instructions are shown in figure below: {% dot sram_read_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; sram_active -> refi_active[label=\"=#hop\"] } %}","title":"Read (DiMArch -&gt; Register file)"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#write-register-file-dimarch","text":"Writing data from Register file to DiMArch share the same set of instruction with the same timestamps as reading operation. The only difference comes from the dependency arrows. The timing relationship of those 3 instructions are shown in figure below: {% dot sram_write_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; refi_active -> sram_active[label=\"=#hop\"] } %}","title":"Write (Register file -&gt; DiMArch)"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/","text":"Expression Simplification Algorithm Perserving Dependency Edges","title":"Expression Simplification"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#expression-simplification","text":"","title":"Expression Simplification"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#algorithm","text":"","title":"Algorithm"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#perserving-dependency-edges","text":"","title":"Perserving Dependency Edges"},{"location":"Docs/ToolChain/Vesyla/Hazzard/","text":"Hazard Here we only talk about data hazards. Standard Hazards A data hazard is created whenever there is a dependence between data read and/or write operations. Without such dependency information perserved by some proper format, the data access order might be different from the intended order expressed by the programmer in source code thus might lead to unintended output. The goal of harzard detection is to exploit parallesism by perserving data access order only where it affects the outcome of the program. Data hazard can be categorized as Read-After-Write (RAW), Write-After-Write (WAW) and Write-After-Read (WAR). For out-of-order issue hardware or compiler that exploits instruction execution order all three types of hazard can happen. Therefore, we need to preserve the dependency information in order to avoid those hazards. Hazards in Vector Machine and Vesyla In vesyla, the case for RAW is simple. It will be directly absorbed by the data dependency edge that is anyway created. WAR and WAW, requires creation of additional special edges to indicate that there are data dependencies. Data hazards for vector variables are different from those for scalar variables. For example, in the following figure, a WAW dependency is not necessary for scalar variables because the first \u201cWrite\u201d operation can\u2019t affect the final result of that scalar variable hence can be directly removed. While for vector variables, WAW dependency is absolutely necessary, because those two \u201cWrite\u201d operations might write to different part of the vector therefore both will influence the final result of the vector variable. Different from scalar machine, vector machine need extra information to create dependencies. Vector operations usually last for some time period. The dependencies between vector operations need to specify which timing point they are referring to. Specifically, the start and end time of a vector operation are important. Regarding just start and end time of vector operations, we can create 4 types of dependencies: Dependency between the start of predicessor and the start of successor. Dependency between the start of predicessor and the end of successor. Dependency between the end of predicessor and the start of successor. Dependency between the end of predicessor and the end of successor. Data dependency analysis technique can be found in section Dependency Analysis .","title":"Hazard"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#hazard","text":"Here we only talk about data hazards.","title":"Hazard"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#standard-hazards","text":"A data hazard is created whenever there is a dependence between data read and/or write operations. Without such dependency information perserved by some proper format, the data access order might be different from the intended order expressed by the programmer in source code thus might lead to unintended output. The goal of harzard detection is to exploit parallesism by perserving data access order only where it affects the outcome of the program. Data hazard can be categorized as Read-After-Write (RAW), Write-After-Write (WAW) and Write-After-Read (WAR). For out-of-order issue hardware or compiler that exploits instruction execution order all three types of hazard can happen. Therefore, we need to preserve the dependency information in order to avoid those hazards.","title":"Standard Hazards"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#hazards-in-vector-machine-and-vesyla","text":"In vesyla, the case for RAW is simple. It will be directly absorbed by the data dependency edge that is anyway created. WAR and WAW, requires creation of additional special edges to indicate that there are data dependencies. Data hazards for vector variables are different from those for scalar variables. For example, in the following figure, a WAW dependency is not necessary for scalar variables because the first \u201cWrite\u201d operation can\u2019t affect the final result of that scalar variable hence can be directly removed. While for vector variables, WAW dependency is absolutely necessary, because those two \u201cWrite\u201d operations might write to different part of the vector therefore both will influence the final result of the vector variable. Different from scalar machine, vector machine need extra information to create dependencies. Vector operations usually last for some time period. The dependencies between vector operations need to specify which timing point they are referring to. Specifically, the start and end time of a vector operation are important. Regarding just start and end time of vector operations, we can create 4 types of dependencies: Dependency between the start of predicessor and the start of successor. Dependency between the start of predicessor and the end of successor. Dependency between the end of predicessor and the start of successor. Dependency between the end of predicessor and the end of successor. Data dependency analysis technique can be found in section Dependency Analysis .","title":"Hazards in Vector Machine and Vesyla"},{"location":"Docs/ToolChain/Vesyla/Idg/","text":"IDG - Instruction Dependency Graph","title":"IDG - Instruction Dependency Graph"},{"location":"Docs/ToolChain/Vesyla/Idg/#idg-instruction-dependency-graph","text":"","title":"IDG - Instruction Dependency Graph"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/","text":"Instruction Set Instructions 0001 - REFI1 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 1 A A B B C D D D D D D E F F F F F F G H H H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0001 REFI1 instruction code port_no [22, 21] 2 [0, 3] Selects one of the RFile ports extra [20, 19] 2 [0, 3] How many following instructions. init_addr_sd 18 1 [0, 1] [0] init_addr is static; [1] init_addr is from RACCU. init_addr [17, 12] 6 [0, 63] Static init address or RACCU register. l1_iter_sd 11 1 [0, 1] [0] Level 1 iteration is static; [1] L1 iteration is from RACCU. l1_iter [10, 5] 6 [0, 63] Static L1 iteration or RACCU register. init_delay_sd 4 1 [0, 1] [0] init_delay is static; [1] init_delay is from RACCU. init_delay [3, 0] 4 [0, 15] Static init delay or RACCU register. 0010 - REFI2 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 1 0 A B B B B B B C D E E E E F G G G G G H H H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0010 REFI2 instruction code l1_step_sd [22] 1 [0, 1] [0] l1_step is static; [1] l1_step is from RACCU l1_step [21, 16] 6 [0, 63] Static level 1 step value or RACCU register l1_step_sign [15] 1 [0, 1] Sign bit of l1_step l1_delay_sd [14] 1 [0, 1] [0] l1_delay is static; [1] l1_delay is from RACCU l1_delay [13, 10] 4 [0, 15] Static level 1 delay or RACCU register l2_iter_sd [9] 1 [0, 1] [0] l2_iter is static; [1] l2_iter is from RACCU l2_iter [8, 4] 5 [0, 31] Static level 2 iteration or RACCU register l2_step [3, 0] 4 [0, 15] Level 2 step value 0011 - REFI3 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 1 1 A B B B B B B 0 0 0 0 0 0 C C D E E 0 0 0 F G Field Position Width Range/Value Description instr_code [26, 23] 4 b'0011 REFI3 instruction code l2_delay_sd [22] 1 [0, 1] [0] l2_delay is static; [1] l2_delay is from RACCU. l2_delay [21, 16] 6 [0, 63] Static level 2 delay or RACCU register. unused [15, 10] 6 0 Deprecated l1_delay_ext [9, 8] 2 [0, 3] Extended bits for l1_delay l2_iter_ext [7] 1 [0, 1] Extended bits for l2_iter l2_step_ext [6, 5] 2 [0, 3] Extended bits for l2_step unused [4, 2] 3 0 Deprecated dimarch [1] 1 [0, 1] [0] Not DiMArch; [1] DiMArch mode compress [0] 1 [0, 1] [0] Not compressed; [1] Compressed 0100 - DPU 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 0 A A A A A B B C C D D E F G G G G G G G G H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0100 DPU instruction code mode [22, 18] 5 [0, 12] Configures the valid dpu mode control [17, 16] 2 [0, 3] [00] no saturation, integer; [01] no saturation, fixed-point; [10] saturation, integer; [11] saturation, fixed-point. not_used [15, 10] 6 b'000010 Deprecated acc_clear [9, 2] 8 [0, 255] The DPU accumulator register clear threshold. io_change [1, 0] 2 [0, 3] [00] no change; [01]negate in1; [10] negate in2; [11] return abosolute value of output. 0101 SWB 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 1 1 A B C D D D E F F F 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 SWB instruction code active [22] 1 1 Deprecated, always 1 src_row [21] 1 [0, 1] The source DRRA row src_block [20] 1 [0, 1] [0] RF; [1] DPU src_port [19] 1 [0, 1] Source port number hb_index [18, 16] 3 [0, 6] Index of horizontal bus send_to_other_row [15] 1 [0, 1] Flag of whether src and dest row are equal v_index [14, 12] 3 [0, 5] Index of vertical bus unused [11, 0] 12 0 Deprecated 0110 JUMP 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 0 A A A A A A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 JUMP instruction code pc [22, 17] 6 [0, 63] The target address unused [16, 0] 17 0 Deprecated 0111 WAIT 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B B B B B B B B B B B B B 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0111 DELAY instruction code cycle_sd [22] 1 [0, 1] [0] cycle is static; [1] cycle is from RACCU cycle [21, 7] 15 [0, 32767] Static cycle or RACCU register unused [6, 0] 7 0 0 1000 LOOP 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A B B C C C C C C D E E E E E E F G G G G G G 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | H I I I I I I 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [53, 50] 4 b'1000 LOOPH instruction code extend [49] 1 [0, 15] 0:No extension; 1:Extended loopid [48, 47] 2 [0, 3] The id of nested loops endpc [46, 41] 6 [0, 63] The PC where loop ends start_sd [40] 1 [0, 1] 0:start is static; 1: start is from RACCU start [39, 34] 6 [-32, 31] Start address, either static or from RACCU iter_sd [33] 1 [0, 1] 0:iter is static; 1: iter is from RACCU iter [32, 27] 6 [0, 63] Iteration, either static or from RACCU step_sd [26] 1 [0, 1] / 0 0:step is static; 1: step is from RACCU step [25, 20] 6 [0, 63] / 1 Step, either static or from RACCU unused [19, 0] 20 0 Unused 1000 LOOPH (Deprecated) 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A A A A B B B B B B C D D D D 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1000 LOOPH instruction code loopid [22, 19] 4 [0, 15] Loop id start [18, 13] 6 [0, 63] The start number static [12] 1 [0, 1] [0] iter is static; [1] iter is from RACCU iter [11, 8] 4 [0, 15] Static iteration or RACCU register unused [7, 0] 8 0 Deprecated 1001 LOOPT (Deprecated) 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 1 A A A A A A B B B B B B C C C C 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1001 LOOPT instruction code step [22, 17] 6 [0, 63] The step pc [16, 11] 6 [0, 63] Location to jump back loopid [10, 7] 4 [0, 15] Loop id unused [6, 0] 6 0 Unused 1010 RACCU 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A A B C C C C C C C D E E E E E E E F F F F Field Position Width Range/Value Description instr_code [26, 23] 4 b'1010 RACCU instruction code mode [22, 20] 3 [0, 7] Operation mode operand1_sd [19, 19] 1 [0, 1] [0] operand1 is static; [1] operand1 is from RACCU register operand1 [18, 12] 7 [-64, 63] Operand 1 operand2_sd [11, 11] 1 [0, 1] [0] operand2 is static; [1] operand2 is from RACCU register operand2 [10, 4] 7 [-64, 63] Operand 2 result [4, 0] 4 [0, 15] Result register address 1011 BRANCH 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A B B B B B B 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1011 BRANCH instruction code mode [22, 21] 2 [0, 4] The conditional branch mode false_pc [20, 15] 6 [0, 63] Configures the false address unused [14, 0] 15 0 Deprecated 1100 ROUTE 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B C D D D 0 0 0 0 0 0 E 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1100 ROUTE instruction code src_row [22] 1 [0, 1] Source DiMArch row src_col [21, 19] 3 [0, 7] Source DiMArch column dest_row [18] 1 [0, 1] Destination DiMArch row dest_col [17, 15] 3 [0, 7] Destination DiMArch column unused [14, 9] 6 0 Deprecated select_drra_row [8] 1 [0, 1] [0] source is origin; [1] destination is origin unused [7, 0] 8 0 Deprecated 1101 SRAMR 80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 0 1 A B B B B B B B C C C C D D D D D D D E E E E 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | E E E E F F F F F F G G G G G G G H H H H H H H H I I 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1101 SRAMR instruction code unused [76] 1 0 Deprecated init_addr [75, 69] 7 [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 [0, 127] Level 1 iteration l1_step [57, 50] 8 [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 [0, 127] Level 2 iteration l2_step [36, 29] 8 [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused 1110 SRAMW 80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 1 0 A B B B B B B B C C C C D D D D D D D E E E E 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | E E E E F F F F F F G G G G G G G H H H H H H H H I I 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1110 SRAMW instruction code unused [76] 1 0 Deprecated init_addr [75, 69] 7 [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 [0, 127] Level 1 iteration l1_step [57, 50] 8 [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 [0, 127] Level 2 iteration l2_step [36, 29] 8 [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused 1111 HALT 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1111 HALT instruction code unused [22, 0] 23 0 Unused","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#instruction-set","text":"","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#instructions","text":"","title":"Instructions"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0001-refi1","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 1 A A B B C D D D D D D E F F F F F F G H H H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0001 REFI1 instruction code port_no [22, 21] 2 [0, 3] Selects one of the RFile ports extra [20, 19] 2 [0, 3] How many following instructions. init_addr_sd 18 1 [0, 1] [0] init_addr is static; [1] init_addr is from RACCU. init_addr [17, 12] 6 [0, 63] Static init address or RACCU register. l1_iter_sd 11 1 [0, 1] [0] Level 1 iteration is static; [1] L1 iteration is from RACCU. l1_iter [10, 5] 6 [0, 63] Static L1 iteration or RACCU register. init_delay_sd 4 1 [0, 1] [0] init_delay is static; [1] init_delay is from RACCU. init_delay [3, 0] 4 [0, 15] Static init delay or RACCU register.","title":"0001 - REFI1"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0010-refi2","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 1 0 A B B B B B B C D E E E E F G G G G G H H H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0010 REFI2 instruction code l1_step_sd [22] 1 [0, 1] [0] l1_step is static; [1] l1_step is from RACCU l1_step [21, 16] 6 [0, 63] Static level 1 step value or RACCU register l1_step_sign [15] 1 [0, 1] Sign bit of l1_step l1_delay_sd [14] 1 [0, 1] [0] l1_delay is static; [1] l1_delay is from RACCU l1_delay [13, 10] 4 [0, 15] Static level 1 delay or RACCU register l2_iter_sd [9] 1 [0, 1] [0] l2_iter is static; [1] l2_iter is from RACCU l2_iter [8, 4] 5 [0, 31] Static level 2 iteration or RACCU register l2_step [3, 0] 4 [0, 15] Level 2 step value","title":"0010 - REFI2"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0011-refi3","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 1 1 A B B B B B B 0 0 0 0 0 0 C C D E E 0 0 0 F G Field Position Width Range/Value Description instr_code [26, 23] 4 b'0011 REFI3 instruction code l2_delay_sd [22] 1 [0, 1] [0] l2_delay is static; [1] l2_delay is from RACCU. l2_delay [21, 16] 6 [0, 63] Static level 2 delay or RACCU register. unused [15, 10] 6 0 Deprecated l1_delay_ext [9, 8] 2 [0, 3] Extended bits for l1_delay l2_iter_ext [7] 1 [0, 1] Extended bits for l2_iter l2_step_ext [6, 5] 2 [0, 3] Extended bits for l2_step unused [4, 2] 3 0 Deprecated dimarch [1] 1 [0, 1] [0] Not DiMArch; [1] DiMArch mode compress [0] 1 [0, 1] [0] Not compressed; [1] Compressed","title":"0011 - REFI3"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0100-dpu","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 0 A A A A A B B C C D D E F G G G G G G G G H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0100 DPU instruction code mode [22, 18] 5 [0, 12] Configures the valid dpu mode control [17, 16] 2 [0, 3] [00] no saturation, integer; [01] no saturation, fixed-point; [10] saturation, integer; [11] saturation, fixed-point. not_used [15, 10] 6 b'000010 Deprecated acc_clear [9, 2] 8 [0, 255] The DPU accumulator register clear threshold. io_change [1, 0] 2 [0, 3] [00] no change; [01]negate in1; [10] negate in2; [11] return abosolute value of output.","title":"0100 - DPU"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0101-swb","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 1 1 A B C D D D E F F F 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 SWB instruction code active [22] 1 1 Deprecated, always 1 src_row [21] 1 [0, 1] The source DRRA row src_block [20] 1 [0, 1] [0] RF; [1] DPU src_port [19] 1 [0, 1] Source port number hb_index [18, 16] 3 [0, 6] Index of horizontal bus send_to_other_row [15] 1 [0, 1] Flag of whether src and dest row are equal v_index [14, 12] 3 [0, 5] Index of vertical bus unused [11, 0] 12 0 Deprecated","title":"0101 SWB"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0110-jump","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 0 A A A A A A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 JUMP instruction code pc [22, 17] 6 [0, 63] The target address unused [16, 0] 17 0 Deprecated","title":"0110 JUMP"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0111-wait","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B B B B B B B B B B B B B 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0111 DELAY instruction code cycle_sd [22] 1 [0, 1] [0] cycle is static; [1] cycle is from RACCU cycle [21, 7] 15 [0, 32767] Static cycle or RACCU register unused [6, 0] 7 0 0","title":"0111 WAIT"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1000-loop","text":"53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A B B C C C C C C D E E E E E E F G G G G G G 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | H I I I I I I 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [53, 50] 4 b'1000 LOOPH instruction code extend [49] 1 [0, 15] 0:No extension; 1:Extended loopid [48, 47] 2 [0, 3] The id of nested loops endpc [46, 41] 6 [0, 63] The PC where loop ends start_sd [40] 1 [0, 1] 0:start is static; 1: start is from RACCU start [39, 34] 6 [-32, 31] Start address, either static or from RACCU iter_sd [33] 1 [0, 1] 0:iter is static; 1: iter is from RACCU iter [32, 27] 6 [0, 63] Iteration, either static or from RACCU step_sd [26] 1 [0, 1] / 0 0:step is static; 1: step is from RACCU step [25, 20] 6 [0, 63] / 1 Step, either static or from RACCU unused [19, 0] 20 0 Unused","title":"1000 LOOP"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1000-looph-deprecated","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A A A A B B B B B B C D D D D 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1000 LOOPH instruction code loopid [22, 19] 4 [0, 15] Loop id start [18, 13] 6 [0, 63] The start number static [12] 1 [0, 1] [0] iter is static; [1] iter is from RACCU iter [11, 8] 4 [0, 15] Static iteration or RACCU register unused [7, 0] 8 0 Deprecated","title":"1000 LOOPH (Deprecated)"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1001-loopt-deprecated","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 1 A A A A A A B B B B B B C C C C 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1001 LOOPT instruction code step [22, 17] 6 [0, 63] The step pc [16, 11] 6 [0, 63] Location to jump back loopid [10, 7] 4 [0, 15] Loop id unused [6, 0] 6 0 Unused","title":"1001 LOOPT (Deprecated)"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1010-raccu","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A A B C C C C C C C D E E E E E E E F F F F Field Position Width Range/Value Description instr_code [26, 23] 4 b'1010 RACCU instruction code mode [22, 20] 3 [0, 7] Operation mode operand1_sd [19, 19] 1 [0, 1] [0] operand1 is static; [1] operand1 is from RACCU register operand1 [18, 12] 7 [-64, 63] Operand 1 operand2_sd [11, 11] 1 [0, 1] [0] operand2 is static; [1] operand2 is from RACCU register operand2 [10, 4] 7 [-64, 63] Operand 2 result [4, 0] 4 [0, 15] Result register address","title":"1010 RACCU"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1011-branch","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A B B B B B B 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1011 BRANCH instruction code mode [22, 21] 2 [0, 4] The conditional branch mode false_pc [20, 15] 6 [0, 63] Configures the false address unused [14, 0] 15 0 Deprecated","title":"1011 BRANCH"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1100-route","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B C D D D 0 0 0 0 0 0 E 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1100 ROUTE instruction code src_row [22] 1 [0, 1] Source DiMArch row src_col [21, 19] 3 [0, 7] Source DiMArch column dest_row [18] 1 [0, 1] Destination DiMArch row dest_col [17, 15] 3 [0, 7] Destination DiMArch column unused [14, 9] 6 0 Deprecated select_drra_row [8] 1 [0, 1] [0] source is origin; [1] destination is origin unused [7, 0] 8 0 Deprecated","title":"1100 ROUTE"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1101-sramr","text":"80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 0 1 A B B B B B B B C C C C D D D D D D D E E E E 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | E E E E F F F F F F G G G G G G G H H H H H H H H I I 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1101 SRAMR instruction code unused [76] 1 0 Deprecated init_addr [75, 69] 7 [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 [0, 127] Level 1 iteration l1_step [57, 50] 8 [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 [0, 127] Level 2 iteration l2_step [36, 29] 8 [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused","title":"1101 SRAMR"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1110-sramw","text":"80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 1 0 A B B B B B B B C C C C D D D D D D D E E E E 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 | | | | | | | | | | | | | | | | | | | | | | | | | | | E E E E F F F F F F G G G G G G G H H H H H H H H I I 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1110 SRAMW instruction code unused [76] 1 0 Deprecated init_addr [75, 69] 7 [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 [0, 127] Level 1 iteration l1_step [57, 50] 8 [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 [0, 127] Level 2 iteration l2_step [36, 29] 8 [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused","title":"1110 SRAMW"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1111-halt","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1111 HALT instruction code unused [22, 0] 23 0 Unused","title":"1111 HALT"},{"location":"Docs/ToolChain/Vesyla/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/","text":"Programming Guide Basics General Guide Vesyla accept modified matlab code as input language. You shouldn't write the matlab code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of matlab grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variable except for constant variable and loop iterator should always be decleared via pragma. Statement should always ends with semicolon ( ; ) to avoid unexpected outputs while simulating in matlab. Constant number is normally treated as integers, not double floating point. Pragma Pragma is the notation that guides Vesyla during synthesis process. Vesyla recongnize pragma starting with symbols %! . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail. Variable Declaration Variables supported by Vesyla are vectored Register file variables and SRAM variables. Register file variables will bind to register file and SRAM variables will bind to DiMArch. Since matlab dosen't require variable declaration, we need to give initial value to declare them. You can use the standard initialization assignment for matlab 1-D arry to declare a variable. Function such as zeros() and ones() are also supported. To declear SRAM variable, you need to use %! MEM[row, col] pragma. row and col are the coordinate of the SRAM block you want to bind for this variable. SRAM usually organized as a 2-D bit matrix without bit-level and word-level access. Data communication with SRAM happens in bulk mode where each data exchange need to be a complete SRAM row. Suppose SRAM with is N N and Register width (1 word) is M M bit. Each SRAM row will have N/M N/M words. Typical value for M M and N N are M=256 M=256 and N=16 N=16 . Since SRAM only support whole line reading and writing, the SRAM variable you defined should always have multiple of M/N M/N elements. Example The example shows how to define a SRAM variable y on SRAM block [0,0] . y is initialized by a 1-D vector [1,2,3,4,5,...,16] . y = [ 1 : 16 ]; %! MEM[0,0] To declear register file variable, you need to use %! RFIL[row, col] pragma. row and col are the coordinate of the DRRA cell you want to bind for this variable. Unlike SRAM, register file is organized in the way that each row will always represent a word. So there is no restriction on the size of register file variable as long as it doesn't exceed the register depth limit. Example The example shows how to define a register file variable x on DRRA cell [0,0] . x has 5 elements and is initialized by a zeros() function which will set all elements in x to 0 . x = zeros ( 1 , 5 ); %! REFI[0,0] For debugging purpose, vesyla allows initialization of register file variable. However, register should not be initialized with any value other than zeros because the real DRRA cell doesn't have interface to support the register initalization. Register file variables hence should always get data from SRAM variables. Error The following variable declaration style is incorrect: No storage pragma specified x = zeros ( 1 , 5 ); Initialized to scalar x = 1 ; %! RFILE[1,1] Initialized to 2-D array x = ones ( 2 , 3 ); %! RFILE[1,1] SRAM varible is not the size of SRAM row x = [ 1 : 3 ]; %! MEM[0,1] Initialization function randi() is not supported x = randi ( 10 , 1 , 16 ); %! MEM[0,1] Vector Slicing and Address Generation Each DPU can only process one scalar data each time, so the vectored register variable should be slice first before sending to DPU. The slicing operation is mapped on AGU by REFI instruction. While writing matlab code, you don't have to worry about the slicing since matlab directly support vector slicing. Here is an example of slicing a vector: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] If you don't use any slicing and directly feed a vectored register variable to arithmetic operaion, Vesyla will use the full range of that variable. When slicing a SRAM varialbe, the minimal slice should always be multiple of 16. Except for the matlab default slicing method, you can also use two primitive AGU function to linear slice a vectored varialbe both in 1-D or 2-D. Example is given below. All address sequence in the following example are \"1,2,3,4,5\". Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( silago_agu_linear_1d ( 1 , 1 , 5 )) + y ( silago_agu_linear_2d ( 1 , 0 , 1 , 1 , 5 )); %! DPU[0,0] Arithmetic Operation Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, sum, abs, etc. Special arithmetic operation need to be mapped to special DPU mode by primitive function call, see section Primitive Function . Bug Symbol ~ is not supported yet! For arithmetic assignment, you can have a multiple variables as output depending on the DPU mode. The ignored output can be muted by symbol ~ . Arithmetic operation need a computation resource to perform required operation, that is the DPU. So, every arithmetic operation need to bind to a DPU resource via pragma. Example of an arithmetic assignment is demonstrated as following: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] Static Loop Vesyla accept all static loops. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example n = 3 ; for i = 1 : 1 : n + 1 ... end Dynamic Loop Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point, and dynamic iteration. However, those number should be in address domain, a.k.a computed by RACCU and is fully determinastic after unrolling all the loops. Example of such dynamic loop is shown below: Example for i = 1 : 1 : 4 for j = i : 1 : i + 3 ... end end Branch Vesyla support normal matlab branch except for both operands of condition are constants. The usage of branch is the same as the original matlab code. For example: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] w = [ 3 , 5 ]; %! REFI[0,0] if w ( 1 ) > w ( 2 ) y = x ; else y = x + y ; %! DPU[0,0] end Address Constraint Address constraints are parameters used by address generation in AGU. Address constraints can be constant or RACCU variable calculated at run-time in RACCU. Dynamic address constraint variables are usually used in loops. Example below shows how to use a RACCU variable to serve as address constraint. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] a = 1 ; %! RACCU_VAR for i = 1 : 1 : 4 y ( a + 1 : a + 1 + 5 ) = x ( 1 : 5 ) + y ( a : a + 5 ); %! DPU[0,0] a = a + 1 ; end Advanced Features Macro Vesyla support symbolic expression to enable fast design space exploration. One of the technique is to use macros. Before the lexecal analysis, vesyla will expand all macro to normal program code. Macro gives programmer the tool to generate multiple program with small variations. Programmer need to provide a template and a series of data. Data is organized in json format and will be loaded in to evaluate those macros defined in template. Template use a grammar like the templating package inja . Infact, vesyla directly use inja library to evaluate macros. Example below demonstrate how to define a loop in template: Example An template file defined as following: { % for x in range(par_col) %} x0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] y0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] { % endfor %} With a json-formated data file: { \"par_col\" : 2 } This template will generate a real matlab code as following by expanding the FOR-LOOP macro: x0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] y0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] x0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] y0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] Tip More complex usage please visit inja website. Primitive Function Primitive DPU functions are functions that corresponds to a complete DPU mode. Different DPUs targeting on different application domain may have some special modes specifically made for such application domain. For example, sigmoid function for neural network application. Those primitive function is not directly supported by matlab, but they are supported by vesyla. To use a specific DPU mode as primitive function, first you need to make sure the DRRA cell you are using has such mode. Then you need to change the configuration of vesyla to recongnize such mode. The configuration file is $Vesyla_root/config/primitive_func_def.xml . Finally, you can use the function inside your program. All primitive DPU functions have name should start with silago_dpu_ to be accepted by Vesyla. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] x = silago_dpu_sigmoid ( x ); %! DPU[0,0] AUGs also have special primitive functions to express the complex addressing mode. But AGU primitive functions are not custom. There are two AGU primitive function: silago_agu_linear_1d() and silago_agu_linear_2d() . More AGU primitive functions will be added if some application domain requires. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] a = [ 1 ]; %! REFI[0,0] x = x + a ( silago_agu_linear_1d ( 1 , 0 , 5 )); %! DPU[0,0] Resource Sharing Region When multiple operations need some common operands, due to the limit of the number of reading ports, those operations can't happen at the same time in normal condition. Resource sharing region tries to solve the problem. By enabling the broadcasting mechanism, all operation will recieve the same common operand at the same time generated by single reading port of the register file. The datapath of transmitting the common operand is now shared among those operations. Resource sharing region requires a fixed datapath layout. Dynamic change of datapath structure is forbidden inside resource sharing region. So, you should only use it when needed. Following example shows how to active resource sharing region. Example x0 = [ 1 : 5 ]; %! REFI[0,0] x1 = [ 1 : 5 ]; %! REFI[1,0] a2 = [ 1 : 5 ]; %! REFI[2,0] x3 = [ 1 : 5 ]; %! REFI[3,0] x4 = [ 1 : 5 ]; %! REFI[4,0] %! RESOURCE_SHARING_BEGIN x0 = x0 + a2 ; %! DPU[0,0] x1 = x1 + a2 ; %! DPU[1,0] x3 = x3 + a2 ; %! DPU[3,0] x4 = x4 + a2 ; %! DPU[4,0] %! RESOURCE_SHARING_END DPU Chain Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] z = [ 1 : 5 ]; %! REFI[0,0] t = zeros ( 1 , 5 ); %! CDPU[0,0] t = x + y ; z = silago_dpu_sigmoid ( t ); %! DPU[1,0] DPU Internal Scalar Register Inside each DPU, there are two internal scalar registers which can be explicitly used via high-level matlab program. One can use them by declearing them with the pragma %! CDPU[row, col] . The available functions to load and store values to/from internal scalar registers are: r0 = silago_dpu_load_reg_0 ( x ( 1 )); r1 = silago_dpu_load_reg_1 ( x ( 1 )); [ r0 , r1 ] = silago_dpu_load_reg_both ( x ( 1 ), x ( 2 )); x ( 1 ) = silago_dpu_load_store_0 ( r0 ); x ( 1 ) = silago_dpu_load_store_1 ( r1 ); [ x ( 1 ), y ( 1 )] = silago_dpu_load_store_both ( r0 , r1 ); Warning Programmer should keep in mind that lifetime and physical location of those variable. Vesyla has very weak semantic checking on those internal scalar register variables. Example For example, if one want to calculate a function: y = ax.y y = ax.y . Instead of put the coefficient a a inside a normal register and waste other register entries of the same register block, you can put the coefficient to the internal register, and configure DPU to a scaled multiplication mode to get the correct result. a_mem = [ 1 : 16 ]; %! SRAM[0,0] x_mem = [ 1 : 16 ]; %! SRAM[0,0] y_mem = [ 1 : 16 ]; %! SRAM[0,0] x = [ 1 : 16 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] r = zeros ( 1 , 1 ); %! CDPU[0,0] x = a_mem ; r = silago_dpu_load_reg_1 ( x ( 1 )); x = x_mem ; y = y_mem ; y = silago_dpu_scaled_mul ( x , y , r ); %! DPU[0,0] y_mem = y ; Not Supported Some matlab code is not accepted by Vesyla because it can't execute on DRRA fabric. They are: While-loop. For-loop inside branch. Arithmetic statement that can't be mapped to single DPU mode. Normal function call except for primitive function call. Indirect addressing.","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#programming-guide","text":"","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#basics","text":"","title":"Basics"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#general-guide","text":"Vesyla accept modified matlab code as input language. You shouldn't write the matlab code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of matlab grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variable except for constant variable and loop iterator should always be decleared via pragma. Statement should always ends with semicolon ( ; ) to avoid unexpected outputs while simulating in matlab. Constant number is normally treated as integers, not double floating point.","title":"General Guide"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#pragma","text":"Pragma is the notation that guides Vesyla during synthesis process. Vesyla recongnize pragma starting with symbols %! . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail.","title":"Pragma"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#variable-declaration","text":"Variables supported by Vesyla are vectored Register file variables and SRAM variables. Register file variables will bind to register file and SRAM variables will bind to DiMArch. Since matlab dosen't require variable declaration, we need to give initial value to declare them. You can use the standard initialization assignment for matlab 1-D arry to declare a variable. Function such as zeros() and ones() are also supported. To declear SRAM variable, you need to use %! MEM[row, col] pragma. row and col are the coordinate of the SRAM block you want to bind for this variable. SRAM usually organized as a 2-D bit matrix without bit-level and word-level access. Data communication with SRAM happens in bulk mode where each data exchange need to be a complete SRAM row. Suppose SRAM with is N N and Register width (1 word) is M M bit. Each SRAM row will have N/M N/M words. Typical value for M M and N N are M=256 M=256 and N=16 N=16 . Since SRAM only support whole line reading and writing, the SRAM variable you defined should always have multiple of M/N M/N elements. Example The example shows how to define a SRAM variable y on SRAM block [0,0] . y is initialized by a 1-D vector [1,2,3,4,5,...,16] . y = [ 1 : 16 ]; %! MEM[0,0] To declear register file variable, you need to use %! RFIL[row, col] pragma. row and col are the coordinate of the DRRA cell you want to bind for this variable. Unlike SRAM, register file is organized in the way that each row will always represent a word. So there is no restriction on the size of register file variable as long as it doesn't exceed the register depth limit. Example The example shows how to define a register file variable x on DRRA cell [0,0] . x has 5 elements and is initialized by a zeros() function which will set all elements in x to 0 . x = zeros ( 1 , 5 ); %! REFI[0,0] For debugging purpose, vesyla allows initialization of register file variable. However, register should not be initialized with any value other than zeros because the real DRRA cell doesn't have interface to support the register initalization. Register file variables hence should always get data from SRAM variables. Error The following variable declaration style is incorrect: No storage pragma specified x = zeros ( 1 , 5 ); Initialized to scalar x = 1 ; %! RFILE[1,1] Initialized to 2-D array x = ones ( 2 , 3 ); %! RFILE[1,1] SRAM varible is not the size of SRAM row x = [ 1 : 3 ]; %! MEM[0,1] Initialization function randi() is not supported x = randi ( 10 , 1 , 16 ); %! MEM[0,1]","title":"Variable Declaration"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#vector-slicing-and-address-generation","text":"Each DPU can only process one scalar data each time, so the vectored register variable should be slice first before sending to DPU. The slicing operation is mapped on AGU by REFI instruction. While writing matlab code, you don't have to worry about the slicing since matlab directly support vector slicing. Here is an example of slicing a vector: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] If you don't use any slicing and directly feed a vectored register variable to arithmetic operaion, Vesyla will use the full range of that variable. When slicing a SRAM varialbe, the minimal slice should always be multiple of 16. Except for the matlab default slicing method, you can also use two primitive AGU function to linear slice a vectored varialbe both in 1-D or 2-D. Example is given below. All address sequence in the following example are \"1,2,3,4,5\". Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( silago_agu_linear_1d ( 1 , 1 , 5 )) + y ( silago_agu_linear_2d ( 1 , 0 , 1 , 1 , 5 )); %! DPU[0,0]","title":"Vector Slicing and Address Generation"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#arithmetic-operation","text":"Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, sum, abs, etc. Special arithmetic operation need to be mapped to special DPU mode by primitive function call, see section Primitive Function . Bug Symbol ~ is not supported yet! For arithmetic assignment, you can have a multiple variables as output depending on the DPU mode. The ignored output can be muted by symbol ~ . Arithmetic operation need a computation resource to perform required operation, that is the DPU. So, every arithmetic operation need to bind to a DPU resource via pragma. Example of an arithmetic assignment is demonstrated as following: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0]","title":"Arithmetic Operation"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#static-loop","text":"Vesyla accept all static loops. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example n = 3 ; for i = 1 : 1 : n + 1 ... end","title":"Static Loop"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#dynamic-loop","text":"Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point, and dynamic iteration. However, those number should be in address domain, a.k.a computed by RACCU and is fully determinastic after unrolling all the loops. Example of such dynamic loop is shown below: Example for i = 1 : 1 : 4 for j = i : 1 : i + 3 ... end end","title":"Dynamic Loop"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#branch","text":"Vesyla support normal matlab branch except for both operands of condition are constants. The usage of branch is the same as the original matlab code. For example: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] w = [ 3 , 5 ]; %! REFI[0,0] if w ( 1 ) > w ( 2 ) y = x ; else y = x + y ; %! DPU[0,0] end","title":"Branch"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#address-constraint","text":"Address constraints are parameters used by address generation in AGU. Address constraints can be constant or RACCU variable calculated at run-time in RACCU. Dynamic address constraint variables are usually used in loops. Example below shows how to use a RACCU variable to serve as address constraint. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] a = 1 ; %! RACCU_VAR for i = 1 : 1 : 4 y ( a + 1 : a + 1 + 5 ) = x ( 1 : 5 ) + y ( a : a + 5 ); %! DPU[0,0] a = a + 1 ; end","title":"Address Constraint"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#advanced-features","text":"","title":"Advanced Features"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#macro","text":"Vesyla support symbolic expression to enable fast design space exploration. One of the technique is to use macros. Before the lexecal analysis, vesyla will expand all macro to normal program code. Macro gives programmer the tool to generate multiple program with small variations. Programmer need to provide a template and a series of data. Data is organized in json format and will be loaded in to evaluate those macros defined in template. Template use a grammar like the templating package inja . Infact, vesyla directly use inja library to evaluate macros. Example below demonstrate how to define a loop in template: Example An template file defined as following: { % for x in range(par_col) %} x0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] y0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] { % endfor %} With a json-formated data file: { \"par_col\" : 2 } This template will generate a real matlab code as following by expanding the FOR-LOOP macro: x0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] y0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] x0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] y0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] Tip More complex usage please visit inja website.","title":"Macro"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#primitive-function","text":"Primitive DPU functions are functions that corresponds to a complete DPU mode. Different DPUs targeting on different application domain may have some special modes specifically made for such application domain. For example, sigmoid function for neural network application. Those primitive function is not directly supported by matlab, but they are supported by vesyla. To use a specific DPU mode as primitive function, first you need to make sure the DRRA cell you are using has such mode. Then you need to change the configuration of vesyla to recongnize such mode. The configuration file is $Vesyla_root/config/primitive_func_def.xml . Finally, you can use the function inside your program. All primitive DPU functions have name should start with silago_dpu_ to be accepted by Vesyla. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] x = silago_dpu_sigmoid ( x ); %! DPU[0,0] AUGs also have special primitive functions to express the complex addressing mode. But AGU primitive functions are not custom. There are two AGU primitive function: silago_agu_linear_1d() and silago_agu_linear_2d() . More AGU primitive functions will be added if some application domain requires. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] a = [ 1 ]; %! REFI[0,0] x = x + a ( silago_agu_linear_1d ( 1 , 0 , 5 )); %! DPU[0,0]","title":"Primitive Function"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#resource-sharing-region","text":"When multiple operations need some common operands, due to the limit of the number of reading ports, those operations can't happen at the same time in normal condition. Resource sharing region tries to solve the problem. By enabling the broadcasting mechanism, all operation will recieve the same common operand at the same time generated by single reading port of the register file. The datapath of transmitting the common operand is now shared among those operations. Resource sharing region requires a fixed datapath layout. Dynamic change of datapath structure is forbidden inside resource sharing region. So, you should only use it when needed. Following example shows how to active resource sharing region. Example x0 = [ 1 : 5 ]; %! REFI[0,0] x1 = [ 1 : 5 ]; %! REFI[1,0] a2 = [ 1 : 5 ]; %! REFI[2,0] x3 = [ 1 : 5 ]; %! REFI[3,0] x4 = [ 1 : 5 ]; %! REFI[4,0] %! RESOURCE_SHARING_BEGIN x0 = x0 + a2 ; %! DPU[0,0] x1 = x1 + a2 ; %! DPU[1,0] x3 = x3 + a2 ; %! DPU[3,0] x4 = x4 + a2 ; %! DPU[4,0] %! RESOURCE_SHARING_END","title":"Resource Sharing Region"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#dpu-chain","text":"Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] z = [ 1 : 5 ]; %! REFI[0,0] t = zeros ( 1 , 5 ); %! CDPU[0,0] t = x + y ; z = silago_dpu_sigmoid ( t ); %! DPU[1,0]","title":"DPU Chain"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#dpu-internal-scalar-register","text":"Inside each DPU, there are two internal scalar registers which can be explicitly used via high-level matlab program. One can use them by declearing them with the pragma %! CDPU[row, col] . The available functions to load and store values to/from internal scalar registers are: r0 = silago_dpu_load_reg_0 ( x ( 1 )); r1 = silago_dpu_load_reg_1 ( x ( 1 )); [ r0 , r1 ] = silago_dpu_load_reg_both ( x ( 1 ), x ( 2 )); x ( 1 ) = silago_dpu_load_store_0 ( r0 ); x ( 1 ) = silago_dpu_load_store_1 ( r1 ); [ x ( 1 ), y ( 1 )] = silago_dpu_load_store_both ( r0 , r1 ); Warning Programmer should keep in mind that lifetime and physical location of those variable. Vesyla has very weak semantic checking on those internal scalar register variables. Example For example, if one want to calculate a function: y = ax.y y = ax.y . Instead of put the coefficient a a inside a normal register and waste other register entries of the same register block, you can put the coefficient to the internal register, and configure DPU to a scaled multiplication mode to get the correct result. a_mem = [ 1 : 16 ]; %! SRAM[0,0] x_mem = [ 1 : 16 ]; %! SRAM[0,0] y_mem = [ 1 : 16 ]; %! SRAM[0,0] x = [ 1 : 16 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] r = zeros ( 1 , 1 ); %! CDPU[0,0] x = a_mem ; r = silago_dpu_load_reg_1 ( x ( 1 )); x = x_mem ; y = y_mem ; y = silago_dpu_scaled_mul ( x , y , r ); %! DPU[0,0] y_mem = y ;","title":"DPU Internal Scalar Register"},{"location":"Docs/ToolChain/Vesyla/ProgrammingGuide/#not-supported","text":"Some matlab code is not accepted by Vesyla because it can't execute on DRRA fabric. They are: While-loop. For-loop inside branch. Arithmetic statement that can't be mapped to single DPU mode. Normal function call except for primitive function call. Indirect addressing.","title":"Not Supported"},{"location":"Docs/ToolChain/Vesyla/Scheduling/","text":"Scheduling Problem Defination In Vesyla, the generated instructions have fairly long life-time and are highly cooperative. Which means they are not just single-cycle actors with simple precedency relation that fight for resources. Instructions running in DRRA microthreads might actively coordinate themselves with other instructions executing in some other microthreads. Cooperation with other instructions can happen at any time when an instruction is alive and it can happen multiple times with multiple different other instructions. Further more, the life-time of an instruction in Vesyla can be undetermined and depend on other instructions in terms of both precedency relation and resource availability. To simplify the scenario a little bit, we consider the critical points of those instructions as the atomic unit objects (jobs/actors/operations) that need to be scheduled in the cooperative instruction scheduling problem which will be defined later. What are the critical points? They can be starting and ending point of instructions. They can be the time points when a instruction change its resource usage. They can be the time points when a instruction need to coordinate with other instructions. In short, whenever an instruction changes anything, it's a critical point. Critical points don't have execution duration, it just represents a timestamp. However, critical points can have resoure usage attached to it. Resource usage requires time duration. With the usage of critical points, a new phenominal appears. Some instructions can have undetermined life-time before scheduling. When those instructions are broken down into critical points, the resource usage of those critical points need special treatment since their usage duration are undetermined. We need to assign a LOCK resource usage frame to the critical point starting to use the resource and a KEY resource usage frame to the critical point finishing to use the resource. The resource between LOCK and KEY frame during scheding should be marked unavailable to other critical points. Cooperative instruction scheduling problem thus is very different from the classic instruction scheduling problem. In classic instruction scheduling problem, either positive or negative time-lag exists between a pair of instructions. While between a cooperative critical points pair, both minimal and maximum time-lag may exist, which constrants the precedence relation to a possibly closed time frame. A special case is when minimal and maximum time-lag are equal, representing the two critical points will have an exact time difference. The introduce of LOCK and KEY frame for resource usage is also very different from conventional instruction scheduling problem. Now, we formally define the scheduling model and the scheduling problem. Warning MODEL AND PROBLEM DEFINATION Problem Simplification The scheduling model defined above can not be used directly because it's high complexity creates a vast solution space and scheduling algorithm will have hard time to navigate to the correct direction. Therefore, we propose one assumption and four simplification step to simplify the model. The simplification processes transform the model to equivalent but simpler model hence shrink the solution space. Delay bound assumption Delay bounds of an edge in depenency graph can be either negative or positive as long as the higher bound d_h d_h is not less than lower bound d_l d_l . An edge with d_l=-\\infty d_l=-\\infty or with d_l\\le d_h \\lt 0 d_l\\le d_h \\lt 0 can be easily converted to an edge with d_l\\neq -\\infty d_l\\neq -\\infty and d_h\\ge 0 d_h\\ge 0 . Therefore, we assume that: every edge in dependency graph will have a delay bounds satisfying d_l\\neq -\\infty d_l\\neq -\\infty , d_h\\ge 0 d_h\\ge 0 and d_l\\le d_h d_l\\le d_h . Parking Hard-links Hard-links are edges with constant delay ( d_l=d_h d_l=d_h ). For example, A\\xrightarrow[]{\\text{[w,w]}}B A\\xrightarrow[]{\\text{[w,w]}}B is a hard-link, it describs the constraint that the schedule time of B is exactly w w cycles after the schedule time of A. All vertices linked by hard-links should be scheduled together, because if any vertex has been scheduled, the schedule time of other vertices which directly or indirectly linked to the scheduled vertex can be determined immediately. Therefore, packing hard-linked vertices together can reduce the size of graph and accelerate the scheduling process. Pseudo Algorithm is shown below: Graph packing_hard_links ( Graph g ){ Graph g1 = remove_soft_links ( g ); Component C = find_connected_components ( g1 ); Graph g2 ; for ( auto c : C ){ vector < Vertex , int > offset_map = find_offset_for_each_vertex ( c ); Vertex vc ; Graph g3 ; for ( auto v : c . vertices ()){ v . schedule_time = offset_map ( v ); g3 . add_vertex ( v ); } vc . add_child ( g3 ) g2 . add_vertex ( vc ); } for ( auto e : edges ( g )){ if ( is_soft_link ( e ) && in_different_component ( e . src , e . dest )){ Edge e1 = reshape_edge_accroding_to_g2 ( e ); g2 . add_edge ( e1 ); } } return g2 ; } Remove Redundant Edges When analyzing the weighted edges in dependency graph (DG), it's easy to discover that there are some edges that have very relatexed constraints which can be removed completely without loosing any synchronization constraint information of the original DG. Example below illustrate such scenario. {% dot schedule_remove_redundant_edges.svg digraph G { rankdir=\"LR\"; u -> v [label=\"[1, 5]\"]; u -> w [label=\"[1, 2]\"]; w -> v [label=\"[0, 1]\"]; } %} From the path u \\rightarrow v u \\rightarrow v , assuming u u starts at t_0 t_0 , v v should start at the time period [t_0+1,t_0+5] [t_0+1,t_0+5] . While from the path u \\rightarrow w \\rightarrow v u \\rightarrow w \\rightarrow v , v v should start at the time period [t_0+1,t_0+3] [t_0+1,t_0+3] . It's obvious that period [t_0+1,t_0+5] [t_0+1,t_0+5] is more relaxed thatn period [t_0+1,t_0+3] [t_0+1,t_0+3] . The path u \\rightarrow v u \\rightarrow v doesn't add any addtition information, hence, can be removed. Negative Edge Weight Adjustment In DG, weight can be period with negative integers. Therefore, if there is an edge u \\xrightarrow[]{\\text[-2,2]} v u \\xrightarrow[]{\\text[-2,2]} v , though graphically the edge point from u u to v v , it doesn't necessarily mean that after scheduling, v v is scheduled after u u . The inconsistancy between graph representation and the actual meaning of the weighted edge cause some troubles during later process. It would be much better if we can find a way to make them consistant.To adjust the weight of edges, the goal is to guarantee the weight period are strictly positive numbers. Reader should keep in mind what are the vertices in DG. They are just timestamp marking the critical time of each operation. There may be resource occupation table (ROT) attach to them. Suppose we have an edge like as following: {% dot schedule_edge_weight_adjustment_0.svg digraph G { rankdir=\"LR\"; u [label=\"u\"]; v [label=\"v\"]; u -> v [label=\"[-2, 2]\"]; } %} We can insert a dummy vertex d d with no ROT attach to it before u u with exactly 3 cycles ahead. {% dot schedule_remove_edge_weight_adjustment_1.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; u -> v [label=\"[-2, 2]\"]; } %} The edge u \\rightarrow v u \\rightarrow v can be replaced by a new edge d \\rightarrow v d \\rightarrow v . {% dot schedule_remove_edge_weight_adjustment_2.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; d -> v [label=\"[1, 5]\"]; } %} Edge d \\rightarrow u d \\rightarrow u is always a hard edge, we can merge vertex d d and u u to a new vertex u' u' with shifted ROT_u as its attached ROT. {% dot schedule_edge_weight_adjustment_3.svg digraph G { rankdir=\"LR\"; u [label=\"u'\"]; v [label=\"v\"]; u -> v [label=\"[1, 5]\"]; } %} In this way, every negative numbered weight can be converted to positive weight in DG. Resource Hazard Prediction A well defined program will always have LOCK/KEY frame pair for any resource. A resource should never been locked and there is no KEY frame to unlock it, or vice versa. Different LOCK/KEY pair targeting the same resource will conflict with each other due to the resource occupation. The resource harzard should be resolved by scheduling via time multiplexing. However, in some scenario, if the scheduler don't schedule the vertices in a specific order, the scheduling might lead to unschduable situation due to resource occupation deadlock. Some exploration algorithms such as LIST scheduling engine might fail. While other scheduling engine such as Branch-and-Bound might stack to some corner space exploring for a very long time in order to find a valid suliton. The following example clearly shows such scenario. {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; } %} Vertex c c can be chosen by the scheduler to schedule first because it don't have any dependency from other vertices. The naturally, f, g, h f, g, h can be scheduled. But d d can not be scheduled because e e is not scheduled. e e can not be scheduled because a a can't be scheduled due to resource r r is locked by c c . And r r is not can't be freed because d d can't be scheduled. This is a deadlock and will make this scheduling unfeasible. In order to correct the mistake, the scheduler (for example Branch-and-Bound) will try to trace back and to the step of scheduling h h , then trace back again to g g . Until it back-tracks to c c , the very first scheduling step, the scheduler can't correct the mistake. To solve such problem, we need to predict the scheduling order. By analyzing the graph structure, we should be able to conclude that c c should be scheduled after than b b . We then force a constraint edge to explictly represent such scheduling order in order to help the later exploring phase. The dependency graph after hazard prediction will be look like this: {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; b -> c; } %} Solution Space Exploration Scheduling is an NP-Complete problem. To find a valid solution for dependency graph, we need some solution searching engine or hierustic scheduling algorithm. Branch-and-Bound, Constriant Programming, LIST algorithm, Simulated Annening, etc are such searching engines. In this section, we introduce two searching engine as an example to demonstrate how does the solution space exploration works. LIST Scheduling Algorithm","title":"Scheduling"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#scheduling","text":"","title":"Scheduling"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#problem-defination","text":"In Vesyla, the generated instructions have fairly long life-time and are highly cooperative. Which means they are not just single-cycle actors with simple precedency relation that fight for resources. Instructions running in DRRA microthreads might actively coordinate themselves with other instructions executing in some other microthreads. Cooperation with other instructions can happen at any time when an instruction is alive and it can happen multiple times with multiple different other instructions. Further more, the life-time of an instruction in Vesyla can be undetermined and depend on other instructions in terms of both precedency relation and resource availability. To simplify the scenario a little bit, we consider the critical points of those instructions as the atomic unit objects (jobs/actors/operations) that need to be scheduled in the cooperative instruction scheduling problem which will be defined later. What are the critical points? They can be starting and ending point of instructions. They can be the time points when a instruction change its resource usage. They can be the time points when a instruction need to coordinate with other instructions. In short, whenever an instruction changes anything, it's a critical point. Critical points don't have execution duration, it just represents a timestamp. However, critical points can have resoure usage attached to it. Resource usage requires time duration. With the usage of critical points, a new phenominal appears. Some instructions can have undetermined life-time before scheduling. When those instructions are broken down into critical points, the resource usage of those critical points need special treatment since their usage duration are undetermined. We need to assign a LOCK resource usage frame to the critical point starting to use the resource and a KEY resource usage frame to the critical point finishing to use the resource. The resource between LOCK and KEY frame during scheding should be marked unavailable to other critical points. Cooperative instruction scheduling problem thus is very different from the classic instruction scheduling problem. In classic instruction scheduling problem, either positive or negative time-lag exists between a pair of instructions. While between a cooperative critical points pair, both minimal and maximum time-lag may exist, which constrants the precedence relation to a possibly closed time frame. A special case is when minimal and maximum time-lag are equal, representing the two critical points will have an exact time difference. The introduce of LOCK and KEY frame for resource usage is also very different from conventional instruction scheduling problem. Now, we formally define the scheduling model and the scheduling problem. Warning MODEL AND PROBLEM DEFINATION","title":"Problem Defination"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#problem-simplification","text":"The scheduling model defined above can not be used directly because it's high complexity creates a vast solution space and scheduling algorithm will have hard time to navigate to the correct direction. Therefore, we propose one assumption and four simplification step to simplify the model. The simplification processes transform the model to equivalent but simpler model hence shrink the solution space.","title":"Problem Simplification"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#delay-bound-assumption","text":"Delay bounds of an edge in depenency graph can be either negative or positive as long as the higher bound d_h d_h is not less than lower bound d_l d_l . An edge with d_l=-\\infty d_l=-\\infty or with d_l\\le d_h \\lt 0 d_l\\le d_h \\lt 0 can be easily converted to an edge with d_l\\neq -\\infty d_l\\neq -\\infty and d_h\\ge 0 d_h\\ge 0 . Therefore, we assume that: every edge in dependency graph will have a delay bounds satisfying d_l\\neq -\\infty d_l\\neq -\\infty , d_h\\ge 0 d_h\\ge 0 and d_l\\le d_h d_l\\le d_h .","title":"Delay bound assumption"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#parking-hard-links","text":"Hard-links are edges with constant delay ( d_l=d_h d_l=d_h ). For example, A\\xrightarrow[]{\\text{[w,w]}}B A\\xrightarrow[]{\\text{[w,w]}}B is a hard-link, it describs the constraint that the schedule time of B is exactly w w cycles after the schedule time of A. All vertices linked by hard-links should be scheduled together, because if any vertex has been scheduled, the schedule time of other vertices which directly or indirectly linked to the scheduled vertex can be determined immediately. Therefore, packing hard-linked vertices together can reduce the size of graph and accelerate the scheduling process. Pseudo Algorithm is shown below: Graph packing_hard_links ( Graph g ){ Graph g1 = remove_soft_links ( g ); Component C = find_connected_components ( g1 ); Graph g2 ; for ( auto c : C ){ vector < Vertex , int > offset_map = find_offset_for_each_vertex ( c ); Vertex vc ; Graph g3 ; for ( auto v : c . vertices ()){ v . schedule_time = offset_map ( v ); g3 . add_vertex ( v ); } vc . add_child ( g3 ) g2 . add_vertex ( vc ); } for ( auto e : edges ( g )){ if ( is_soft_link ( e ) && in_different_component ( e . src , e . dest )){ Edge e1 = reshape_edge_accroding_to_g2 ( e ); g2 . add_edge ( e1 ); } } return g2 ; }","title":"Parking Hard-links"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#remove-redundant-edges","text":"When analyzing the weighted edges in dependency graph (DG), it's easy to discover that there are some edges that have very relatexed constraints which can be removed completely without loosing any synchronization constraint information of the original DG. Example below illustrate such scenario. {% dot schedule_remove_redundant_edges.svg digraph G { rankdir=\"LR\"; u -> v [label=\"[1, 5]\"]; u -> w [label=\"[1, 2]\"]; w -> v [label=\"[0, 1]\"]; } %} From the path u \\rightarrow v u \\rightarrow v , assuming u u starts at t_0 t_0 , v v should start at the time period [t_0+1,t_0+5] [t_0+1,t_0+5] . While from the path u \\rightarrow w \\rightarrow v u \\rightarrow w \\rightarrow v , v v should start at the time period [t_0+1,t_0+3] [t_0+1,t_0+3] . It's obvious that period [t_0+1,t_0+5] [t_0+1,t_0+5] is more relaxed thatn period [t_0+1,t_0+3] [t_0+1,t_0+3] . The path u \\rightarrow v u \\rightarrow v doesn't add any addtition information, hence, can be removed.","title":"Remove Redundant Edges"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#negative-edge-weight-adjustment","text":"In DG, weight can be period with negative integers. Therefore, if there is an edge u \\xrightarrow[]{\\text[-2,2]} v u \\xrightarrow[]{\\text[-2,2]} v , though graphically the edge point from u u to v v , it doesn't necessarily mean that after scheduling, v v is scheduled after u u . The inconsistancy between graph representation and the actual meaning of the weighted edge cause some troubles during later process. It would be much better if we can find a way to make them consistant.To adjust the weight of edges, the goal is to guarantee the weight period are strictly positive numbers. Reader should keep in mind what are the vertices in DG. They are just timestamp marking the critical time of each operation. There may be resource occupation table (ROT) attach to them. Suppose we have an edge like as following: {% dot schedule_edge_weight_adjustment_0.svg digraph G { rankdir=\"LR\"; u [label=\"u\"]; v [label=\"v\"]; u -> v [label=\"[-2, 2]\"]; } %} We can insert a dummy vertex d d with no ROT attach to it before u u with exactly 3 cycles ahead. {% dot schedule_remove_edge_weight_adjustment_1.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; u -> v [label=\"[-2, 2]\"]; } %} The edge u \\rightarrow v u \\rightarrow v can be replaced by a new edge d \\rightarrow v d \\rightarrow v . {% dot schedule_remove_edge_weight_adjustment_2.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; d -> v [label=\"[1, 5]\"]; } %} Edge d \\rightarrow u d \\rightarrow u is always a hard edge, we can merge vertex d d and u u to a new vertex u' u' with shifted ROT_u as its attached ROT. {% dot schedule_edge_weight_adjustment_3.svg digraph G { rankdir=\"LR\"; u [label=\"u'\"]; v [label=\"v\"]; u -> v [label=\"[1, 5]\"]; } %} In this way, every negative numbered weight can be converted to positive weight in DG.","title":"Negative Edge Weight Adjustment"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#resource-hazard-prediction","text":"A well defined program will always have LOCK/KEY frame pair for any resource. A resource should never been locked and there is no KEY frame to unlock it, or vice versa. Different LOCK/KEY pair targeting the same resource will conflict with each other due to the resource occupation. The resource harzard should be resolved by scheduling via time multiplexing. However, in some scenario, if the scheduler don't schedule the vertices in a specific order, the scheduling might lead to unschduable situation due to resource occupation deadlock. Some exploration algorithms such as LIST scheduling engine might fail. While other scheduling engine such as Branch-and-Bound might stack to some corner space exploring for a very long time in order to find a valid suliton. The following example clearly shows such scenario. {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; } %} Vertex c c can be chosen by the scheduler to schedule first because it don't have any dependency from other vertices. The naturally, f, g, h f, g, h can be scheduled. But d d can not be scheduled because e e is not scheduled. e e can not be scheduled because a a can't be scheduled due to resource r r is locked by c c . And r r is not can't be freed because d d can't be scheduled. This is a deadlock and will make this scheduling unfeasible. In order to correct the mistake, the scheduler (for example Branch-and-Bound) will try to trace back and to the step of scheduling h h , then trace back again to g g . Until it back-tracks to c c , the very first scheduling step, the scheduler can't correct the mistake. To solve such problem, we need to predict the scheduling order. By analyzing the graph structure, we should be able to conclude that c c should be scheduled after than b b . We then force a constraint edge to explictly represent such scheduling order in order to help the later exploring phase. The dependency graph after hazard prediction will be look like this: {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; b -> c; } %}","title":"Resource Hazard Prediction"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#solution-space-exploration","text":"Scheduling is an NP-Complete problem. To find a valid solution for dependency graph, we need some solution searching engine or hierustic scheduling algorithm. Branch-and-Bound, Constriant Programming, LIST algorithm, Simulated Annening, etc are such searching engines. In this section, we introduce two searching engine as an example to demonstrate how does the solution space exploration works.","title":"Solution Space Exploration"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#list-scheduling-algorithm","text":"","title":"LIST Scheduling Algorithm"},{"location":"Docs/ToolChain/Vesyla/Tutorial/","text":"Vesyla tutorial Working environment Operating System : Any modern Linux distribution Commercial Software : Matlab QuestaSim File structure $VesylaRoot/ |- src/ | |- all source files. | |- matlab_lib/ | |- matlab behavior models for DPU modes | |- config/ | |- some configuration files. | |- autotest/ | |- some scripts for auto testing. | |- some testcases. | |- build/ |- compilation working directory Compile Vesyla First, install compilation tool chain. You need to use the correct package manager of your Linux distribution. The needed packages include: g++ (version 5 or above), make, cmake, boost liabrires, gecode. Here, we give the example command for Fedora Linux. sudo yum install g ++ make cmake boost-devel Gecode is not really necessary, Vesyla only use it for CP scheduling engine. However, you still need to install it. You can install it according to the installation instruction on the official website: https://www.gecode.org/ Then, you create working directory build . cd $VesylaRoot mkdir build cd build Next step is to generate makefile according to the CMake configuration file CMakeLists.txt. cmake .. Now, it's time to compile vesyla. make After a while, the executable file named as \"vesyla\" should appear in the build directory. Write the source code Please Check the Programming Guide . Compilation and simulation Use automatic test framework Warning Not available in public github repo A bash script called $VesylaRoot/autotest/testall.sh is provided to automatically test many testcases. Put all your testcases (matlab file) in $VesylaRoot/autotest/testcases/ directory, the script will test all of them and generate a report in the same directory. The script uses Robot Framework to manage the test process and to generate result. To run the test script, use command: . / testall Use automatic test script to test single testcase Script using test framework can test many testcases, but it will not print out detailed information. If you want to test single testcases, there is a provided bash script. It automatically compile your matlab file, prepare simulation environment and perform the matlab and RTL simulation, and finally compare the result. The script is called $VesylaRoot/autotest/run.sh . To use it, use the command below: . / run - c - f $PathToSiLagoFabric $PathToYourMatlabFile -c parameter try to compile Vesyla everytime in case Vesyla is modified, -f $PathToSiLagoFabric parameter indicates the RTL description of the SiLago fabric used for RTL simulation. After the script has been executed, a message SUCCESS or FAIL will show at the end to report whether the source file is correct or not. Manually testing Compile testcase To compile a testcase that is purely matlab script by using Vesyla, go to the build directory and run: . / vesyla - o $PathToOutputDirectory $PathToMatlabFile If instead, you want to compile a testcase that consists a template file and a data file, go to the build directory and run: . / vesyla - o $PathToOutputDirectory $PathToTemplate $PathToData Matlab simulation Vesyla generates a matlab simulation environment inside the output directory specified when you compile the testcase. Suppose your output directory is $OUTPUT , the matlab simulation environment is in $OUTPUT/filegen/sim_matlab . You can simulate the matlab model named as instrumenteed_code.m in matlab and get the register file data change event recording from the generated files after simulation. QuestaSim simulation Vesyla also generates environment for RTL simulation. It's in $OUTPUT/filegen/sim_vsim . However, you can't directly simulate it under QuestaSim because you need to specify the path to the DRRA+DiMArch fabric. You need to change the automatic script according to the actual fabric RTL location in order to make the simulation work. Please check the provided automatic test script $ROOT/autotest/run.sh to know more about how to add the fabric information. After QuestaSim simulation, a register file data change event recording will also be generated. Compare the register file data change A way to verify the correct behaviour of vesyla is to compare the register file data change event recording generated from both matlab and RTL simulation. A program for the exact purpose is created while vesyla is compiled. To run the program, go to build directory and use command: . / vesyla_verify $PathToMatlabRecording $PathToVsimRecording Important output files Warning Update later.","title":"Vesyla tutorial"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#vesyla-tutorial","text":"","title":"Vesyla tutorial"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#working-environment","text":"Operating System : Any modern Linux distribution Commercial Software : Matlab QuestaSim","title":"Working environment"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#file-structure","text":"$VesylaRoot/ |- src/ | |- all source files. | |- matlab_lib/ | |- matlab behavior models for DPU modes | |- config/ | |- some configuration files. | |- autotest/ | |- some scripts for auto testing. | |- some testcases. | |- build/ |- compilation working directory","title":"File structure"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#compile-vesyla","text":"First, install compilation tool chain. You need to use the correct package manager of your Linux distribution. The needed packages include: g++ (version 5 or above), make, cmake, boost liabrires, gecode. Here, we give the example command for Fedora Linux. sudo yum install g ++ make cmake boost-devel Gecode is not really necessary, Vesyla only use it for CP scheduling engine. However, you still need to install it. You can install it according to the installation instruction on the official website: https://www.gecode.org/ Then, you create working directory build . cd $VesylaRoot mkdir build cd build Next step is to generate makefile according to the CMake configuration file CMakeLists.txt. cmake .. Now, it's time to compile vesyla. make After a while, the executable file named as \"vesyla\" should appear in the build directory.","title":"Compile Vesyla"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#write-the-source-code","text":"Please Check the Programming Guide .","title":"Write the source code"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#compilation-and-simulation","text":"","title":"Compilation and simulation"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#use-automatic-test-framework","text":"Warning Not available in public github repo A bash script called $VesylaRoot/autotest/testall.sh is provided to automatically test many testcases. Put all your testcases (matlab file) in $VesylaRoot/autotest/testcases/ directory, the script will test all of them and generate a report in the same directory. The script uses Robot Framework to manage the test process and to generate result. To run the test script, use command: . / testall","title":"Use automatic test framework"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#use-automatic-test-script-to-test-single-testcase","text":"Script using test framework can test many testcases, but it will not print out detailed information. If you want to test single testcases, there is a provided bash script. It automatically compile your matlab file, prepare simulation environment and perform the matlab and RTL simulation, and finally compare the result. The script is called $VesylaRoot/autotest/run.sh . To use it, use the command below: . / run - c - f $PathToSiLagoFabric $PathToYourMatlabFile -c parameter try to compile Vesyla everytime in case Vesyla is modified, -f $PathToSiLagoFabric parameter indicates the RTL description of the SiLago fabric used for RTL simulation. After the script has been executed, a message SUCCESS or FAIL will show at the end to report whether the source file is correct or not.","title":"Use automatic test script to test single testcase"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#manually-testing","text":"","title":"Manually testing"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#compile-testcase","text":"To compile a testcase that is purely matlab script by using Vesyla, go to the build directory and run: . / vesyla - o $PathToOutputDirectory $PathToMatlabFile If instead, you want to compile a testcase that consists a template file and a data file, go to the build directory and run: . / vesyla - o $PathToOutputDirectory $PathToTemplate $PathToData","title":"Compile testcase"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#matlab-simulation","text":"Vesyla generates a matlab simulation environment inside the output directory specified when you compile the testcase. Suppose your output directory is $OUTPUT , the matlab simulation environment is in $OUTPUT/filegen/sim_matlab . You can simulate the matlab model named as instrumenteed_code.m in matlab and get the register file data change event recording from the generated files after simulation.","title":"Matlab simulation"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#questasim-simulation","text":"Vesyla also generates environment for RTL simulation. It's in $OUTPUT/filegen/sim_vsim . However, you can't directly simulate it under QuestaSim because you need to specify the path to the DRRA+DiMArch fabric. You need to change the automatic script according to the actual fabric RTL location in order to make the simulation work. Please check the provided automatic test script $ROOT/autotest/run.sh to know more about how to add the fabric information. After QuestaSim simulation, a register file data change event recording will also be generated.","title":"QuestaSim simulation"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#compare-the-register-file-data-change","text":"A way to verify the correct behaviour of vesyla is to compare the register file data change event recording generated from both matlab and RTL simulation. A program for the exact purpose is created while vesyla is compiled. To run the program, go to build directory and use command: . / vesyla_verify $PathToMatlabRecording $PathToVsimRecording","title":"Compare the register file data change"},{"location":"Docs/ToolChain/Vesyla/Tutorial/#important-output-files","text":"Warning Update later.","title":"Important output files"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/","text":"Instruction Set SRAM_R SRAM_W VWR_R VWR_W R1_R R1_W R2_R R2_W R3_R R3_W R4_R R4_W DPU SHFF_BLK SHFF_BIT","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#instruction-set","text":"","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#sram_r","text":"","title":"SRAM_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#sram_w","text":"","title":"SRAM_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#vwr_r","text":"","title":"VWR_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#vwr_w","text":"","title":"VWR_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r1_r","text":"","title":"R1_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r1_w","text":"","title":"R1_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r2_r","text":"","title":"R2_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r2_w","text":"","title":"R2_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r3_r","text":"","title":"R3_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r3_w","text":"","title":"R3_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r4_r","text":"","title":"R4_R"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#r4_w","text":"","title":"R4_W"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#dpu","text":"","title":"DPU"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#shff_blk","text":"","title":"SHFF_BLK"},{"location":"Docs/ToolChain/Vesyla2/InstructionSet/#shff_bit","text":"","title":"SHFF_BIT"},{"location":"Docs/ToolChain/Vesyla2/Macro/","text":"Macro Expansion Preprocess Veyla uses inja to implement the macro expansion preprocess. The program which performs the macro expansion is called VeExpand . This program will convert a template file to an output file with the help of a json formatted data file. In the template file, one can use macros which should be substituted by the variable values defined in the data file when the macro expansion is performed. The Grammar rule is based on the inja grammar . Program Execution Format Command $VESYLA_BIN /VeExpand -t template_file [ -d data_file ] -o output_file Arguments -t/-template: specify the template file. Default value is \"template.cpp\". -d/-data: specify the data file in json format. This argument is optional. -o/-output: specify the output file. This file should be a .cpp file that include the expanded model. Inja Grammar Basics Whatever content that is not specially marked in the template file will be considered as normal content and will be directly copied to the output file. To reference a simple variable, use {{ }} to wrap the varible name. All referenced variable should be defined in the data file. Example The example shows how to reference a simple variable. The template file: int x = {{VAR_A}}; The data file: { \"VAR_A\" : 2 } The redered output would be: int x = 2 ; To write a comment, use {# #} to wrap the commented words. Example The example shows how to write a commnet. The template file: int x = 2; {# This is a comment #}; The redered output would be: int x = 2 ; Inja supports complex types (like array or object) to be wrapped in {{ }} . Example The example shows how to reference a complex variable. The template file: int x = {{VAR_A/1}}; int y = {{VAR_B/one}}; The data file: { \"VAR_A\" : [ 2 , 3 , 4 ], \"VAR_B\" : { \"one\" : 1 , \"two\" : 2 } } The redered output would be: int x = 2 ; int y = 1 ; Bug The template int x = {{VAR_A/1}}; in above example is not working. It seems a bug of inja library. Commands Several commands are supported by inja to implement control flow. They include: branches and loops. The commands are wrapped in {% %} . Example The example shows how to implement a branch. The template file: {% if VAR_A <= 0 %}int x = 0; {% else %}int x = {{VAR_A}}; {% endif %} The data file: { \"VAR_A\" : 2 } The redered output would be: int x = 2 ; Example The example shows how to implement a loop. The template file: {% for i in range(3) %}int x = {{i}}; {% endfor %} The redered output would be: int x = 0 ; int x = 1 ; int x = 2 ; Pre-defined functions There are many pre-defined functions that are directly supported by inja. Example The example shows how to use pre-defined functions. The template file: Hello {{ world }}! Hello {{ upper(world) }}! Hello {{ lower(world) }}! {% for i in range(4) %}{{ loop/index1 }}{% endfor %} In total {{ length(guests) }} guests. {{ first(guests) }} was first. {{ last(guests) }} was last. Guest list in alphabetic order: {{ sort(guests) }}. {{ round(3.1415, 0) }} {{ round(3.1415, 3) }} {% if odd(a) %}{{a}} is odd! {% endif %} {% if even(a) %}{{a}} is even! {% endif %} {% if divisibleBy(a, 7) %}{{a}} is divisible by 7! {% endif %} Max of vec is {{ max(vec) }}. Min of vec is {{ min(vec) }}. \"m\" can be converted to number {{ int(m) }} \"n\" can be converted to number {{ float(n) }} {% if exists(\"node1\") and existsIn(node1, \"node2\") %}node1/node2 exists! The value is {{node1/node2}}{% endif %} The data file: { \"world\" : \"World\" , \"guests\" : [ \"Tom\" , \"Mike\" , \"John\" ], \"a\" : 42 , \"vec\" : [ 1 , 2 , 3 ], \"m\" : \"2\" , \"n\" : \"1.85\" , \"node1\" : { \"node2\" : 1 } } The redered output would be: Hello World ! Hello WORLD ! Hello world ! 1234 In total 3 guests . Tom was first . John was last . Guest list in alphabetic order : [ \"John\" , \"Mike\" , \"Tom\" ]. 3.0 3.142 42 is even ! 42 is divisible by 7 ! Max of vec is 3. Min of vec is 1. \"m\" can be converted to number 2 \"n\" can be converted to number 1.85 node1 / node2 exists ! The value is 1 There are also several pre-defined functions that are defined by VeExpand program. They are: add(a, b) sub(a, b) mul(a, b) div(a, b) pow(a, b)","title":"Macro Expansion Preprocess"},{"location":"Docs/ToolChain/Vesyla2/Macro/#macro-expansion-preprocess","text":"Veyla uses inja to implement the macro expansion preprocess. The program which performs the macro expansion is called VeExpand . This program will convert a template file to an output file with the help of a json formatted data file. In the template file, one can use macros which should be substituted by the variable values defined in the data file when the macro expansion is performed. The Grammar rule is based on the inja grammar .","title":"Macro Expansion Preprocess"},{"location":"Docs/ToolChain/Vesyla2/Macro/#program-execution-format","text":"","title":"Program Execution Format"},{"location":"Docs/ToolChain/Vesyla2/Macro/#command","text":"$VESYLA_BIN /VeExpand -t template_file [ -d data_file ] -o output_file","title":"Command"},{"location":"Docs/ToolChain/Vesyla2/Macro/#arguments","text":"-t/-template: specify the template file. Default value is \"template.cpp\". -d/-data: specify the data file in json format. This argument is optional. -o/-output: specify the output file. This file should be a .cpp file that include the expanded model.","title":"Arguments"},{"location":"Docs/ToolChain/Vesyla2/Macro/#inja-grammar","text":"","title":"Inja Grammar"},{"location":"Docs/ToolChain/Vesyla2/Macro/#basics","text":"Whatever content that is not specially marked in the template file will be considered as normal content and will be directly copied to the output file. To reference a simple variable, use {{ }} to wrap the varible name. All referenced variable should be defined in the data file. Example The example shows how to reference a simple variable. The template file: int x = {{VAR_A}}; The data file: { \"VAR_A\" : 2 } The redered output would be: int x = 2 ; To write a comment, use {# #} to wrap the commented words. Example The example shows how to write a commnet. The template file: int x = 2; {# This is a comment #}; The redered output would be: int x = 2 ; Inja supports complex types (like array or object) to be wrapped in {{ }} . Example The example shows how to reference a complex variable. The template file: int x = {{VAR_A/1}}; int y = {{VAR_B/one}}; The data file: { \"VAR_A\" : [ 2 , 3 , 4 ], \"VAR_B\" : { \"one\" : 1 , \"two\" : 2 } } The redered output would be: int x = 2 ; int y = 1 ; Bug The template int x = {{VAR_A/1}}; in above example is not working. It seems a bug of inja library.","title":"Basics"},{"location":"Docs/ToolChain/Vesyla2/Macro/#commands","text":"Several commands are supported by inja to implement control flow. They include: branches and loops. The commands are wrapped in {% %} . Example The example shows how to implement a branch. The template file: {% if VAR_A <= 0 %}int x = 0; {% else %}int x = {{VAR_A}}; {% endif %} The data file: { \"VAR_A\" : 2 } The redered output would be: int x = 2 ; Example The example shows how to implement a loop. The template file: {% for i in range(3) %}int x = {{i}}; {% endfor %} The redered output would be: int x = 0 ; int x = 1 ; int x = 2 ;","title":"Commands"},{"location":"Docs/ToolChain/Vesyla2/Macro/#pre-defined-functions","text":"There are many pre-defined functions that are directly supported by inja. Example The example shows how to use pre-defined functions. The template file: Hello {{ world }}! Hello {{ upper(world) }}! Hello {{ lower(world) }}! {% for i in range(4) %}{{ loop/index1 }}{% endfor %} In total {{ length(guests) }} guests. {{ first(guests) }} was first. {{ last(guests) }} was last. Guest list in alphabetic order: {{ sort(guests) }}. {{ round(3.1415, 0) }} {{ round(3.1415, 3) }} {% if odd(a) %}{{a}} is odd! {% endif %} {% if even(a) %}{{a}} is even! {% endif %} {% if divisibleBy(a, 7) %}{{a}} is divisible by 7! {% endif %} Max of vec is {{ max(vec) }}. Min of vec is {{ min(vec) }}. \"m\" can be converted to number {{ int(m) }} \"n\" can be converted to number {{ float(n) }} {% if exists(\"node1\") and existsIn(node1, \"node2\") %}node1/node2 exists! The value is {{node1/node2}}{% endif %} The data file: { \"world\" : \"World\" , \"guests\" : [ \"Tom\" , \"Mike\" , \"John\" ], \"a\" : 42 , \"vec\" : [ 1 , 2 , 3 ], \"m\" : \"2\" , \"n\" : \"1.85\" , \"node1\" : { \"node2\" : 1 } } The redered output would be: Hello World ! Hello WORLD ! Hello world ! 1234 In total 3 guests . Tom was first . John was last . Guest list in alphabetic order : [ \"John\" , \"Mike\" , \"Tom\" ]. 3.0 3.142 42 is even ! 42 is divisible by 7 ! Max of vec is 3. Min of vec is 1. \"m\" can be converted to number 2 \"n\" can be converted to number 1.85 node1 / node2 exists ! The value is 1 There are also several pre-defined functions that are defined by VeExpand program. They are: add(a, b) sub(a, b) mul(a, b) div(a, b) pow(a, b)","title":"Pre-defined functions"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/","text":"Programming Guide Top-level Function Declaration The top-level function is always defined as following: void model_l2 () { ... } The function name model_l2 means this is the 2 nd level of computation model. The level 1 model is a free-style C++ model that defines the desired computation behavior. The level 2 model is a untimed C model that directly reflects the hardware mapping. The level 3 model is cycle-accurate model defined in either HDL or systemC. The compiler creates cycle-accurate configuration that can be co-simulated with level 3 model. The input of the compiler is level 2 model. Global Variables The global variables model the SRAM, the VWRs and the internal registers inside each DPU. Once the architecture is defined, these global variables is also defined. The global variables are: SRAM used as I/O: __sram_vector_0__ VWRs: __vwr_vector_0__ __vwr_vector_1__ __vwr_vector_2__ ... REGISTERS inside DPU: __reg_vector_r1_0__ __reg_vector_r2_0__ __reg_vector_r3_0__ __reg_vector_r4_0__ __reg_vector_r1_1__ __reg_vector_r2_2__ __reg_vector_r3_3__ __reg_vector_r4_4__ ... Warning The idea of defining VWRs and Registers as global variables might not be a good idea. It could be replaced by binding pragma associated with temporary variable declaration. Pre-defined Primitive Functions Data Transfer // SRAM -> VWR void read_sram_to_vwr ( SramVector sram_name , int sram_addr , VwrVector & vwr_name , int shuffle_mode ); // VWR -> SRAM void write_sram_from_vwr ( SramVector & sram_name , int sram_addr , VwrVector vwr_name , int shuffle_mode ); // Read VWR content in parellel void read_vwr ( VwrVector vwr_name , RegVector & r0 , RegVector & r1 , ...); // Write VWR content in parellel void write_vwr ( VwrVector & vwr_name , RegVector r0 , RegVector r1 , ...); Computation // DPU operation r0+r1->r2 void dpu_add ( RegVector r0 , RegVector r1 , RegVector & r2 ); // DPU operation r0*r1->r2 void dpu_mul ( RegVector r0 , RegVector r1 , RegVector & r2 ); // Shuffle in DPU: shuffle(r0) -> r1 void shuffle ( RegVector r0 , RegVector & r1 ); Example Here we show a program that implement a simple vector addition. Vector A , B and C are both 16-word vector. Each word is 16-bit. They vector addition is described by equation: C = A + B . SRAM Organization A[00], A[01], ..., A[07], A[08], A[09], ..., A[15], B[00], B[01], ..., B[07], B[08], B[09], ..., B[15], C[00], C[01], ..., C[07], C[08], C[09], ..., C[15], Architecture Definiation #define ARCH_SRAM_NUM 1 #define ARCH_VWR_NUM 2 #define ARCH_DPU_NUM 8 #define ARCH_SRAM_CHUNK_SIZE 128 #define ARCH_VWR_CHUNK_SIZE 16 #define ARCH_REG_CHUNK_SIZE 16 #define ARCH_SRAM_VECTOR_SIZE 6 #define ARCH_VWR_VECTOR_SIZE 8 #define ARCH_REG_VECTOR_SIZE 1 This defination defines the following architecture: SRAM: [[128b], [128b], [128b], [128b], [128b], [128b]] VWR: [[16b], [16b], [16b], [16b], [16b], [16b], [16b], [16b]] Registers inside DPU: [[16b]] Algorithm void model_l2 () { for ( int i = 0 ; i < 2 ; i ++ ){ // Read A and B vector from SRAM to VWR read_sram_to_vwr ( __sram_vector_0__ , i , __vwr_vector_0__ ); read_sram_to_vwr ( __sram_vector_0__ , i + 2 , __vwr_vector_1__ ); // Create temp variables RegVector _x0 , _x1 , _x2 , _x3 , _x4 , _x5 , _x6 , _x7 ; RegVector _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ; // Read A in VWR0 to R1 registers read_vwr ( __vwr_vector_0__ , _x0 , _x1 , _x2 , _x3 , _x4 , _x5 , _x6 , _x7 ); write_r1 ( __reg_vector_r1_0__ , _x0 ); write_r1 ( __reg_vector_r1_1__ , _x1 ); write_r1 ( __reg_vector_r1_2__ , _x2 ); write_r1 ( __reg_vector_r1_3__ , _x3 ); write_r1 ( __reg_vector_r1_4__ , _x4 ); write_r1 ( __reg_vector_r1_5__ , _x5 ); write_r1 ( __reg_vector_r1_6__ , _x6 ); write_r1 ( __reg_vector_r1_7__ , _x7 ); // Read B in VWR1 to temp variables read_vwr ( __vwr_vector_1__ , _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ); // Preform Addition read_r1 ( __reg_vector_r1_0__ , _x0 ); read_r1 ( __reg_vector_r1_1__ , _x1 ); read_r1 ( __reg_vector_r1_2__ , _x2 ); read_r1 ( __reg_vector_r1_3__ , _x3 ); read_r1 ( __reg_vector_r1_4__ , _x4 ); read_r1 ( __reg_vector_r1_5__ , _x5 ); read_r1 ( __reg_vector_r1_6__ , _x6 ); read_r1 ( __reg_vector_r1_7__ , _x7 ); dpu_add ( _x0 , _y0 , _y0 ); dpu_add ( _x1 , _y1 , _y1 ); dpu_add ( _x2 , _y2 , _y2 ); dpu_add ( _x3 , _y3 , _y3 ); dpu_add ( _x4 , _y4 , _y4 ); dpu_add ( _x5 , _y5 , _y5 ); dpu_add ( _x6 , _y6 , _y6 ); dpu_add ( _x7 , _y7 , _y7 ); // Write back the result from temp variables to VWR0, this is C vector write_vwr ( __vwr_vector_0__ , _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ); // Write back C vector to SRAM write_sram_from_vwr ( ___sram_vector_0__ , i + 4 , __vwr_vector_0__ ); } }","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#programming-guide","text":"","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#top-level-function-declaration","text":"The top-level function is always defined as following: void model_l2 () { ... } The function name model_l2 means this is the 2 nd level of computation model. The level 1 model is a free-style C++ model that defines the desired computation behavior. The level 2 model is a untimed C model that directly reflects the hardware mapping. The level 3 model is cycle-accurate model defined in either HDL or systemC. The compiler creates cycle-accurate configuration that can be co-simulated with level 3 model. The input of the compiler is level 2 model.","title":"Top-level Function Declaration"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#global-variables","text":"The global variables model the SRAM, the VWRs and the internal registers inside each DPU. Once the architecture is defined, these global variables is also defined. The global variables are: SRAM used as I/O: __sram_vector_0__ VWRs: __vwr_vector_0__ __vwr_vector_1__ __vwr_vector_2__ ... REGISTERS inside DPU: __reg_vector_r1_0__ __reg_vector_r2_0__ __reg_vector_r3_0__ __reg_vector_r4_0__ __reg_vector_r1_1__ __reg_vector_r2_2__ __reg_vector_r3_3__ __reg_vector_r4_4__ ... Warning The idea of defining VWRs and Registers as global variables might not be a good idea. It could be replaced by binding pragma associated with temporary variable declaration.","title":"Global Variables"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#pre-defined-primitive-functions","text":"","title":"Pre-defined Primitive Functions"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#data-transfer","text":"// SRAM -> VWR void read_sram_to_vwr ( SramVector sram_name , int sram_addr , VwrVector & vwr_name , int shuffle_mode ); // VWR -> SRAM void write_sram_from_vwr ( SramVector & sram_name , int sram_addr , VwrVector vwr_name , int shuffle_mode ); // Read VWR content in parellel void read_vwr ( VwrVector vwr_name , RegVector & r0 , RegVector & r1 , ...); // Write VWR content in parellel void write_vwr ( VwrVector & vwr_name , RegVector r0 , RegVector r1 , ...);","title":"Data Transfer"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#computation","text":"// DPU operation r0+r1->r2 void dpu_add ( RegVector r0 , RegVector r1 , RegVector & r2 ); // DPU operation r0*r1->r2 void dpu_mul ( RegVector r0 , RegVector r1 , RegVector & r2 ); // Shuffle in DPU: shuffle(r0) -> r1 void shuffle ( RegVector r0 , RegVector & r1 );","title":"Computation"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#example","text":"Here we show a program that implement a simple vector addition. Vector A , B and C are both 16-word vector. Each word is 16-bit. They vector addition is described by equation: C = A + B .","title":"Example"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#sram-organization","text":"A[00], A[01], ..., A[07], A[08], A[09], ..., A[15], B[00], B[01], ..., B[07], B[08], B[09], ..., B[15], C[00], C[01], ..., C[07], C[08], C[09], ..., C[15],","title":"SRAM Organization"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#architecture-definiation","text":"#define ARCH_SRAM_NUM 1 #define ARCH_VWR_NUM 2 #define ARCH_DPU_NUM 8 #define ARCH_SRAM_CHUNK_SIZE 128 #define ARCH_VWR_CHUNK_SIZE 16 #define ARCH_REG_CHUNK_SIZE 16 #define ARCH_SRAM_VECTOR_SIZE 6 #define ARCH_VWR_VECTOR_SIZE 8 #define ARCH_REG_VECTOR_SIZE 1 This defination defines the following architecture: SRAM: [[128b], [128b], [128b], [128b], [128b], [128b]] VWR: [[16b], [16b], [16b], [16b], [16b], [16b], [16b], [16b]] Registers inside DPU: [[16b]]","title":"Architecture Definiation"},{"location":"Docs/ToolChain/Vesyla2/ProgrammingGuide/#algorithm","text":"void model_l2 () { for ( int i = 0 ; i < 2 ; i ++ ){ // Read A and B vector from SRAM to VWR read_sram_to_vwr ( __sram_vector_0__ , i , __vwr_vector_0__ ); read_sram_to_vwr ( __sram_vector_0__ , i + 2 , __vwr_vector_1__ ); // Create temp variables RegVector _x0 , _x1 , _x2 , _x3 , _x4 , _x5 , _x6 , _x7 ; RegVector _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ; // Read A in VWR0 to R1 registers read_vwr ( __vwr_vector_0__ , _x0 , _x1 , _x2 , _x3 , _x4 , _x5 , _x6 , _x7 ); write_r1 ( __reg_vector_r1_0__ , _x0 ); write_r1 ( __reg_vector_r1_1__ , _x1 ); write_r1 ( __reg_vector_r1_2__ , _x2 ); write_r1 ( __reg_vector_r1_3__ , _x3 ); write_r1 ( __reg_vector_r1_4__ , _x4 ); write_r1 ( __reg_vector_r1_5__ , _x5 ); write_r1 ( __reg_vector_r1_6__ , _x6 ); write_r1 ( __reg_vector_r1_7__ , _x7 ); // Read B in VWR1 to temp variables read_vwr ( __vwr_vector_1__ , _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ); // Preform Addition read_r1 ( __reg_vector_r1_0__ , _x0 ); read_r1 ( __reg_vector_r1_1__ , _x1 ); read_r1 ( __reg_vector_r1_2__ , _x2 ); read_r1 ( __reg_vector_r1_3__ , _x3 ); read_r1 ( __reg_vector_r1_4__ , _x4 ); read_r1 ( __reg_vector_r1_5__ , _x5 ); read_r1 ( __reg_vector_r1_6__ , _x6 ); read_r1 ( __reg_vector_r1_7__ , _x7 ); dpu_add ( _x0 , _y0 , _y0 ); dpu_add ( _x1 , _y1 , _y1 ); dpu_add ( _x2 , _y2 , _y2 ); dpu_add ( _x3 , _y3 , _y3 ); dpu_add ( _x4 , _y4 , _y4 ); dpu_add ( _x5 , _y5 , _y5 ); dpu_add ( _x6 , _y6 , _y6 ); dpu_add ( _x7 , _y7 , _y7 ); // Write back the result from temp variables to VWR0, this is C vector write_vwr ( __vwr_vector_0__ , _y0 , _y1 , _y2 , _y3 , _y4 , _y5 , _y6 , _y7 ); // Write back C vector to SRAM write_sram_from_vwr ( ___sram_vector_0__ , i + 4 , __vwr_vector_0__ ); } }","title":"Algorithm"},{"location":"Docs/ToolChain/Vesyla2/Tutorial/","text":"Vesyla tutorial Warning Documentation is not complete!","title":"Vesyla tutorial"},{"location":"Docs/ToolChain/Vesyla2/Tutorial/#vesyla-tutorial","text":"Warning Documentation is not complete!","title":"Vesyla tutorial"}]}