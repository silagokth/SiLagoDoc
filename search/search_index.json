{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SiLago Documentation Abstract This website hosts all the documentation of SiLago project. Repos Warning The repos are private for now! Fabric Repo Vesyla-suite Repo Quick Start Tutorials MkDoc Tutorial Vesyla Tutorial for DRRA Vesyla Tutorial for RISC-V Vesyla programming guide Guidlines C++ RTL","title":"Home"},{"location":"#welcome-to-silago-documentation","text":"Abstract This website hosts all the documentation of SiLago project.","title":"Welcome to SiLago Documentation"},{"location":"#repos","text":"Warning The repos are private for now! Fabric Repo Vesyla-suite Repo","title":"Repos"},{"location":"#quick-start-tutorials","text":"MkDoc Tutorial Vesyla Tutorial for DRRA Vesyla Tutorial for RISC-V Vesyla programming guide","title":"Quick Start Tutorials"},{"location":"#guidlines","text":"C++ RTL","title":"Guidlines"},{"location":"About/About/","text":"About SiLago Team Members Name Email Role Jordi Altayo Gonzalez jordiag@kth.se PhD student Ahmed Hemani hemani@kth.se Supervisor Bj\u00f6rn Lindqvist bjolin2@kth.se PhD student Sofia Olsson sools@kth.se PhD student Ritika Ratnu ratnu@kth.se PhD student Ivan Sraichuk sraichuk@kth.se PhD student Dimitrios Stathis stathis@kth.se Postdoc Saba Yousefzadeh sabay@kth.se PhD student Yu Yang yuyang2@kth.se Postdoc","title":"About"},{"location":"About/About/#about","text":"","title":"About"},{"location":"About/About/#silago-team-members","text":"Name Email Role Jordi Altayo Gonzalez jordiag@kth.se PhD student Ahmed Hemani hemani@kth.se Supervisor Bj\u00f6rn Lindqvist bjolin2@kth.se PhD student Sofia Olsson sools@kth.se PhD student Ritika Ratnu ratnu@kth.se PhD student Ivan Sraichuk sraichuk@kth.se PhD student Dimitrios Stathis stathis@kth.se Postdoc Saba Yousefzadeh sabay@kth.se PhD student Yu Yang yuyang2@kth.se Postdoc","title":"SiLago Team Members"},{"location":"About/License/","text":"License This documentation is licensed under GNU Free Documentation License . A full legal document is listed below. You can also check the license contents from the official website: https://www.gnu.org/licenses/fdl.html GNU Free Documentation License Version 1.3, 3 November 2008 Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc. <https://fsf.org/> Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. 0. PREAMBLE The purpose of this License is to make a manual, textbook, or other functional and useful document \"free\" in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others. This License is a kind of \"copyleft\", which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software. We have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference. 1. APPLICABILITY AND DEFINITIONS This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The \"Document\", below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as \"you\". You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law. A \"Modified Version\" of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language. A \"Secondary Section\" is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document's overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them. The \"Invariant Sections\" are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none. The \"Cover Texts\" are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words. A \"Transparent\" copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not \"Transparent\" is called \"Opaque\". Examples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only. The \"Title Page\" means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, \"Title Page\" means the text near the most prominent appearance of the work's title, preceding the beginning of the body of the text. The \"publisher\" means any person or entity that distributes copies of the Document to the public. A section \"Entitled XYZ\" means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as \"Acknowledgements\", \"Dedications\", \"Endorsements\", or \"History\".) To \"Preserve the Title\" of such a section when you modify the Document means that it remains a section \"Entitled XYZ\" according to this definition. The Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License. 2. VERBATIM COPYING You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3. You may also lend copies, under the same conditions stated above, and you may publicly display copies. 3. COPYING IN QUANTITY If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document's license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects. If the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages. If you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public. It is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document. 4. MODIFICATIONS You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version: A. Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission. B. List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement. C. State on the Title page the name of the publisher of the Modified Version, as the publisher. D. Preserve all the copyright notices of the Document. E. Add an appropriate copyright notice for your modifications adjacent to the other copyright notices. F. Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below. G. Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document's license notice. H. Include an unaltered copy of this License. I. Preserve the section Entitled \"History\", Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled \"History\" in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence. J. Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the \"History\" section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission. K. For any section Entitled \"Acknowledgements\" or \"Dedications\", Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein. L. Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles. M. Delete any section Entitled \"Endorsements\". Such a section may not be included in the Modified Version. N. Do not retitle any existing section to be Entitled \"Endorsements\" or to conflict in title with any Invariant Section. O. Preserve any Warranty Disclaimers. If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version's license notice. These titles must be distinct from any other section titles. You may add a section Entitled \"Endorsements\", provided it contains nothing but endorsements of your Modified Version by various parties--for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard. You may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one. The author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version. 5. COMBINING DOCUMENTS You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers. The combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work. In the combination, you must combine any sections Entitled \"History\" in the various original documents, forming one section Entitled \"History\"; likewise combine any sections Entitled \"Acknowledgements\", and any sections Entitled \"Dedications\". You must delete all sections Entitled \"Endorsements\". 6. COLLECTIONS OF DOCUMENTS You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects. You may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document. 7. AGGREGATION WITH INDEPENDENT WORKS A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the copyright resulting from the compilation is not used to limit the legal rights of the compilation's users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document. If the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document's Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate. 8. TRANSLATION Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail. If a section in the Document is Entitled \"Acknowledgements\", \"Dedications\", or \"History\", the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title. 9. TERMINATION You may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your rights under this License. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a copy of some or all of the same material does not give you any rights to use it. 10. FUTURE REVISIONS OF THIS LICENSE The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See https://www.gnu.org/licenses/. Each version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can decide which future versions of this License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Document. 11. RELICENSING \"Massive Multiauthor Collaboration Site\" (or \"MMC Site\") means any World Wide Web server that publishes copyrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody can edit is an example of such a server. A \"Massive Multiauthor Collaboration\" (or \"MMC\") contained in the site means any set of copyrightable works thus published on the MMC site. \"CC-BY-SA\" means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons Corporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as future copyleft versions of that license published by that same organization. \"Incorporate\" means to publish or republish a Document, in whole or in part, as part of another Document. An MMC is \"eligible for relicensing\" if it is licensed under this License, and if all works that were first published under this License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1) had no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008. The operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any time before August 1, 2009, provided the MMC is eligible for relicensing. ADDENDUM: How to use this License for your documents To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page: Copyright (c) YEAR YOUR NAME. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled \"GNU Free Documentation License\". If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the \"with...Texts.\" line with this: with the Invariant Sections being LIST THEIR TITLES, with the Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST. If you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation. If your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.","title":"License"},{"location":"About/License/#license","text":"This documentation is licensed under GNU Free Documentation License . A full legal document is listed below. You can also check the license contents from the official website: https://www.gnu.org/licenses/fdl.html GNU Free Documentation License Version 1.3, 3 November 2008 Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc. <https://fsf.org/> Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. 0. PREAMBLE The purpose of this License is to make a manual, textbook, or other functional and useful document \"free\" in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others. This License is a kind of \"copyleft\", which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software. We have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference. 1. APPLICABILITY AND DEFINITIONS This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The \"Document\", below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as \"you\". You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law. A \"Modified Version\" of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language. A \"Secondary Section\" is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document's overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them. The \"Invariant Sections\" are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none. The \"Cover Texts\" are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words. A \"Transparent\" copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not \"Transparent\" is called \"Opaque\". Examples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only. The \"Title Page\" means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, \"Title Page\" means the text near the most prominent appearance of the work's title, preceding the beginning of the body of the text. The \"publisher\" means any person or entity that distributes copies of the Document to the public. A section \"Entitled XYZ\" means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as \"Acknowledgements\", \"Dedications\", \"Endorsements\", or \"History\".) To \"Preserve the Title\" of such a section when you modify the Document means that it remains a section \"Entitled XYZ\" according to this definition. The Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License. 2. VERBATIM COPYING You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3. You may also lend copies, under the same conditions stated above, and you may publicly display copies. 3. COPYING IN QUANTITY If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document's license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects. If the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages. If you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public. It is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document. 4. MODIFICATIONS You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version: A. Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission. B. List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement. C. State on the Title page the name of the publisher of the Modified Version, as the publisher. D. Preserve all the copyright notices of the Document. E. Add an appropriate copyright notice for your modifications adjacent to the other copyright notices. F. Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below. G. Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document's license notice. H. Include an unaltered copy of this License. I. Preserve the section Entitled \"History\", Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled \"History\" in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence. J. Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the \"History\" section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission. K. For any section Entitled \"Acknowledgements\" or \"Dedications\", Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein. L. Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles. M. Delete any section Entitled \"Endorsements\". Such a section may not be included in the Modified Version. N. Do not retitle any existing section to be Entitled \"Endorsements\" or to conflict in title with any Invariant Section. O. Preserve any Warranty Disclaimers. If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version's license notice. These titles must be distinct from any other section titles. You may add a section Entitled \"Endorsements\", provided it contains nothing but endorsements of your Modified Version by various parties--for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard. You may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one. The author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version. 5. COMBINING DOCUMENTS You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers. The combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work. In the combination, you must combine any sections Entitled \"History\" in the various original documents, forming one section Entitled \"History\"; likewise combine any sections Entitled \"Acknowledgements\", and any sections Entitled \"Dedications\". You must delete all sections Entitled \"Endorsements\". 6. COLLECTIONS OF DOCUMENTS You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects. You may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document. 7. AGGREGATION WITH INDEPENDENT WORKS A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an \"aggregate\" if the copyright resulting from the compilation is not used to limit the legal rights of the compilation's users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document. If the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document's Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate. 8. TRANSLATION Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail. If a section in the Document is Entitled \"Acknowledgements\", \"Dedications\", or \"History\", the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title. 9. TERMINATION You may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your rights under this License. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a copy of some or all of the same material does not give you any rights to use it. 10. FUTURE REVISIONS OF THIS LICENSE The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See https://www.gnu.org/licenses/. Each version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License \"or any later version\" applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can decide which future versions of this License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Document. 11. RELICENSING \"Massive Multiauthor Collaboration Site\" (or \"MMC Site\") means any World Wide Web server that publishes copyrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody can edit is an example of such a server. A \"Massive Multiauthor Collaboration\" (or \"MMC\") contained in the site means any set of copyrightable works thus published on the MMC site. \"CC-BY-SA\" means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons Corporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as future copyleft versions of that license published by that same organization. \"Incorporate\" means to publish or republish a Document, in whole or in part, as part of another Document. An MMC is \"eligible for relicensing\" if it is licensed under this License, and if all works that were first published under this License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1) had no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008. The operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any time before August 1, 2009, provided the MMC is eligible for relicensing. ADDENDUM: How to use this License for your documents To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page: Copyright (c) YEAR YOUR NAME. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled \"GNU Free Documentation License\". If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the \"with...Texts.\" line with this: with the Invariant Sections being LIST THEIR TITLES, with the Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST. If you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation. If your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.","title":"License"},{"location":"Docs/Application/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Application/SiLagoDSP/Fast-Fourier-Projection/","text":"Warning Documentation is not complete!","title":"Fast Fourier Projection"},{"location":"Docs/Fabric/Overview/","text":"Overview Please check the specification of DRRA: DRRA Specification","title":"Overview"},{"location":"Docs/Fabric/Overview/#overview","text":"Please check the specification of DRRA: DRRA Specification","title":"Overview"},{"location":"Docs/Fabric/Style-guide/","text":"Style Guide VHDL Style","title":"Style Guide"},{"location":"Docs/Fabric/Style-guide/#style-guide","text":"","title":"Style Guide"},{"location":"Docs/Fabric/Style-guide/#vhdl-style","text":"","title":"VHDL Style"},{"location":"Docs/Fabric/DRRA/RACCU/","text":"Run-time Address Constraint Computing Unit Function Run-time Address Constraint Computing Unit (RACCU) is used for computing address constraint for Address Generation Unit (AGU). AGU can deal with maximum 2-level affine address function. Affine address function is a function that can be expressed by equation below: \\begin{align} y = ax+b \\end{align} \\begin{align} y = ax+b \\end{align} where a and b are constraints. 2-level affine address function can then be expressed as: \\begin{align} y = c(ax+b)+d \\end{align} \\begin{align} y = c(ax+b)+d \\end{align} where a , b , c and d are constraints. Address constraint can be immediate value or a number generated at run-time according to a given function. The resources which deal with the constraint generation is the RACCU. Specification Info Old RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints and temporary variables will be stored inside this register file. The data register is always exposed to Sequencer to read. Another register file in RACCU is used to manage the loops. The depth depends on maximum nested loop RACCU can handle, by default it's 4 . Each entry in loop management register file has 3 fields: Loop id Loop counter Loop end flag The loop id will be identify the entry location in the loop management register file. Loop counter will be initialized by the first LOOP_HEADER instruction and be changed periodically by LOOP_TAIL instruction. The comparison between the loop conter and loop bound is carried out by LOOP_HEADER instruction. If they are equal, loop end flag will be set to true and exits the loop. RACCU has a computation unit which is similar to a mini-DPU. It has 5 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_ADD_WITH_LOOP_INDEX Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Info New RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints, temporary variables and loop iterators will be stored inside this register file. The data register is always exposed to Sequencer to read. Loop iterator will be assigned from the beginning of the register file according to the order of loop while RACCU variables will be assigned from the end of register file. Once the loop iterators or the RACCU variables are not needed, they can be freed by moving the stack/heap pointer 1 position back. The assignment of register location is managed by the Vesyla compiler. RACCU has a computation unit which is similar to a mini-DPU. It has 8 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_LOG2 Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Related Instructions RACCU instruction LOOP_HEADER instruction LOOP_TAIL instruction Interface Info Old RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output loop_reg out raccu_loop_array_ty Loop register output Info New RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output","title":"Run-time Address Constraint Computing Unit"},{"location":"Docs/Fabric/DRRA/RACCU/#run-time-address-constraint-computing-unit","text":"","title":"Run-time Address Constraint Computing Unit"},{"location":"Docs/Fabric/DRRA/RACCU/#function","text":"Run-time Address Constraint Computing Unit (RACCU) is used for computing address constraint for Address Generation Unit (AGU). AGU can deal with maximum 2-level affine address function. Affine address function is a function that can be expressed by equation below: \\begin{align} y = ax+b \\end{align} \\begin{align} y = ax+b \\end{align} where a and b are constraints. 2-level affine address function can then be expressed as: \\begin{align} y = c(ax+b)+d \\end{align} \\begin{align} y = c(ax+b)+d \\end{align} where a , b , c and d are constraints. Address constraint can be immediate value or a number generated at run-time according to a given function. The resources which deal with the constraint generation is the RACCU.","title":"Function"},{"location":"Docs/Fabric/DRRA/RACCU/#specification","text":"Info Old RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints and temporary variables will be stored inside this register file. The data register is always exposed to Sequencer to read. Another register file in RACCU is used to manage the loops. The depth depends on maximum nested loop RACCU can handle, by default it's 4 . Each entry in loop management register file has 3 fields: Loop id Loop counter Loop end flag The loop id will be identify the entry location in the loop management register file. Loop counter will be initialized by the first LOOP_HEADER instruction and be changed periodically by LOOP_TAIL instruction. The comparison between the loop conter and loop bound is carried out by LOOP_HEADER instruction. If they are equal, loop end flag will be set to true and exits the loop. RACCU has a computation unit which is similar to a mini-DPU. It has 5 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_ADD_WITH_LOOP_INDEX Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin. Info New RACCU implementation. RACCU is a unit inside Sequencer. It has a register file of default depth N=8 . Contraints, temporary variables and loop iterators will be stored inside this register file. The data register is always exposed to Sequencer to read. Loop iterator will be assigned from the beginning of the register file according to the order of loop while RACCU variables will be assigned from the end of register file. Once the loop iterators or the RACCU variables are not needed, they can be freed by moving the stack/heap pointer 1 position back. The assignment of register location is managed by the Vesyla compiler. RACCU has a computation unit which is similar to a mini-DPU. It has 8 working modes. All of them are binary operations. They are: (0) RACCU_MODE_IDLE (1) RACCU_MODE_LOOP_H (2) RACCU_MODE_LOOP_T (3) RACCU_MODE_ADD (4) RACCU_MODE_SUB (5) RACCU_MODE_SHIFT_L (6) RACCU_MODE_SHIFT_R (7) RACCU_MODE_LOG2 Operands of each mode can be either immediate value from instruction or data from RACCU register whoes address is specified by the instruction. A bit is used to distinguish the operand origin.","title":"Specification"},{"location":"Docs/Fabric/DRRA/RACCU/#related-instructions","text":"","title":"Related Instructions"},{"location":"Docs/Fabric/DRRA/RACCU/#raccu-instruction","text":"","title":"RACCU instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#loop_header-instruction","text":"","title":"LOOP_HEADER instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#loop_tail-instruction","text":"","title":"LOOP_TAIL instruction"},{"location":"Docs/Fabric/DRRA/RACCU/#interface","text":"Info Old RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output loop_reg out raccu_loop_array_ty Loop register output Info New RACCU implementation. Signal I/O Type Description clk in std_logic Clock rst in std_logic Reset, active low op1_sd in std_logic Type of operand 1, 0-immediate, 1-reference op1 in std_logic_vector 8bits Operand 1 value / Operand 1 address op2_sd in std_logic Type of operand 2, 0-immediate, 1-reference op2 in std_logic_vector 8bits Operand 2 value / Operand 2 address cfg_mode in std_logic_vector 3bits Mode of RACCU computation unit result_addr in std_logic_vector 3bits Result address in data_reg data_reg out raccu_reg_out_ty Data register output","title":"Interface"},{"location":"Docs/Fabric/RISCV/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/BLAS/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/BLAS/L3/gemm/","text":"GEMM Function gemm computes a matrix-matrix product with general matrices. The gemm routines compute a scalar-matrix-matrix product and add the result to a scalar-matrix product, with general matrices. The operation is defined as C \\leftarrow \\alpha *A*B + \\beta *C C \\leftarrow \\alpha *A*B + \\beta *C where: \\alpha \\alpha and \\beta \\beta are scalars, A A , B B and C C are matrices: A A is an m-by-k matrix, B B is a k-by-n matrix, C C is an m-by-n matrix. Parameters m m : The number of rows in A A and C C . k k : The number of columns in A A and the number of rows in B B . n n : The number of columns in C C . Mapping One-Column Mapping Memory Mapping m m , k k and n n are multiple of DiMArch row width (16). A A and C C stored in DiMArch in row-major fashion and B B stored in DiMArch in col-major fashion. The first 16 words in register file in DRRA cell [0,0] is reserved for elements in A A . The second half register file (16 words) is reserved for elements in B B . The first 16 words in register file in DRRA cell [1,0] is for elements in C C . The register space for A A is also used temporarily for storing \\alpha \\alpha and \\beta \\beta . One of the internal register in DRRA cell [0,0] is also used for holding \\alpha \\alpha in order to perform the axpy() function. Function Mapping Scaling Cost Metrics","title":"GEMM"},{"location":"Docs/Library/BLAS/L3/gemm/#gemm","text":"","title":"GEMM"},{"location":"Docs/Library/BLAS/L3/gemm/#function","text":"gemm computes a matrix-matrix product with general matrices. The gemm routines compute a scalar-matrix-matrix product and add the result to a scalar-matrix product, with general matrices. The operation is defined as C \\leftarrow \\alpha *A*B + \\beta *C C \\leftarrow \\alpha *A*B + \\beta *C where: \\alpha \\alpha and \\beta \\beta are scalars, A A , B B and C C are matrices: A A is an m-by-k matrix, B B is a k-by-n matrix, C C is an m-by-n matrix.","title":"Function"},{"location":"Docs/Library/BLAS/L3/gemm/#parameters","text":"m m : The number of rows in A A and C C . k k : The number of columns in A A and the number of rows in B B . n n : The number of columns in C C .","title":"Parameters"},{"location":"Docs/Library/BLAS/L3/gemm/#mapping","text":"","title":"Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#one-column-mapping","text":"","title":"One-Column Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#memory-mapping","text":"m m , k k and n n are multiple of DiMArch row width (16). A A and C C stored in DiMArch in row-major fashion and B B stored in DiMArch in col-major fashion. The first 16 words in register file in DRRA cell [0,0] is reserved for elements in A A . The second half register file (16 words) is reserved for elements in B B . The first 16 words in register file in DRRA cell [1,0] is for elements in C C . The register space for A A is also used temporarily for storing \\alpha \\alpha and \\beta \\beta . One of the internal register in DRRA cell [0,0] is also used for holding \\alpha \\alpha in order to perform the axpy() function.","title":"Memory Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#function-mapping","text":"","title":"Function Mapping"},{"location":"Docs/Library/BLAS/L3/gemm/#scaling","text":"","title":"Scaling"},{"location":"Docs/Library/BLAS/L3/gemm/#cost-metrics","text":"","title":"Cost Metrics"},{"location":"Docs/Library/FFT/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/Interleaver/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/Library/NN/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/ToolChain/Overview/","text":"Toolchain for SiLago Platform Application-Level Synthesis (ALS) Sylva is the ALS tool for SiLago platform. High-Level Synthesis (HLS) Vesyla-suite is the HLS tool for DRRA-based SiLago platform. It contains multiple tools, such as vs-vesyla , vs-manas , vs-alimpsim , etc. It also contains a compiler for IMEC architecture called vs-imecc .","title":"Toolchain for SiLago Platform"},{"location":"Docs/ToolChain/Overview/#toolchain-for-silago-platform","text":"","title":"Toolchain for SiLago Platform"},{"location":"Docs/ToolChain/Overview/#application-level-synthesis-als","text":"Sylva is the ALS tool for SiLago platform.","title":"Application-Level Synthesis (ALS)"},{"location":"Docs/ToolChain/Overview/#high-level-synthesis-hls","text":"Vesyla-suite is the HLS tool for DRRA-based SiLago platform. It contains multiple tools, such as vs-vesyla , vs-manas , vs-alimpsim , etc. It also contains a compiler for IMEC architecture called vs-imecc .","title":"High-Level Synthesis (HLS)"},{"location":"Docs/ToolChain/Manas/Tutorial/","text":"Manas Tutorial Warning Documentation is not complete!","title":"Manas Tutorial"},{"location":"Docs/ToolChain/Manas/Tutorial/#manas-tutorial","text":"Warning Documentation is not complete!","title":"Manas Tutorial"},{"location":"Docs/ToolChain/Sylva/Overview/","text":"Sylva New version of Sylva documentation: Sylva documentation","title":"Sylva"},{"location":"Docs/ToolChain/Sylva/Overview/#sylva","text":"New version of Sylva documentation: Sylva documentation","title":"Sylva"},{"location":"Docs/ToolChain/Vesyla/Cadfg/","text":"CADFG - Control Address Data-Flow Graph CADFG is a DAG(directed acyclic graph)-based data structure used as an intermediate representation (IR) by Vesyla. Conventional High-level synthesis (HLS) tools typically model high-level program as control and dataflow graph (CDFG) as the intermediate representation (IR). This representation was appropriate because HLS tools synthesize an FSMD (FSM+Datapath) as the target architecture, deal with scalars and do not differentiate between functional, address and address constraints computation. Vesyla-II, in contrast generates distributed two-level FSM control scheme, deals with vectors and differentiates between the three categories of computation. These differences are reflected in the the IR used by Vesyla-II called Control, Address and Dataflow Graph (CADFG). CADFG is derived from the abstract syntax tree (AST). By a series of refinement, it transforms to Instruction Dependent Graph (IDG) as the back-end IR. In this section, we focus on elaborating some of the critical vertices of CADFG. Vertices There are several broad categories of vertices in CADFG: Source and Sink vertices : create and terminate data flow. Read and Write vertices : slice vector to scalar and pack scalar to vector. Address and Address Constraint vertices : generates the address sequence for slicing and packing and address constraints. Function vertex : does general data computation. Control vertices : handle branches and loops. Source and Sink Vertices Source vertices doesn't have any input port and sink vertices doesn't have any output port. Both types of vertices support both vector and scalar data type. In figure ??, p1 to p5 and X are all source vertices, while y is sink vertex. Read and Write Vertices Read vertex slices the vector variable to its each individual element and sending out them one at a time. On the contrary, write vertex packs the time distributed scalar data sequence to vector variable. Both vertices need an address vertex attach to them in order to decide the address sequence. In figure ??, vertex R is an example of read vertex. Address and Address Constraint Vertices Address and Address Constraint Vertices are the key differentiator compared to conventional CDFGs. These vertices embody the policy of differentiating address and address constraints as separate computation category and mapping them to dedicated spatially distributed resources. This manifests in the read vertex getting its addresses from a function that models the address computation as a two-level affine function with five operands as shown and explained with an example in Figure ??. An implication of such an address function is that read vertex does not read a scalar but a vector. The address constraints are also explicitly identified to enable their computation to be also mapped to custom spatially distributed computation resource. In following figure, vertex A is an address vertex. When Vesyla encounters higher order address functions beyond two levels affine function, it repeatedly computes the constraints of the inner two-level loops in a pipelined fashion. Computation in pipelined fashion deserves some explanation. Let us call one instance of innermost two loops as an epoch. While the functional computation and address computation of the innermost two loops are working on epoch i, the address constraints for the next epoch, i+1, are computed in parallel on an independent machine as shown in the following figure. Function Vertex Function vertices are responsible for the actual computation on input data. They are usually bind to arithmetic units inside DRRA cells. Function vertices only accept scalar inputs and generate scalar outputs. That's why we have the read and write nodes to break down the vector variables. Function vertex can be chained together to form more complex arithmetic operation. Control Vertex Control vertices model the control hierarchy and in this respective they are similar to the control vertices in typical CDFGs. These vertices model the main algorithmic level control and not the control for fine grained address and address constraints computation. In CADFG, we do not have explicit control edges to model control dependencies. This is implicitly represented by the hierarchy of the control blocks. All nodes inside a control block are implicitly triggered if the control condition and the data dependency condition of the control block is fulfilled. When an algorithm is parallelized, parts of control hierarchy are replicated to represent the parallelism. Loops in Vesyla are not dynamic, they are either compile time or parametrically static. The latter implies that once the parameter for the loop bounds and increment are decided, these parameters remain static until the loop is complete. The dedicated resources for address constraints computation also serve to manage the loop parameters or constraints. For this reason, CADFG loop vertices are composite, i.e., they do not have any separate datapath vertex for loop condition comparison. Typical HLS tools, on the other hand, instantiate comparators and incrementors/adders to implement loop control verteices. Control Vertices include branch vertex, loop vertex, merge vertex, etc. Edges There are two broad categories of edges in CADFG: Dataflow edge : represents the flow of data, either scalar or vector. Dependency edge : represents the dependency relation between the predicessor and successor. Dataflow Edge Like in conventional CDFG, dataflow edge shows the flow of data. It's a directed edge with predicessor and successor. Data flows from predicessor to successor. Dataflow edge can be either scalar or vector. Dataflow edge automatically embeds the information of dependency. The successor cannot be scheduled earlier than the predicessor. Dependency Edge Dependency edge is a more sophiscated way to describe dependencies among vertices. Vesyla uses dependency edges because in order to solve some hazzards such as \"WAR\" and \"WAW\", extra dependency information is needed and these information can't be provided by normal dataflow edges. A dependency edge is also a directed edge. A timing period is associated with each dependency edge to indicate that the successor should start after the predicessor after some time t t and t t should be bounded by the timing period associated with the dependency edge. Each terminal of the edge also has a property indicating the moment the dependency edge will start to apply. The property can be PROCESS BEGIN or PROCESS END . Thus, a dependency edge a \\rightarrow{} b a \\rightarrow{} b can express 4 different types of dependencies. b b starts after a a starts. b b starts after a a ends. b b ends after a a starts. b b ends after a a ends. Example Lines 1 to 4 are the symbolic parameters that control the dimension of the algorithm and also the allocation and binding. These parameters influence the dimension of the CADFG. For instance, the parameter Col decides the degree of parallelism. The CADFG shown in figure corresponds to Col=1 case. If Col > 1, Vesyla would replicate the CADFG Col times to represent the parallelism. Lines 5 to 8 define the allocation and binding for the storage. This information is stored as attributes in the source and destination nodes of the read/write nodes in the CADFG. Lines 9 to 16 decide the dimension and structure of the CADFG. The control hierarchy is represented by hierarchy of control blocks that serves as containers. In CADFG, there are no explicit control arcs but being inside a control block implies having a control arc from the parent control block. Line 9 refers to spatial iteration, i.e., parallelism and as stated above, decides the number of replications of CADFG. Line 10 is the highest control node that will be executed in each thread; CADFG in figure has a single thread with Col=1. Inside this control block, there are three sub-control blocks, each representing a vector operation on lines 11, 12 and 14. Two of these control blocks enclose read nodes and one write node. Besides these three read/write nodes, there is a functional computation node to represent the functionality on line 13. The read/write nodes that model the vector movement in lines 11, 12 and 14 all have the address and address constraints computation nodes for both LHS and RHS. Potentially, all three nodes could involve three sets of spatially distributed FSMs for address and address computations. Later, factoring in the allocation, binding and the data dependenncies, Vesyla synthesizes strucutures and details for scheduling and synchronizing these FSMs, some of them could be mapped to the same FSM. A simplification process in Vesyla transforms the symbolic expressions in Matlab to numerical values for loop and address constraints. A boxed note in figure explains one such example for address constraints for LHS of line 11. In the example under consideration, there is only one functional computation node on line 13 and as can be seen its inputs and outputs are also vectorizing read/write nodes. Also, the functional computational node is also associated with an allocation and binding pragmas that is duly recorded as part of building the CADFG. While building the CADFG, Vesyla, like other HLS tools also creates explicit data dependencies that crosses control block boundaries. Vesyla also detect hazards and records them with additional dependency arcs. This is explained next.","title":"CADFG - Control Address Data-Flow Graph"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#cadfg-control-address-data-flow-graph","text":"CADFG is a DAG(directed acyclic graph)-based data structure used as an intermediate representation (IR) by Vesyla. Conventional High-level synthesis (HLS) tools typically model high-level program as control and dataflow graph (CDFG) as the intermediate representation (IR). This representation was appropriate because HLS tools synthesize an FSMD (FSM+Datapath) as the target architecture, deal with scalars and do not differentiate between functional, address and address constraints computation. Vesyla-II, in contrast generates distributed two-level FSM control scheme, deals with vectors and differentiates between the three categories of computation. These differences are reflected in the the IR used by Vesyla-II called Control, Address and Dataflow Graph (CADFG). CADFG is derived from the abstract syntax tree (AST). By a series of refinement, it transforms to Instruction Dependent Graph (IDG) as the back-end IR. In this section, we focus on elaborating some of the critical vertices of CADFG.","title":"CADFG - Control Address Data-Flow Graph"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#vertices","text":"There are several broad categories of vertices in CADFG: Source and Sink vertices : create and terminate data flow. Read and Write vertices : slice vector to scalar and pack scalar to vector. Address and Address Constraint vertices : generates the address sequence for slicing and packing and address constraints. Function vertex : does general data computation. Control vertices : handle branches and loops.","title":"Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#source-and-sink-vertices","text":"Source vertices doesn't have any input port and sink vertices doesn't have any output port. Both types of vertices support both vector and scalar data type. In figure ??, p1 to p5 and X are all source vertices, while y is sink vertex.","title":"Source and Sink Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#read-and-write-vertices","text":"Read vertex slices the vector variable to its each individual element and sending out them one at a time. On the contrary, write vertex packs the time distributed scalar data sequence to vector variable. Both vertices need an address vertex attach to them in order to decide the address sequence. In figure ??, vertex R is an example of read vertex.","title":"Read and Write Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#address-and-address-constraint-vertices","text":"Address and Address Constraint Vertices are the key differentiator compared to conventional CDFGs. These vertices embody the policy of differentiating address and address constraints as separate computation category and mapping them to dedicated spatially distributed resources. This manifests in the read vertex getting its addresses from a function that models the address computation as a two-level affine function with five operands as shown and explained with an example in Figure ??. An implication of such an address function is that read vertex does not read a scalar but a vector. The address constraints are also explicitly identified to enable their computation to be also mapped to custom spatially distributed computation resource. In following figure, vertex A is an address vertex. When Vesyla encounters higher order address functions beyond two levels affine function, it repeatedly computes the constraints of the inner two-level loops in a pipelined fashion. Computation in pipelined fashion deserves some explanation. Let us call one instance of innermost two loops as an epoch. While the functional computation and address computation of the innermost two loops are working on epoch i, the address constraints for the next epoch, i+1, are computed in parallel on an independent machine as shown in the following figure.","title":"Address and Address Constraint Vertices"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#function-vertex","text":"Function vertices are responsible for the actual computation on input data. They are usually bind to arithmetic units inside DRRA cells. Function vertices only accept scalar inputs and generate scalar outputs. That's why we have the read and write nodes to break down the vector variables. Function vertex can be chained together to form more complex arithmetic operation.","title":"Function Vertex"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#control-vertex","text":"Control vertices model the control hierarchy and in this respective they are similar to the control vertices in typical CDFGs. These vertices model the main algorithmic level control and not the control for fine grained address and address constraints computation. In CADFG, we do not have explicit control edges to model control dependencies. This is implicitly represented by the hierarchy of the control blocks. All nodes inside a control block are implicitly triggered if the control condition and the data dependency condition of the control block is fulfilled. When an algorithm is parallelized, parts of control hierarchy are replicated to represent the parallelism. Loops in Vesyla are not dynamic, they are either compile time or parametrically static. The latter implies that once the parameter for the loop bounds and increment are decided, these parameters remain static until the loop is complete. The dedicated resources for address constraints computation also serve to manage the loop parameters or constraints. For this reason, CADFG loop vertices are composite, i.e., they do not have any separate datapath vertex for loop condition comparison. Typical HLS tools, on the other hand, instantiate comparators and incrementors/adders to implement loop control verteices. Control Vertices include branch vertex, loop vertex, merge vertex, etc.","title":"Control Vertex"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#edges","text":"There are two broad categories of edges in CADFG: Dataflow edge : represents the flow of data, either scalar or vector. Dependency edge : represents the dependency relation between the predicessor and successor.","title":"Edges"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#dataflow-edge","text":"Like in conventional CDFG, dataflow edge shows the flow of data. It's a directed edge with predicessor and successor. Data flows from predicessor to successor. Dataflow edge can be either scalar or vector. Dataflow edge automatically embeds the information of dependency. The successor cannot be scheduled earlier than the predicessor.","title":"Dataflow Edge"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#dependency-edge","text":"Dependency edge is a more sophiscated way to describe dependencies among vertices. Vesyla uses dependency edges because in order to solve some hazzards such as \"WAR\" and \"WAW\", extra dependency information is needed and these information can't be provided by normal dataflow edges. A dependency edge is also a directed edge. A timing period is associated with each dependency edge to indicate that the successor should start after the predicessor after some time t t and t t should be bounded by the timing period associated with the dependency edge. Each terminal of the edge also has a property indicating the moment the dependency edge will start to apply. The property can be PROCESS BEGIN or PROCESS END . Thus, a dependency edge a \\rightarrow{} b a \\rightarrow{} b can express 4 different types of dependencies. b b starts after a a starts. b b starts after a a ends. b b ends after a a starts. b b ends after a a ends.","title":"Dependency Edge"},{"location":"Docs/ToolChain/Vesyla/Cadfg/#example","text":"Lines 1 to 4 are the symbolic parameters that control the dimension of the algorithm and also the allocation and binding. These parameters influence the dimension of the CADFG. For instance, the parameter Col decides the degree of parallelism. The CADFG shown in figure corresponds to Col=1 case. If Col > 1, Vesyla would replicate the CADFG Col times to represent the parallelism. Lines 5 to 8 define the allocation and binding for the storage. This information is stored as attributes in the source and destination nodes of the read/write nodes in the CADFG. Lines 9 to 16 decide the dimension and structure of the CADFG. The control hierarchy is represented by hierarchy of control blocks that serves as containers. In CADFG, there are no explicit control arcs but being inside a control block implies having a control arc from the parent control block. Line 9 refers to spatial iteration, i.e., parallelism and as stated above, decides the number of replications of CADFG. Line 10 is the highest control node that will be executed in each thread; CADFG in figure has a single thread with Col=1. Inside this control block, there are three sub-control blocks, each representing a vector operation on lines 11, 12 and 14. Two of these control blocks enclose read nodes and one write node. Besides these three read/write nodes, there is a functional computation node to represent the functionality on line 13. The read/write nodes that model the vector movement in lines 11, 12 and 14 all have the address and address constraints computation nodes for both LHS and RHS. Potentially, all three nodes could involve three sets of spatially distributed FSMs for address and address computations. Later, factoring in the allocation, binding and the data dependenncies, Vesyla synthesizes strucutures and details for scheduling and synchronizing these FSMs, some of them could be mapped to the same FSM. A simplification process in Vesyla transforms the symbolic expressions in Matlab to numerical values for loop and address constraints. A boxed note in figure explains one such example for address constraints for LHS of line 11. In the example under consideration, there is only one functional computation node on line 13 and as can be seen its inputs and outputs are also vectorizing read/write nodes. Also, the functional computational node is also associated with an allocation and binding pragmas that is duly recorded as part of building the CADFG. While building the CADFG, Vesyla, like other HLS tools also creates explicit data dependencies that crosses control block boundaries. Vesyla also detect hazards and records them with additional dependency arcs. This is explained next.","title":"Example"},{"location":"Docs/ToolChain/Vesyla/DeadCodeElimination/","text":"","title":"DeadCodeElimination"},{"location":"Docs/ToolChain/Vesyla/DependencyAnalysis/","text":"Dependency Analysis Dependencies created in CADFG don't take the address range of vector variable read/write operations into account. To add such information and fine tune the dependencies, we need to have this dependency analysis process. Here, dependency analysis only refers to the dependency checking for vector operations. Data dependencies between vector variables are more complex than scalar variables because it not only involves the variables but also their read and write access patterns. There are many sophisticated techniques to analyse dependencies among vector operations. Many great works have been done in this research field. However, Vesyla, as a proof-of-concept tool, doesn\u2019t explore all those advanced methods for optimization purpose. It broadly categorizes data dependency among vector variables as strong dependency , weak dependency and fake dependency . Strong dependency requires the successor starts no earlier than the end of its predecessor. Weak dependency only requires the successor starts no earlier than the start of its predecessor. Fake dependency indicates there is no actual data hazard between predecessor and successor, the dependency edge can be removed. As shown in the following figure, If the predecessor and successor of a dependency edge has non-overlapping access patterns the dependency edge is fake because the two nodes will never access the same location. If the predecessor and successor have the same pattern or the successor has a pattern that is a simple shift of the predecessor pattern, the dependency is weak because the predecessor will always access the location before the successor, thus the successor can start one cycle later than the starting of predecessor. For all other cases, Vesyla-II considers the dependency edge strong since this is the most conservative assumption.","title":"Dependency Analysis"},{"location":"Docs/ToolChain/Vesyla/DependencyAnalysis/#dependency-analysis","text":"Dependencies created in CADFG don't take the address range of vector variable read/write operations into account. To add such information and fine tune the dependencies, we need to have this dependency analysis process. Here, dependency analysis only refers to the dependency checking for vector operations. Data dependencies between vector variables are more complex than scalar variables because it not only involves the variables but also their read and write access patterns. There are many sophisticated techniques to analyse dependencies among vector operations. Many great works have been done in this research field. However, Vesyla, as a proof-of-concept tool, doesn\u2019t explore all those advanced methods for optimization purpose. It broadly categorizes data dependency among vector variables as strong dependency , weak dependency and fake dependency . Strong dependency requires the successor starts no earlier than the end of its predecessor. Weak dependency only requires the successor starts no earlier than the start of its predecessor. Fake dependency indicates there is no actual data hazard between predecessor and successor, the dependency edge can be removed. As shown in the following figure, If the predecessor and successor of a dependency edge has non-overlapping access patterns the dependency edge is fake because the two nodes will never access the same location. If the predecessor and successor have the same pattern or the successor has a pattern that is a simple shift of the predecessor pattern, the dependency is weak because the predecessor will always access the location before the successor, thus the successor can start one cycle later than the starting of predecessor. For all other cases, Vesyla-II considers the dependency edge strong since this is the most conservative assumption.","title":"Dependency Analysis"},{"location":"Docs/ToolChain/Vesyla/DiMArch/","text":"DiMArch Reading and Writing To read from DiMArch cell or write to DiMArch cell, we need several collaborating instructions. They are ROUTE instruction, REFI instruction and SRAM_R / SRAM_W instruction. Read (DiMArch -> Register file) When reading from DiMArch to Register file, a path should be routed first by ROUTE instruction. ROUTE instruction has 2 critical timestamps: issue and end . ROUTE instruction will occupy the DiMArch NoC resource of all cells on the routed path until it's end timestamp reached. During the time when the DiMArch NoC path is guaranteed by ROUTE instruction, a SRAM_R instruction is applied to configure the AGU on DiMArch side. SRAM_R instruction has 4 critical timestamps: issue , arrive , active and end . Issue time represents the cycle when sequencer issue the instruction, arrive time represents the instruction reaches the destination DiMArch cell, active time represents the time point when the instruction starts outputing readed data, and end time indicates the instruction stops reading data. At the same time, a REFI instruction should be activated in order to store the data from DiMArch to register file entries. REFI instruction has 3 critical timestamps: issue , active and end . The timing relationship of those 3 instructions are shown in figure below: {% dot sram_read_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; sram_active -> refi_active[label=\"=#hop\"] } %} Write (Register file -> DiMArch) Writing data from Register file to DiMArch share the same set of instruction with the same timestamps as reading operation. The only difference comes from the dependency arrows. The timing relationship of those 3 instructions are shown in figure below: {% dot sram_write_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; refi_active -> sram_active[label=\"=#hop\"] } %}","title":"DiMArch Reading and Writing"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#dimarch-reading-and-writing","text":"To read from DiMArch cell or write to DiMArch cell, we need several collaborating instructions. They are ROUTE instruction, REFI instruction and SRAM_R / SRAM_W instruction.","title":"DiMArch Reading and Writing"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#read-dimarch-register-file","text":"When reading from DiMArch to Register file, a path should be routed first by ROUTE instruction. ROUTE instruction has 2 critical timestamps: issue and end . ROUTE instruction will occupy the DiMArch NoC resource of all cells on the routed path until it's end timestamp reached. During the time when the DiMArch NoC path is guaranteed by ROUTE instruction, a SRAM_R instruction is applied to configure the AGU on DiMArch side. SRAM_R instruction has 4 critical timestamps: issue , arrive , active and end . Issue time represents the cycle when sequencer issue the instruction, arrive time represents the instruction reaches the destination DiMArch cell, active time represents the time point when the instruction starts outputing readed data, and end time indicates the instruction stops reading data. At the same time, a REFI instruction should be activated in order to store the data from DiMArch to register file entries. REFI instruction has 3 critical timestamps: issue , active and end . The timing relationship of those 3 instructions are shown in figure below: {% dot sram_read_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; sram_active -> refi_active[label=\"=#hop\"] } %}","title":"Read (DiMArch -&gt; Register file)"},{"location":"Docs/ToolChain/Vesyla/DiMArch/#write-register-file-dimarch","text":"Writing data from Register file to DiMArch share the same set of instruction with the same timestamps as reading operation. The only difference comes from the dependency arrows. The timing relationship of those 3 instructions are shown in figure below: {% dot sram_write_dep.svg digraph G { subgraph cluster_route{ label=\"ROUTE\" route_issue [label=\"issue\"]; route_end [label=\"end\"]; route_issue -> route_end [label=\">0\"] } subgraph cluster_sram{ label=\"SRAM_R\" sram_issue [label=\"issue\"]; sram_arrive [label=\"arrive\"]; sram_active [label=\"active\"]; sram_end [label=\"end\"]; sram_issue -> sram_arrive [label=\"=(#hop+1)\"]; sram_arrive -> sram_active [label=\"=0\"]; sram_active -> sram_end [label=\"=#element\"]; } subgraph cluster_refi{ label=\"REFI\" refi_issue [label=\"issue\"]; refi_active [label=\"active\"]; refi_end [label=\"end\"]; refi_issue -> refi_active [label=\">=0\"]; refi_active -> refi_end [label=\"=#element\"]; } route_issue -> sram_issue [label=\">0\"]; route_issue -> refi_issue [label=\">0\"]; sram_end -> route_end [label=\">=0\"]; refi_end -> route_end [label=\">=0\"]; refi_active -> sram_active[label=\"=#hop\"] } %}","title":"Write (Register file -&gt; DiMArch)"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/","text":"Expression Simplification Algorithm Perserving Dependency Edges","title":"Expression Simplification"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#expression-simplification","text":"","title":"Expression Simplification"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#algorithm","text":"","title":"Algorithm"},{"location":"Docs/ToolChain/Vesyla/ExpressionSimplification/#perserving-dependency-edges","text":"","title":"Perserving Dependency Edges"},{"location":"Docs/ToolChain/Vesyla/Hazzard/","text":"Hazard Here we only talk about data hazards. Standard Hazards A data hazard is created whenever there is a dependence between data read and/or write operations. Without such dependency information perserved by some proper format, the data access order might be different from the intended order expressed by the programmer in source code thus might lead to unintended output. The goal of harzard detection is to exploit parallesism by perserving data access order only where it affects the outcome of the program. Data hazard can be categorized as Read-After-Write (RAW), Write-After-Write (WAW) and Write-After-Read (WAR). For out-of-order issue hardware or compiler that exploits instruction execution order all three types of hazard can happen. Therefore, we need to preserve the dependency information in order to avoid those hazards. Hazards in Vector Machine and Vesyla In vesyla, the case for RAW is simple. It will be directly absorbed by the data dependency edge that is anyway created. WAR and WAW, requires creation of additional special edges to indicate that there are data dependencies. Data hazards for vector variables are different from those for scalar variables. For example, in the following figure, a WAW dependency is not necessary for scalar variables because the first \u201cWrite\u201d operation can\u2019t affect the final result of that scalar variable hence can be directly removed. While for vector variables, WAW dependency is absolutely necessary, because those two \u201cWrite\u201d operations might write to different part of the vector therefore both will influence the final result of the vector variable. Different from scalar machine, vector machine need extra information to create dependencies. Vector operations usually last for some time period. The dependencies between vector operations need to specify which timing point they are referring to. Specifically, the start and end time of a vector operation are important. Regarding just start and end time of vector operations, we can create 4 types of dependencies: Dependency between the start of predicessor and the start of successor. Dependency between the start of predicessor and the end of successor. Dependency between the end of predicessor and the start of successor. Dependency between the end of predicessor and the end of successor. Data dependency analysis technique can be found in section Dependency Analysis .","title":"Hazard"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#hazard","text":"Here we only talk about data hazards.","title":"Hazard"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#standard-hazards","text":"A data hazard is created whenever there is a dependence between data read and/or write operations. Without such dependency information perserved by some proper format, the data access order might be different from the intended order expressed by the programmer in source code thus might lead to unintended output. The goal of harzard detection is to exploit parallesism by perserving data access order only where it affects the outcome of the program. Data hazard can be categorized as Read-After-Write (RAW), Write-After-Write (WAW) and Write-After-Read (WAR). For out-of-order issue hardware or compiler that exploits instruction execution order all three types of hazard can happen. Therefore, we need to preserve the dependency information in order to avoid those hazards.","title":"Standard Hazards"},{"location":"Docs/ToolChain/Vesyla/Hazzard/#hazards-in-vector-machine-and-vesyla","text":"In vesyla, the case for RAW is simple. It will be directly absorbed by the data dependency edge that is anyway created. WAR and WAW, requires creation of additional special edges to indicate that there are data dependencies. Data hazards for vector variables are different from those for scalar variables. For example, in the following figure, a WAW dependency is not necessary for scalar variables because the first \u201cWrite\u201d operation can\u2019t affect the final result of that scalar variable hence can be directly removed. While for vector variables, WAW dependency is absolutely necessary, because those two \u201cWrite\u201d operations might write to different part of the vector therefore both will influence the final result of the vector variable. Different from scalar machine, vector machine need extra information to create dependencies. Vector operations usually last for some time period. The dependencies between vector operations need to specify which timing point they are referring to. Specifically, the start and end time of a vector operation are important. Regarding just start and end time of vector operations, we can create 4 types of dependencies: Dependency between the start of predicessor and the start of successor. Dependency between the start of predicessor and the end of successor. Dependency between the end of predicessor and the start of successor. Dependency between the end of predicessor and the end of successor. Data dependency analysis technique can be found in section Dependency Analysis .","title":"Hazards in Vector Machine and Vesyla"},{"location":"Docs/ToolChain/Vesyla/Idg/","text":"IDG - Instruction Dependency Graph","title":"IDG - Instruction Dependency Graph"},{"location":"Docs/ToolChain/Vesyla/Idg/#idg-instruction-dependency-graph","text":"","title":"IDG - Instruction Dependency Graph"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/","text":"Instruction Set Instructions 0000 HALT 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0000 HALT instruction code unused [22, 0] 23 0 Unused 0001 - REFI 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 1 A A B B C D D D D D D E F F F F F F G H H H H 0 0 1 0 I J J J J J J K L M M M M M N N N N N O O O O 0 0 1 1 P Q Q Q Q Q Q 0 0 0 0 0 0 R R S T T 0 0 0 U V Field Position Width Range/Value Description instr_code [26, 23] 4 b'0001 REFI1 instruction code port_no [22, 21] 2 [0, 3] Selects one of the RFile ports extra [20, 19] 2 [0, 3] How many following instructions. init_addr_sd 18 1 [0, 1] [0] init_addr is static; [1] init_addr is from RACCU. init_addr [17, 12] 6 [0, 63] Static init address or RACCU register. l1_iter_sd 11 1 [0, 1] [0] Level 1 iteration is static; [1] L1 iteration is from RACCU. l1_iter [10, 5] 6 [0, 63] Static L1 iteration or RACCU register. init_delay_sd 4 1 [0, 1] [0] init_delay is static; [1] init_delay is from RACCU. init_delay [3, 0] 4 [0, 15] Static init delay or RACCU register. unused [26, 23] 4 b'0010 Deprecated l1_step_sd [22] 1 [0, 1] [0] l1_step is static; [1] l1_step is from RACCU l1_step [21, 16] 6 [0, 63] Static level 1 step value or RACCU register l1_step_sign [15] 1 [0, 1] Sign bit of l1_step l1_delay_sd [14] 1 [0, 1] [0] l1_delay is static; [1] l1_delay is from RACCU l1_delay [13, 10] 4 [0, 15] Static level 1 delay or RACCU register l2_iter_sd [9] 1 [0, 1] [0] l2_iter is static; [1] l2_iter is from RACCU l2_iter [8, 4] 5 [0, 31] Static level 2 iteration or RACCU register l2_step [3, 0] 4 [0, 15] Level 2 step value unused [26, 23] 4 b'0011 Deprecated l2_delay_sd [22] 1 [0, 1] [0] l2_delay is static; [1] l2_delay is from RACCU. l2_delay [21, 16] 6 [0, 63] Static level 2 delay or RACCU register. unused [15, 10] 6 0 Deprecated l1_delay_ext [9, 8] 2 [0, 3] Extended bits for l1_delay l2_iter_ext [7] 1 [0, 1] Extended bits for l2_iter l2_step_ext [6, 5] 2 [0, 3] Extended bits for l2_step unused [4, 2] 3 0 Deprecated dimarch [1] 1 [0, 1] [0] Not DiMArch; [1] DiMArch mode compress [0] 1 [0, 1] [0] Not compressed; [1] Compressed 0100 - DPU 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 0 A A A A A B B C C D D E F G G G G G G G G H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0100 DPU instruction code mode [22, 18] 5 [0, 12] Configures the valid dpu mode control [17, 16] 2 [0, 3] [00] no saturation, integer; [01] no saturation, fixed-point; [10] saturation, integer; [11] saturation, fixed-point. not_used [15, 10] 6 b'000010 Deprecated acc_clear [9, 2] 8 [0, 255] The DPU accumulator register clear threshold. io_change [1, 0] 2 [0, 3] [00] no change; [01]negate in1; [10] negate in2; [11] return abosolute value of output. 0101 SWB 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 1 1 A B C D D D E F F F 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 SWB instruction code active [22] 1 1 Deprecated, always 1 src_row [21] 1 [0, 1] The source DRRA row src_block [20] 1 [0, 1] [0] RF; [1] DPU src_port [19] 1 [0, 1] Source port number hb_index [18, 16] 3 [0, 6] Index of horizontal bus send_to_other_row [15] 1 [0, 1] Flag of whether src and dest row are equal v_index [14, 12] 3 [0, 5] Index of vertical bus unused [11, 0] 12 0 Deprecated 0110 JUMP 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 0 A A A A A A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 JUMP instruction code pc [22, 17] 6 [0, 63] The target address unused [16, 0] 17 0 Deprecated 0111 WAIT 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B B B B B B B B B B B B B 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0111 DELAY instruction code cycle_sd [22] 1 [0, 1] [0] cycle is static; [1] cycle is from RACCU cycle [21, 7] 15 [0, 32767] Static cycle or RACCU register unused [6, 0] 7 0 0 1000 LOOP 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A B B C C C C C C D E E E E E E F G G G G G G H I I I I I I 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [53, 50] 4 b'1000 LOOPH instruction code extend [49] 1 [0, 15] 0:No extension; 1:Extended loopid [48, 47] 2 [0, 3] The id of nested loops endpc [46, 41] 6 [0, 63] The PC where loop ends start_sd [40] 1 [0, 1] 0:start is static; 1: start is from RACCU start [39, 34] 6 [-32, 31] Start address, either static or from RACCU iter_sd [33] 1 [0, 1] 0:iter is static; 1: iter is from RACCU iter [32, 27] 6 [0, 63] Iteration, either static or from RACCU step_sd [26] 1 [0, 1] / 0 0:step is static; 1: step is from RACCU step [25, 20] 6 [0, 63] / 1 Step, either static or from RACCU unused [19, 0] 20 0 Unused 1010 RACCU 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A A B C C C C C C C D E E E E E E E F F F F Field Position Width Range/Value Description instr_code [26, 23] 4 b'1010 RACCU instruction code mode [22, 20] 3 [0, 7] Operation mode operand1_sd [19, 19] 1 [0, 1] [0] operand1 is static; [1] operand1 is from RACCU register operand1 [18, 12] 7 [-64, 63] Operand 1 operand2_sd [11, 11] 1 [0, 1] [0] operand2 is static; [1] operand2 is from RACCU register operand2 [10, 4] 7 [-64, 63] Operand 2 result [4, 0] 4 [0, 15] Result register address 1011 BRANCH 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A B B B B B B 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1011 BRANCH instruction code mode [22, 21] 2 [0, 4] The conditional branch mode false_pc [20, 15] 6 [0, 63] Configures the false address unused [14, 0] 15 0 Deprecated 1100 ROUTE 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B C D D D 0 0 0 0 0 0 E 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1100 ROUTE instruction code src_row [22] 1 [0, 1] Source DiMArch row src_col [21, 19] 3 [0, 7] Source DiMArch column dest_row [18] 1 [0, 1] Destination DiMArch row dest_col [17, 15] 3 [0, 7] Destination DiMArch column unused [14, 9] 6 0 Deprecated select_drra_row [8] 1 [0, 1] [0] source is origin; [1] destination is origin unused [7, 0] 8 0 Deprecated 1101 SRAM 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 0 1 A B B B B B B B C C C C D D D D D D D E E E E E E E E F F F F F F G G G G G G G H H H H H H H H I I I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1101 SRAMR instruction code rw [76] 1 [0, 1] Read or Write init_addr [75, 69] 7 * [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 * [0, 127] Level 1 iteration l1_step [57, 50] 8 * [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 * [0, 127] Level 2 iteration l2_step [36, 29] 8 * [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused * The number of bits of the marked fields depends on the size of the SRAM. The current number are set according to a 128 row SRAM, each row is of 256 bits.","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#instruction-set","text":"","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#instructions","text":"","title":"Instructions"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0000-halt","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0000 HALT instruction code unused [22, 0] 23 0 Unused","title":"0000 HALT"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0001-refi","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 0 0 1 A A B B C D D D D D D E F F F F F F G H H H H 0 0 1 0 I J J J J J J K L M M M M M N N N N N O O O O 0 0 1 1 P Q Q Q Q Q Q 0 0 0 0 0 0 R R S T T 0 0 0 U V Field Position Width Range/Value Description instr_code [26, 23] 4 b'0001 REFI1 instruction code port_no [22, 21] 2 [0, 3] Selects one of the RFile ports extra [20, 19] 2 [0, 3] How many following instructions. init_addr_sd 18 1 [0, 1] [0] init_addr is static; [1] init_addr is from RACCU. init_addr [17, 12] 6 [0, 63] Static init address or RACCU register. l1_iter_sd 11 1 [0, 1] [0] Level 1 iteration is static; [1] L1 iteration is from RACCU. l1_iter [10, 5] 6 [0, 63] Static L1 iteration or RACCU register. init_delay_sd 4 1 [0, 1] [0] init_delay is static; [1] init_delay is from RACCU. init_delay [3, 0] 4 [0, 15] Static init delay or RACCU register. unused [26, 23] 4 b'0010 Deprecated l1_step_sd [22] 1 [0, 1] [0] l1_step is static; [1] l1_step is from RACCU l1_step [21, 16] 6 [0, 63] Static level 1 step value or RACCU register l1_step_sign [15] 1 [0, 1] Sign bit of l1_step l1_delay_sd [14] 1 [0, 1] [0] l1_delay is static; [1] l1_delay is from RACCU l1_delay [13, 10] 4 [0, 15] Static level 1 delay or RACCU register l2_iter_sd [9] 1 [0, 1] [0] l2_iter is static; [1] l2_iter is from RACCU l2_iter [8, 4] 5 [0, 31] Static level 2 iteration or RACCU register l2_step [3, 0] 4 [0, 15] Level 2 step value unused [26, 23] 4 b'0011 Deprecated l2_delay_sd [22] 1 [0, 1] [0] l2_delay is static; [1] l2_delay is from RACCU. l2_delay [21, 16] 6 [0, 63] Static level 2 delay or RACCU register. unused [15, 10] 6 0 Deprecated l1_delay_ext [9, 8] 2 [0, 3] Extended bits for l1_delay l2_iter_ext [7] 1 [0, 1] Extended bits for l2_iter l2_step_ext [6, 5] 2 [0, 3] Extended bits for l2_step unused [4, 2] 3 0 Deprecated dimarch [1] 1 [0, 1] [0] Not DiMArch; [1] DiMArch mode compress [0] 1 [0, 1] [0] Not compressed; [1] Compressed","title":"0001 - REFI"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0100-dpu","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 0 A A A A A B B C C D D E F G G G G G G G G H H Field Position Width Range/Value Description instr_code [26, 23] 4 b'0100 DPU instruction code mode [22, 18] 5 [0, 12] Configures the valid dpu mode control [17, 16] 2 [0, 3] [00] no saturation, integer; [01] no saturation, fixed-point; [10] saturation, integer; [11] saturation, fixed-point. not_used [15, 10] 6 b'000010 Deprecated acc_clear [9, 2] 8 [0, 255] The DPU accumulator register clear threshold. io_change [1, 0] 2 [0, 3] [00] no change; [01]negate in1; [10] negate in2; [11] return abosolute value of output.","title":"0100 - DPU"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0101-swb","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 0 1 1 A B C D D D E F F F 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 SWB instruction code active [22] 1 1 Deprecated, always 1 src_row [21] 1 [0, 1] The source DRRA row src_block [20] 1 [0, 1] [0] RF; [1] DPU src_port [19] 1 [0, 1] Source port number hb_index [18, 16] 3 [0, 6] Index of horizontal bus send_to_other_row [15] 1 [0, 1] Flag of whether src and dest row are equal v_index [14, 12] 3 [0, 5] Index of vertical bus unused [11, 0] 12 0 Deprecated","title":"0101 SWB"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0110-jump","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 0 A A A A A A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0110 JUMP instruction code pc [22, 17] 6 [0, 63] The target address unused [16, 0] 17 0 Deprecated","title":"0110 JUMP"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#0111-wait","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B B B B B B B B B B B B B 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'0111 DELAY instruction code cycle_sd [22] 1 [0, 1] [0] cycle is static; [1] cycle is from RACCU cycle [21, 7] 15 [0, 32767] Static cycle or RACCU register unused [6, 0] 7 0 0","title":"0111 WAIT"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1000-loop","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 0 0 0 A B B C C C C C C D E E E E E E F G G G G G G H I I I I I I 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [53, 50] 4 b'1000 LOOPH instruction code extend [49] 1 [0, 15] 0:No extension; 1:Extended loopid [48, 47] 2 [0, 3] The id of nested loops endpc [46, 41] 6 [0, 63] The PC where loop ends start_sd [40] 1 [0, 1] 0:start is static; 1: start is from RACCU start [39, 34] 6 [-32, 31] Start address, either static or from RACCU iter_sd [33] 1 [0, 1] 0:iter is static; 1: iter is from RACCU iter [32, 27] 6 [0, 63] Iteration, either static or from RACCU step_sd [26] 1 [0, 1] / 0 0:step is static; 1: step is from RACCU step [25, 20] 6 [0, 63] / 1 Step, either static or from RACCU unused [19, 0] 20 0 Unused","title":"1000 LOOP"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1010-raccu","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A A B C C C C C C C D E E E E E E E F F F F Field Position Width Range/Value Description instr_code [26, 23] 4 b'1010 RACCU instruction code mode [22, 20] 3 [0, 7] Operation mode operand1_sd [19, 19] 1 [0, 1] [0] operand1 is static; [1] operand1 is from RACCU register operand1 [18, 12] 7 [-64, 63] Operand 1 operand2_sd [11, 11] 1 [0, 1] [0] operand2 is static; [1] operand2 is from RACCU register operand2 [10, 4] 7 [-64, 63] Operand 2 result [4, 0] 4 [0, 15] Result register address","title":"1010 RACCU"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1011-branch","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A A B B B B B B 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1011 BRANCH instruction code mode [22, 21] 2 [0, 4] The conditional branch mode false_pc [20, 15] 6 [0, 63] Configures the false address unused [14, 0] 15 0 Deprecated","title":"1011 BRANCH"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1100-route","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 0 1 1 1 A B B B C D D D 0 0 0 0 0 0 E 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [26, 23] 4 b'1100 ROUTE instruction code src_row [22] 1 [0, 1] Source DiMArch row src_col [21, 19] 3 [0, 7] Source DiMArch column dest_row [18] 1 [0, 1] Destination DiMArch row dest_col [17, 15] 3 [0, 7] Destination DiMArch column unused [14, 9] 6 0 Deprecated select_drra_row [8] 1 [0, 1] [0] source is origin; [1] destination is origin unused [7, 0] 8 0 Deprecated","title":"1100 ROUTE"},{"location":"Docs/ToolChain/Vesyla/Instruction-Set/#1101-sram","text":"26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00 | | | | | | | | | | | | | | | | | | | | | | | | | | | 1 1 0 1 A B B B B B B B C C C C D D D D D D D E E E E E E E E F F F F F F G G G G G G G H H H H H H H H I I I I I I J K L M N O P Q 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Field Position Width Range/Value Description instr_code [80, 77] 4 b'1101 SRAMR instruction code rw [76] 1 [0, 1] Read or Write init_addr [75, 69] 7 * [0, 127] Initial address init_delay [68, 65] 4 [0, 15] Initial delay l1_iter [64, 58] 7 * [0, 127] Level 1 iteration l1_step [57, 50] 8 * [-128, 127] Level 1 step l1_delay [49, 44] 6 [0, 63] Level 1 delay l2_iter [43, 37] 7 * [0, 127] Level 2 iteration l2_step [36, 29] 8 * [-128, 127] Level 2 step l2_delay [28, 23] 6 [0, 63] Level 2 delay init_addr_sd [22] 1 [0, 1] Static or from RACCU l1_iter_sd [21] 1 [0, 1] Static or from RACCU l2_iter_sd [20] 1 [0, 1] Static or from RACCU init_delay_sd [19] 1 [0, 1] Static or from RACCU l1_delay_sd [18] 1 [0, 1] Static or from RACCU l2_delay_sd [17] 1 [0, 1] Static or from RACCU l1_step_sd [16] 1 [0, 1] Static or from RACCU l2_step_sd [15] 1 [0, 1] Static or from RACCU unused [14, 0] 15 0 Unused * The number of bits of the marked fields depends on the size of the SRAM. The current number are set according to a 128 row SRAM, each row is of 256 bits.","title":"1101 SRAM"},{"location":"Docs/ToolChain/Vesyla/Overview/","text":"Warning Documentation is not complete!","title":"Overview"},{"location":"Docs/ToolChain/Vesyla/Scheduling/","text":"Scheduling Problem Defination In Vesyla, the generated instructions have fairly long life-time and are highly cooperative. Which means they are not just single-cycle actors with simple precedency relation that fight for resources. Instructions running in DRRA microthreads might actively coordinate themselves with other instructions executing in some other microthreads. Cooperation with other instructions can happen at any time when an instruction is alive and it can happen multiple times with multiple different other instructions. Further more, the life-time of an instruction in Vesyla can be undetermined and depend on other instructions in terms of both precedency relation and resource availability. To simplify the scenario a little bit, we consider the critical points of those instructions as the atomic unit objects (jobs/actors/operations) that need to be scheduled in the cooperative instruction scheduling problem which will be defined later. What are the critical points? They can be starting and ending point of instructions. They can be the time points when a instruction change its resource usage. They can be the time points when a instruction need to coordinate with other instructions. In short, whenever an instruction changes anything, it's a critical point. Critical points don't have execution duration, it just represents a timestamp. However, critical points can have resoure usage attached to it. Resource usage requires time duration. With the usage of critical points, a new phenominal appears. Some instructions can have undetermined life-time before scheduling. When those instructions are broken down into critical points, the resource usage of those critical points need special treatment since their usage duration are undetermined. We need to assign a LOCK resource usage frame to the critical point starting to use the resource and a KEY resource usage frame to the critical point finishing to use the resource. The resource between LOCK and KEY frame during scheding should be marked unavailable to other critical points. Cooperative instruction scheduling problem thus is very different from the classic instruction scheduling problem. In classic instruction scheduling problem, either positive or negative time-lag exists between a pair of instructions. While between a cooperative critical points pair, both minimal and maximum time-lag may exist, which constrants the precedence relation to a possibly closed time frame. A special case is when minimal and maximum time-lag are equal, representing the two critical points will have an exact time difference. The introduce of LOCK and KEY frame for resource usage is also very different from conventional instruction scheduling problem. Now, we formally define the scheduling model and the scheduling problem. Warning MODEL AND PROBLEM DEFINATION Problem Simplification The scheduling model defined above can not be used directly because it's high complexity creates a vast solution space and scheduling algorithm will have hard time to navigate to the correct direction. Therefore, we propose one assumption and four simplification step to simplify the model. The simplification processes transform the model to equivalent but simpler model hence shrink the solution space. Delay bound assumption Delay bounds of an edge in depenency graph can be either negative or positive as long as the higher bound d_h d_h is not less than lower bound d_l d_l . An edge with d_l=-\\infty d_l=-\\infty or with d_l\\le d_h \\lt 0 d_l\\le d_h \\lt 0 can be easily converted to an edge with d_l\\neq -\\infty d_l\\neq -\\infty and d_h\\ge 0 d_h\\ge 0 . Therefore, we assume that: every edge in dependency graph will have a delay bounds satisfying d_l\\neq -\\infty d_l\\neq -\\infty , d_h\\ge 0 d_h\\ge 0 and d_l\\le d_h d_l\\le d_h . Parking Hard-links Hard-links are edges with constant delay ( d_l=d_h d_l=d_h ). For example, A\\xrightarrow[]{\\text{[w,w]}}B A\\xrightarrow[]{\\text{[w,w]}}B is a hard-link, it describs the constraint that the schedule time of B is exactly w w cycles after the schedule time of A. All vertices linked by hard-links should be scheduled together, because if any vertex has been scheduled, the schedule time of other vertices which directly or indirectly linked to the scheduled vertex can be determined immediately. Therefore, packing hard-linked vertices together can reduce the size of graph and accelerate the scheduling process. Pseudo Algorithm is shown below: Graph packing_hard_links ( Graph g ){ Graph g1 = remove_soft_links ( g ); Component C = find_connected_components ( g1 ); Graph g2 ; for ( auto c : C ){ vector < Vertex , int > offset_map = find_offset_for_each_vertex ( c ); Vertex vc ; Graph g3 ; for ( auto v : c . vertices ()){ v . schedule_time = offset_map ( v ); g3 . add_vertex ( v ); } vc . add_child ( g3 ) g2 . add_vertex ( vc ); } for ( auto e : edges ( g )){ if ( is_soft_link ( e ) && in_different_component ( e . src , e . dest )){ Edge e1 = reshape_edge_accroding_to_g2 ( e ); g2 . add_edge ( e1 ); } } return g2 ; } Remove Redundant Edges When analyzing the weighted edges in dependency graph (DG), it's easy to discover that there are some edges that have very relatexed constraints which can be removed completely without loosing any synchronization constraint information of the original DG. Example below illustrate such scenario. {% dot schedule_remove_redundant_edges.svg digraph G { rankdir=\"LR\"; u -> v [label=\"[1, 5]\"]; u -> w [label=\"[1, 2]\"]; w -> v [label=\"[0, 1]\"]; } %} From the path u \\rightarrow v u \\rightarrow v , assuming u u starts at t_0 t_0 , v v should start at the time period [t_0+1,t_0+5] [t_0+1,t_0+5] . While from the path u \\rightarrow w \\rightarrow v u \\rightarrow w \\rightarrow v , v v should start at the time period [t_0+1,t_0+3] [t_0+1,t_0+3] . It's obvious that period [t_0+1,t_0+5] [t_0+1,t_0+5] is more relaxed thatn period [t_0+1,t_0+3] [t_0+1,t_0+3] . The path u \\rightarrow v u \\rightarrow v doesn't add any addtition information, hence, can be removed. Negative Edge Weight Adjustment In DG, weight can be period with negative integers. Therefore, if there is an edge u \\xrightarrow[]{\\text[-2,2]} v u \\xrightarrow[]{\\text[-2,2]} v , though graphically the edge point from u u to v v , it doesn't necessarily mean that after scheduling, v v is scheduled after u u . The inconsistancy between graph representation and the actual meaning of the weighted edge cause some troubles during later process. It would be much better if we can find a way to make them consistant.To adjust the weight of edges, the goal is to guarantee the weight period are strictly positive numbers. Reader should keep in mind what are the vertices in DG. They are just timestamp marking the critical time of each operation. There may be resource occupation table (ROT) attach to them. Suppose we have an edge like as following: {% dot schedule_edge_weight_adjustment_0.svg digraph G { rankdir=\"LR\"; u [label=\"u\"]; v [label=\"v\"]; u -> v [label=\"[-2, 2]\"]; } %} We can insert a dummy vertex d d with no ROT attach to it before u u with exactly 3 cycles ahead. {% dot schedule_remove_edge_weight_adjustment_1.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; u -> v [label=\"[-2, 2]\"]; } %} The edge u \\rightarrow v u \\rightarrow v can be replaced by a new edge d \\rightarrow v d \\rightarrow v . {% dot schedule_remove_edge_weight_adjustment_2.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; d -> v [label=\"[1, 5]\"]; } %} Edge d \\rightarrow u d \\rightarrow u is always a hard edge, we can merge vertex d d and u u to a new vertex u' u' with shifted ROT_u as its attached ROT. {% dot schedule_edge_weight_adjustment_3.svg digraph G { rankdir=\"LR\"; u [label=\"u'\"]; v [label=\"v\"]; u -> v [label=\"[1, 5]\"]; } %} In this way, every negative numbered weight can be converted to positive weight in DG. Resource Hazard Prediction A well defined program will always have LOCK/KEY frame pair for any resource. A resource should never been locked and there is no KEY frame to unlock it, or vice versa. Different LOCK/KEY pair targeting the same resource will conflict with each other due to the resource occupation. The resource harzard should be resolved by scheduling via time multiplexing. However, in some scenario, if the scheduler don't schedule the vertices in a specific order, the scheduling might lead to unschduable situation due to resource occupation deadlock. Some exploration algorithms such as LIST scheduling engine might fail. While other scheduling engine such as Branch-and-Bound might stack to some corner space exploring for a very long time in order to find a valid suliton. The following example clearly shows such scenario. {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; } %} Vertex c c can be chosen by the scheduler to schedule first because it don't have any dependency from other vertices. The naturally, f, g, h f, g, h can be scheduled. But d d can not be scheduled because e e is not scheduled. e e can not be scheduled because a a can't be scheduled due to resource r r is locked by c c . And r r is not can't be freed because d d can't be scheduled. This is a deadlock and will make this scheduling unfeasible. In order to correct the mistake, the scheduler (for example Branch-and-Bound) will try to trace back and to the step of scheduling h h , then trace back again to g g . Until it back-tracks to c c , the very first scheduling step, the scheduler can't correct the mistake. To solve such problem, we need to predict the scheduling order. By analyzing the graph structure, we should be able to conclude that c c should be scheduled after than b b . We then force a constraint edge to explictly represent such scheduling order in order to help the later exploring phase. The dependency graph after hazard prediction will be look like this: {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; b -> c; } %} Solution Space Exploration Scheduling is an NP-Complete problem. To find a valid solution for dependency graph, we need some solution searching engine or hierustic scheduling algorithm. Branch-and-Bound, Constriant Programming, LIST algorithm, Simulated Annening, etc are such searching engines. In this section, we introduce two searching engine as an example to demonstrate how does the solution space exploration works. LIST Scheduling Algorithm","title":"Scheduling"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#scheduling","text":"","title":"Scheduling"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#problem-defination","text":"In Vesyla, the generated instructions have fairly long life-time and are highly cooperative. Which means they are not just single-cycle actors with simple precedency relation that fight for resources. Instructions running in DRRA microthreads might actively coordinate themselves with other instructions executing in some other microthreads. Cooperation with other instructions can happen at any time when an instruction is alive and it can happen multiple times with multiple different other instructions. Further more, the life-time of an instruction in Vesyla can be undetermined and depend on other instructions in terms of both precedency relation and resource availability. To simplify the scenario a little bit, we consider the critical points of those instructions as the atomic unit objects (jobs/actors/operations) that need to be scheduled in the cooperative instruction scheduling problem which will be defined later. What are the critical points? They can be starting and ending point of instructions. They can be the time points when a instruction change its resource usage. They can be the time points when a instruction need to coordinate with other instructions. In short, whenever an instruction changes anything, it's a critical point. Critical points don't have execution duration, it just represents a timestamp. However, critical points can have resoure usage attached to it. Resource usage requires time duration. With the usage of critical points, a new phenominal appears. Some instructions can have undetermined life-time before scheduling. When those instructions are broken down into critical points, the resource usage of those critical points need special treatment since their usage duration are undetermined. We need to assign a LOCK resource usage frame to the critical point starting to use the resource and a KEY resource usage frame to the critical point finishing to use the resource. The resource between LOCK and KEY frame during scheding should be marked unavailable to other critical points. Cooperative instruction scheduling problem thus is very different from the classic instruction scheduling problem. In classic instruction scheduling problem, either positive or negative time-lag exists between a pair of instructions. While between a cooperative critical points pair, both minimal and maximum time-lag may exist, which constrants the precedence relation to a possibly closed time frame. A special case is when minimal and maximum time-lag are equal, representing the two critical points will have an exact time difference. The introduce of LOCK and KEY frame for resource usage is also very different from conventional instruction scheduling problem. Now, we formally define the scheduling model and the scheduling problem. Warning MODEL AND PROBLEM DEFINATION","title":"Problem Defination"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#problem-simplification","text":"The scheduling model defined above can not be used directly because it's high complexity creates a vast solution space and scheduling algorithm will have hard time to navigate to the correct direction. Therefore, we propose one assumption and four simplification step to simplify the model. The simplification processes transform the model to equivalent but simpler model hence shrink the solution space.","title":"Problem Simplification"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#delay-bound-assumption","text":"Delay bounds of an edge in depenency graph can be either negative or positive as long as the higher bound d_h d_h is not less than lower bound d_l d_l . An edge with d_l=-\\infty d_l=-\\infty or with d_l\\le d_h \\lt 0 d_l\\le d_h \\lt 0 can be easily converted to an edge with d_l\\neq -\\infty d_l\\neq -\\infty and d_h\\ge 0 d_h\\ge 0 . Therefore, we assume that: every edge in dependency graph will have a delay bounds satisfying d_l\\neq -\\infty d_l\\neq -\\infty , d_h\\ge 0 d_h\\ge 0 and d_l\\le d_h d_l\\le d_h .","title":"Delay bound assumption"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#parking-hard-links","text":"Hard-links are edges with constant delay ( d_l=d_h d_l=d_h ). For example, A\\xrightarrow[]{\\text{[w,w]}}B A\\xrightarrow[]{\\text{[w,w]}}B is a hard-link, it describs the constraint that the schedule time of B is exactly w w cycles after the schedule time of A. All vertices linked by hard-links should be scheduled together, because if any vertex has been scheduled, the schedule time of other vertices which directly or indirectly linked to the scheduled vertex can be determined immediately. Therefore, packing hard-linked vertices together can reduce the size of graph and accelerate the scheduling process. Pseudo Algorithm is shown below: Graph packing_hard_links ( Graph g ){ Graph g1 = remove_soft_links ( g ); Component C = find_connected_components ( g1 ); Graph g2 ; for ( auto c : C ){ vector < Vertex , int > offset_map = find_offset_for_each_vertex ( c ); Vertex vc ; Graph g3 ; for ( auto v : c . vertices ()){ v . schedule_time = offset_map ( v ); g3 . add_vertex ( v ); } vc . add_child ( g3 ) g2 . add_vertex ( vc ); } for ( auto e : edges ( g )){ if ( is_soft_link ( e ) && in_different_component ( e . src , e . dest )){ Edge e1 = reshape_edge_accroding_to_g2 ( e ); g2 . add_edge ( e1 ); } } return g2 ; }","title":"Parking Hard-links"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#remove-redundant-edges","text":"When analyzing the weighted edges in dependency graph (DG), it's easy to discover that there are some edges that have very relatexed constraints which can be removed completely without loosing any synchronization constraint information of the original DG. Example below illustrate such scenario. {% dot schedule_remove_redundant_edges.svg digraph G { rankdir=\"LR\"; u -> v [label=\"[1, 5]\"]; u -> w [label=\"[1, 2]\"]; w -> v [label=\"[0, 1]\"]; } %} From the path u \\rightarrow v u \\rightarrow v , assuming u u starts at t_0 t_0 , v v should start at the time period [t_0+1,t_0+5] [t_0+1,t_0+5] . While from the path u \\rightarrow w \\rightarrow v u \\rightarrow w \\rightarrow v , v v should start at the time period [t_0+1,t_0+3] [t_0+1,t_0+3] . It's obvious that period [t_0+1,t_0+5] [t_0+1,t_0+5] is more relaxed thatn period [t_0+1,t_0+3] [t_0+1,t_0+3] . The path u \\rightarrow v u \\rightarrow v doesn't add any addtition information, hence, can be removed.","title":"Remove Redundant Edges"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#negative-edge-weight-adjustment","text":"In DG, weight can be period with negative integers. Therefore, if there is an edge u \\xrightarrow[]{\\text[-2,2]} v u \\xrightarrow[]{\\text[-2,2]} v , though graphically the edge point from u u to v v , it doesn't necessarily mean that after scheduling, v v is scheduled after u u . The inconsistancy between graph representation and the actual meaning of the weighted edge cause some troubles during later process. It would be much better if we can find a way to make them consistant.To adjust the weight of edges, the goal is to guarantee the weight period are strictly positive numbers. Reader should keep in mind what are the vertices in DG. They are just timestamp marking the critical time of each operation. There may be resource occupation table (ROT) attach to them. Suppose we have an edge like as following: {% dot schedule_edge_weight_adjustment_0.svg digraph G { rankdir=\"LR\"; u [label=\"u\"]; v [label=\"v\"]; u -> v [label=\"[-2, 2]\"]; } %} We can insert a dummy vertex d d with no ROT attach to it before u u with exactly 3 cycles ahead. {% dot schedule_remove_edge_weight_adjustment_1.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; u -> v [label=\"[-2, 2]\"]; } %} The edge u \\rightarrow v u \\rightarrow v can be replaced by a new edge d \\rightarrow v d \\rightarrow v . {% dot schedule_remove_edge_weight_adjustment_2.svg digraph G { rankdir=\"LR\"; d [label=\"d\"]; u [label=\"u\"]; v [label=\"v\"]; d -> u [label=\"[3,3]\"]; d -> v [label=\"[1, 5]\"]; } %} Edge d \\rightarrow u d \\rightarrow u is always a hard edge, we can merge vertex d d and u u to a new vertex u' u' with shifted ROT_u as its attached ROT. {% dot schedule_edge_weight_adjustment_3.svg digraph G { rankdir=\"LR\"; u [label=\"u'\"]; v [label=\"v\"]; u -> v [label=\"[1, 5]\"]; } %} In this way, every negative numbered weight can be converted to positive weight in DG.","title":"Negative Edge Weight Adjustment"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#resource-hazard-prediction","text":"A well defined program will always have LOCK/KEY frame pair for any resource. A resource should never been locked and there is no KEY frame to unlock it, or vice versa. Different LOCK/KEY pair targeting the same resource will conflict with each other due to the resource occupation. The resource harzard should be resolved by scheduling via time multiplexing. However, in some scenario, if the scheduler don't schedule the vertices in a specific order, the scheduling might lead to unschduable situation due to resource occupation deadlock. Some exploration algorithms such as LIST scheduling engine might fail. While other scheduling engine such as Branch-and-Bound might stack to some corner space exploring for a very long time in order to find a valid suliton. The following example clearly shows such scenario. {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; } %} Vertex c c can be chosen by the scheduler to schedule first because it don't have any dependency from other vertices. The naturally, f, g, h f, g, h can be scheduled. But d d can not be scheduled because e e is not scheduled. e e can not be scheduled because a a can't be scheduled due to resource r r is locked by c c . And r r is not can't be freed because d d can't be scheduled. This is a deadlock and will make this scheduling unfeasible. In order to correct the mistake, the scheduler (for example Branch-and-Bound) will try to trace back and to the step of scheduling h h , then trace back again to g g . Until it back-tracks to c c , the very first scheduling step, the scheduler can't correct the mistake. To solve such problem, we need to predict the scheduling order. By analyzing the graph structure, we should be able to conclude that c c should be scheduled after than b b . We then force a constraint edge to explictly represent such scheduling order in order to help the later exploring phase. The dependency graph after hazard prediction will be look like this: {% dot schedule_resource_hazard_0.svg digraph G { rankdir=\"LR\"; a [label=\"a / LOCK\u00ae\"]; b [label=\"b / KEY\u00ae\"]; c [label=\"c / LOCK\u00ae\"]; d [label=\"d / KEY\u00ae\"]; e [label=\"e\"]; f [label=\"f\"]; g [label=\"g\"]; h [label=\"h\"]; a -> b; c -> f -> g -> h -> d; b -> e -> d; b -> c; } %}","title":"Resource Hazard Prediction"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#solution-space-exploration","text":"Scheduling is an NP-Complete problem. To find a valid solution for dependency graph, we need some solution searching engine or hierustic scheduling algorithm. Branch-and-Bound, Constriant Programming, LIST algorithm, Simulated Annening, etc are such searching engines. In this section, we introduce two searching engine as an example to demonstrate how does the solution space exploration works.","title":"Solution Space Exploration"},{"location":"Docs/ToolChain/Vesyla/Scheduling/#list-scheduling-algorithm","text":"","title":"LIST Scheduling Algorithm"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/","text":"Installation Note This page is written for vesyla-suite version 3 . We don't recommend to compile for vesyla-suite version 2. Create and Use Docker Image Prerequisites To use docker image, you need to install docker first. You can install docker according to the instruction on the official website: https://docs.docker.com/install/ . Build Docker Image There is a docker file in the root folder of vesyla-suite. You can use it to create a docker image for vesyla-suite. The docker image is based on Fedora Linux. You can use the following command to create a docker image (assuming the version is 3.0): docker build - t vesyla-suite:3.0 . Optionally, you can export the docker image to a tar file by using the following command: docker save - o vesyla-suite-3.0.tar vesyla-suite:3.0 You don't have to build your own docker image from the source code. It is also possible to download the docker image from one-drive. Ask the vesyla-suite maintainer for the download link. Once you can import the docker image using the command: docker load - i vesyla-suite-3.0.tar Create Docker Container To create a docker container from the docker image and bind the current directory to the /work directory in the container, you can use the following command: docker run -- name vesyla-suite - v $PWD: / work vesyla-suite:3.0 Use Docker Container Once the container has been created, you can use the following command to enter the container and access the commands provided by vesyla-suite: docker start - i vesyla-suite Compile and Install from Source Code Prerequisites Vesyla-suite can be compiled and installed on any modern linux distribution. Before compiling vesyla-suite, you need to install compilation tool chain. You need to use the correct package manager of your Linux distribution. The necessary packages include: g++ (version 5 or above), make, cmake, boost liabrires, gecode. Here, we give the example command for Fedora Linux. sudo dnf install g ++ make cmake boost-devel perl autoconf libgmp-devel Installation Gecode Vesyla uses Gecode it for CP scheduling engine. You can install it according to the installation instruction on the official website: https://www.gecode.org/ . Please install Gecode in stanard location (such as /usr or /usr/local ) so that the cmake can find it. cd / gecode / root / folder . / configure -- prefix = / desired / install / path make make install Install Python3 and Python3 packages Python3 is assential for vesyla-suite. You can install it according to the instruction on the official website: https://www.python.org/ . You also need to install some python3 packages. Here, we give the example command for Fedora Linux. sudo dnf install python3-devel python3-pip Vesyla-suite uses nuitka to compile python3 scripts into native executable programs. You can install it by using pip3. sudo dnf install patchelf pip3 install nuitka Compile and install vesyla-suite Vesyla-suite also need flex and bison to compile. You can install them by using the package manager of your Linux distribution. Here, we give the example command for Fedora Linux. sudo dnf install bison flex Then, you can download the vesyla-suite source package and make a build directory. cd / vesyla-suite / root / folder mkdir build Next step is to generate makefile according to the CMake configuration file CMakeLists.txt and specify the installation path. Once the makefile is generated, you can compile it and install the compiled program. cd build cmake - DCMAKE_INSTALL_PREFIX = / desired / install / path .. make make install Now, all executable programs in vesyla-suite are installed. Post-installation Setup If vesyla-suite are installed in non-standard location, you need to set the following environment variables to make it work. export PATH = $PATH: / path / to / vesyla-suite / bin export LD_LIBRARY_PATH = $LD_LIBRARY_PATH: / path / to / vesyla-suite / lib export LD_LIBRARY_PATH = $LD_LIBRARY_PATH: / path / to / gecode / lib","title":"Installation"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#installation","text":"Note This page is written for vesyla-suite version 3 . We don't recommend to compile for vesyla-suite version 2.","title":"Installation"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#create-and-use-docker-image","text":"","title":"Create and Use Docker Image"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#prerequisites","text":"To use docker image, you need to install docker first. You can install docker according to the instruction on the official website: https://docs.docker.com/install/ .","title":"Prerequisites"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#build-docker-image","text":"There is a docker file in the root folder of vesyla-suite. You can use it to create a docker image for vesyla-suite. The docker image is based on Fedora Linux. You can use the following command to create a docker image (assuming the version is 3.0): docker build - t vesyla-suite:3.0 . Optionally, you can export the docker image to a tar file by using the following command: docker save - o vesyla-suite-3.0.tar vesyla-suite:3.0 You don't have to build your own docker image from the source code. It is also possible to download the docker image from one-drive. Ask the vesyla-suite maintainer for the download link. Once you can import the docker image using the command: docker load - i vesyla-suite-3.0.tar","title":"Build Docker Image"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#create-docker-container","text":"To create a docker container from the docker image and bind the current directory to the /work directory in the container, you can use the following command: docker run -- name vesyla-suite - v $PWD: / work vesyla-suite:3.0","title":"Create Docker Container"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#use-docker-container","text":"Once the container has been created, you can use the following command to enter the container and access the commands provided by vesyla-suite: docker start - i vesyla-suite","title":"Use Docker Container"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#compile-and-install-from-source-code","text":"","title":"Compile and Install from Source Code"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#prerequisites_1","text":"Vesyla-suite can be compiled and installed on any modern linux distribution. Before compiling vesyla-suite, you need to install compilation tool chain. You need to use the correct package manager of your Linux distribution. The necessary packages include: g++ (version 5 or above), make, cmake, boost liabrires, gecode. Here, we give the example command for Fedora Linux. sudo dnf install g ++ make cmake boost-devel perl autoconf libgmp-devel","title":"Prerequisites"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#installation-gecode","text":"Vesyla uses Gecode it for CP scheduling engine. You can install it according to the installation instruction on the official website: https://www.gecode.org/ . Please install Gecode in stanard location (such as /usr or /usr/local ) so that the cmake can find it. cd / gecode / root / folder . / configure -- prefix = / desired / install / path make make install","title":"Installation Gecode"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#install-python3-and-python3-packages","text":"Python3 is assential for vesyla-suite. You can install it according to the instruction on the official website: https://www.python.org/ . You also need to install some python3 packages. Here, we give the example command for Fedora Linux. sudo dnf install python3-devel python3-pip Vesyla-suite uses nuitka to compile python3 scripts into native executable programs. You can install it by using pip3. sudo dnf install patchelf pip3 install nuitka","title":"Install Python3 and Python3 packages"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#compile-and-install-vesyla-suite","text":"Vesyla-suite also need flex and bison to compile. You can install them by using the package manager of your Linux distribution. Here, we give the example command for Fedora Linux. sudo dnf install bison flex Then, you can download the vesyla-suite source package and make a build directory. cd / vesyla-suite / root / folder mkdir build Next step is to generate makefile according to the CMake configuration file CMakeLists.txt and specify the installation path. Once the makefile is generated, you can compile it and install the compiled program. cd build cmake - DCMAKE_INSTALL_PREFIX = / desired / install / path .. make make install Now, all executable programs in vesyla-suite are installed.","title":"Compile and install vesyla-suite"},{"location":"Docs/ToolChain/Vesyla-suite/Installation/#post-installation-setup","text":"If vesyla-suite are installed in non-standard location, you need to set the following environment variables to make it work. export PATH = $PATH: / path / to / vesyla-suite / bin export LD_LIBRARY_PATH = $LD_LIBRARY_PATH: / path / to / vesyla-suite / lib export LD_LIBRARY_PATH = $LD_LIBRARY_PATH: / path / to / gecode / lib","title":"Post-installation Setup"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionPhase/","text":"Instruction Phase Instruction phase is the critical timing point when the instruction behavior changes. Each instruction has 1 or more phases. It roughly corresponds to the FSM transition point of each level-2 controller. The following table list all the phases of each instruction on DRRA. Instruction Number Phases HALT 1 FETCH REFI 4 FETCH, ISSUE, ACTIVE, END DPU 4 FETCH, ISSUE, ACTIVE, END SWB 3 FETCH, ISSUE, END JUMP 1 FETCH WAIT 2 FETCH, END LOOP 1 FETCH RACCU 2 FETCH, ISSUE BRANCH 1 FETCH ROUTE 4 FETCH, ISSUE, ARRIVE, END SRAM 5 FETCH, ISSUE, ARRIVE, ACTIVE, END","title":"Instruction Phase"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionPhase/#instruction-phase","text":"Instruction phase is the critical timing point when the instruction behavior changes. Each instruction has 1 or more phases. It roughly corresponds to the FSM transition point of each level-2 controller. The following table list all the phases of each instruction on DRRA. Instruction Number Phases HALT 1 FETCH REFI 4 FETCH, ISSUE, ACTIVE, END DPU 4 FETCH, ISSUE, ACTIVE, END SWB 3 FETCH, ISSUE, END JUMP 1 FETCH WAIT 2 FETCH, END LOOP 1 FETCH RACCU 2 FETCH, ISSUE BRANCH 1 FETCH ROUTE 4 FETCH, ISSUE, ARRIVE, END SRAM 5 FETCH, ISSUE, ARRIVE, ACTIVE, END","title":"Instruction Phase"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/","text":"Instruction Set Instructions Note Instruction fields marked by bold font are controllable and observable. Users can modify these fields in Manas input file. HALT Field Position Width Default Value Description instr_code [26, 23] 4 0 Instruction code for HALT REFI Field Position Width Default Value Description instr_code [80, 77] 4 1 Instruction code for REFI port_no [76, 75] 2 0 Selects one of the RFile port. [0]:w0; [1]:w1; [2]:r0; [3]:r1; extra [74, 73] 2 0 How many following chunks? init_addr_sd [72, 72] 1 0 Is init_addr static or dymamic? [0]:s; [1]:d; init_addr [71, 66] 6 0 Initial address. l1_iter [65, 60] 6 0 Level-1 iteration - 1. init_delay [59, 54] 6 0 Initial delay. l1_iter_sd [53, 53] 1 0 Is level-1 iteration static or dymamic? [0]:s; [1]:d; init_delay_sd [52, 52] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; unused_0 [51, 50] 2 2 Deprecated. l1_step_sd [49, 49] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l1_step [48, 43] 6 1 Level-1 step l1_step_sign [42, 42] 1 0 The sign of level-1 step. [0]:+; [1]:-; l1_delay_sd [41, 41] 1 0 Is the level-1 delay static or dynamic? [0]:s; [1]:d; l1_delay [40, 37] 4 0 The level-1 delay, middle delay l2_iter_sd [36, 36] 1 0 Is level-2 iteration static or dymamic? [0]:s; [1]:d; l2_iter [35, 31] 5 0 The level-2 iteration - 1. l2_step [30, 27] 4 1 The level-2 step. unused_1 [26, 23] 4 3 Deprecated. l2_delay_sd [22, 22] 1 0 Is the level-2 delay static or dynamic? [0]:s; [1]:d; l2_delay [21, 16] 6 0 The level-2 delay, repetition delay. unused_2 [15, 10] 6 0 Deprecated. l1_delay_ext [9, 8] 2 0 The extened bits near MSB of l1_delay. l2_iter_ext [7, 7] 1 0 The extened bits near MSB of l2_iter. l2_step_ext [6, 5] 2 0 The extened bits near MSB of l2_step. unused_3 [4, 2] 3 0 Deprecated. dimarch [1, 1] 1 0 Is reading/writing from/to DiMArch? [0]:n; [1]:y; compress [0, 0] 1 0 Is the data compressed? [0]:n; [1]:y; DPU Field Position Width Default Value Description instr_code [26, 23] 4 4 Instruction code for DPU mode [22, 18] 5 0 The DPU mode. [0]:idle; [1]:add; [2]:sum_acc; [3]:add_const; [4]:subt; [5]:subt_abs; [6]:mode_6; [7]:mult; [8]:mult_add; [9]:mult_const; [10]:mac; [11]:ld_ir; [12]:axpy; [13]:max_min_acc; [14]:max_min_const; [15]:mode_15; [16]:max_min; [17]:shift_l; [18]:shift_r; [19]:sigm; [20]:tanhyp; [21]:expon; [22]:lk_relu; [23]:relu; [24]:div; [25]:acc_softmax; [26]:div_softmax; [27]:ld_acc; [28]:scale_dw; [29]:scale_up; [30]:mac_inter; [31]:mode_31; control [17, 16] 2 2 The controll mode: saturation and operator type. [0]:nosat_int; [1]:nosat_fx; [2]:sat_int; [3]:sat_fx; unused_0 [15, 10] 6 2 Deprecated. acc_clear [9, 2] 8 0 The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode. io_change [1, 0] 2 0 The IO mode: negate input and absolute output. [0]:no_change; [1]:negate_in0; [2]:negate_in1; [3]:abs_out; SWB Field Position Width Default Value Description instr_code [26, 23] 4 5 Instruction code for SWB unused0 [22, 22] 1 1 Deprecated. src_row [21, 21] 1 0 Source row. src_block [20, 20] 1 0 Source block, RF or DPU. [0]:rf; [1]:dpu; src_port [19, 19] 1 0 source port. hb_index [18, 16] 3 0 Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0. send_to_other_row [15, 15] 1 0 Flag of whether src and dest row are equal. [0]:n; [1]:y; v_index [14, 12] 3 0 Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2. JUMP Field Position Width Default Value Description instr_code [26, 23] 4 6 Instruction code for JUMP pc [22, 17] 6 0 The PC to jump to WAIT Field Position Width Default Value Description instr_code [26, 23] 4 7 Instruction code for WAIT cycle_sd [22, 22] 1 0 Is the cycle static or dynamic? [0]:s; [1]:d; cycle [21, 7] 15 0 Number of cycles - 1 LOOP Field Position Width Default Value Description instr_code [53, 50] 4 8 Instruction code for LOOP extra [49, 49] 1 0 How many following chunks? loopid [48, 47] 2 0 The id of the loop manager slot. endpc [46, 41] 6 0 The PC where loop ends. start_sd [40, 40] 1 0 Is the start static or dynamic? [0]:s; [1]:d; start [39, 34] 6 0 The start of iterator. iter_sd [33, 33] 1 0 Is the iteration count static or dynamic? [0]:s; [1]:d; iter [32, 27] 6 0 The number of iteration. step_sd [26, 26] 1 0 Is the step static or dynamic? [0]:s; [1]:d; step [25, 20] 6 1 The iteration step. link [19, 16] 4 0 The loops that have the same endpc will be linked together. This field is 1-hot encoded. BW Field Position Width Default Value Description instr_code [26, 23] 4 9 Instruction code for BW config [22, 21] 2 0 Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit RACCU Field Position Width Default Value Description instr_code [26, 23] 4 10 Instruction code for RACCU mode [22, 20] 3 0 RACCU mode [0]:idle; [1]:add; [2]:sub; [3]:shift_r; [4]:shift_l; [5]:mult; [6]:mult_add; [7]:mult_sub; operand1_sd [19, 19] 1 0 Is the first operand static or dynamic? [0]:s; [1]:d; operand1 [18, 12] 7 0 First operand. operand2_sd [11, 11] 1 0 Is the second operand static or dynamic? [0]:s; [1]:d; operand2 [10, 4] 7 0 Second operand. result [3, 0] 4 0 The RACCU register to store the result. BRANCH Field Position Width Default Value Description instr_code [26, 23] 4 11 Instruction code for BRANCH mode [22, 21] 2 0 The branch mode false_pc [20, 15] 6 0 The PC to jump to in case the condition is false. ROUTE Field Position Width Default Value Description instr_code [26, 23] 4 12 Instruction code for ROUTE horizontal_dir [22, 22] 1 0 The horizontal direction: West or East. [0]:w; [1]:e; horizontal_hops [21, 19] 3 0 The horizontal hops. vertical_dir [18, 18] 1 0 The vertical direction: South or North. [0]:s; [1]:n; vertical_hops [17, 15] 3 0 The vertical hops. direction [14, 14] 1 0 The data transfer direction: Read or Write. [0]:r; [1]:w; select_drra_row [13, 13] 1 0 The drra row that send/recieve the data. SRAM Field Position Width Default Value Description instr_code [80, 77] 4 13 Instruction code for SRAM rw [76, 76] 1 0 Read or Write [0]:r; [1]:w; init_addr [75, 69] 7 0 Initial address init_delay [68, 65] 4 0 initial delay l1_iter [64, 58] 7 0 level-1 iteration - 1. l1_step [57, 50] 8 1 level-1 step l1_delay [49, 44] 6 0 level-1 delay l2_iter [43, 37] 7 0 level-2 iteration - 1. l2_step [36, 29] 8 1 level-2 step l2_delay [28, 23] 6 0 level-2 delay init_addr_sd [22, 22] 1 0 Is initial address static or dynamic? [0]:s; [1]:d; l1_iter_sd [21, 21] 1 0 Is level-1 iteration static or dynamic? [0]:s; [1]:d; l2_iter_sd [20, 20] 1 0 Is level-2 iteration static or dynamic? [0]:s; [1]:d; init_delay_sd [19, 19] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; l1_delay_sd [18, 18] 1 0 Is level-1 delay static or dynamic? [0]:s; [1]:d; l2_delay_sd [17, 17] 1 0 Is level-2 delay static or dynamic? [0]:s; [1]:d; l1_step_sd [16, 16] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l2_step_sd [15, 15] 1 0 Is level-2 step static or dynamic? [0]:s; [1]:d; hops [14, 11] 4 0 Number of hops to reach the DiMArch cell - 1 ISA Description File JSON Schema The ISA description file uses json format and validated by the following json schema: { \"type\" : \"object\" , \"properties\" : { \"platform\" : { \"type\" : \"string\" }, \"instr_bitwidth\" : { \"type\" : \"integer\" }, \"instr_code_bitwidth\" : { \"type\" : \"integer\" }, \"instruction_templates\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"code\" : { \"type\" : \"integer\" }, \"name\" : { \"type\" : \"string\" }, \"phase\" : { \"type\" : \"integer\" }, \"max_chunk\" : { \"type\" : \"integer\" }, \"segment_templates\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"bitwidth\" : { \"type\" : \"integer\" }, \"default_val\" : { \"type\" : \"integer\" }, \"controllable\" : { \"type\" : \"boolean\" }, \"observable\" : { \"type\" : \"boolean\" }, \"verbo_map\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"key\" : { \"type\" : \"integer\" }, \"val\" : { \"type\" : \"string\" } } } }, \"comment\" : { \"type\" : \"string\" } }, \"required\" : [ \"name\" , \"bitwidth\" , \"comment\" ] }, \"uniqueItems\" : true } }, \"required\" : [ \"code\" , \"name\" ] }, \"uniqueItems\" : true } }, \"required\" : [ \"platform\" , \"instr_bitwidth\" , \"instr_code_bitwidth\" , \"instruction_templates\" ] } Note You can validate a ISA description json file using this schema on Json Schema Validator . JSON The ISA description file used for DRRA is shown as follow: { \"platform\" : \"SiLago 1\" , \"instr_bitwidth\" : 27 , \"instr_code_bitwidth\" : 4 , \"instruction_templates\" : [ { \"code\" : 0 , \"name\" : \"HALT\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [] }, { \"code\" : 1 , \"name\" : \"REFI\" , \"phase\" : 4 , \"max_chunk\" : 3 , \"segment_templates\" : [ { \"name\" : \"port_no\" , \"comment\" : \"Selects one of the RFile port.\" , \"bitwidth\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"w0\" }, { \"key\" : 1 , \"val\" : \"w1\" }, { \"key\" : 2 , \"val\" : \"r0\" }, { \"key\" : 3 , \"val\" : \"r1\" } ] }, { \"name\" : \"extra\" , \"comment\" : \"How many following chunks?\" , \"bitwidth\" : 2 }, { \"name\" : \"init_addr_sd\" , \"comment\" : \"Is init_addr static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_addr\" , \"comment\" : \"Initial address.\" , \"bitwidth\" : 6 }, { \"name\" : \"l1_iter\" , \"comment\" : \"Level-1 iteration - 1.\" , \"bitwidth\" : 6 }, { \"name\" : \"init_delay\" , \"comment\" : \"Initial delay.\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"l1_iter_sd\" , \"comment\" : \"Is level-1 iteration static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_delay_sd\" , \"comment\" : \"Is initial delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"unused_0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 2 , \"default_val\" : 2 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l1_step_sd\" , \"comment\" : \"Is level-1 step static or dynamic?\" , \"bitwidth\" : 1 , \"default_val\" : 0 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_step\" , \"comment\" : \"Level-1 step\" , \"bitwidth\" : 6 , \"default_val\" : 1 }, { \"name\" : \"l1_step_sign\" , \"comment\" : \"The sign of level-1 step.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"+\" }, { \"key\" : 1 , \"val\" : \"-\" } ] }, { \"name\" : \"l1_delay_sd\" , \"comment\" : \"Is the level-1 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_delay\" , \"comment\" : \"The level-1 delay, middle delay\" , \"bitwidth\" : 4 , \"controllable\" : true }, { \"name\" : \"l2_iter_sd\" , \"comment\" : \"Is level-2 iteration static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_iter\" , \"comment\" : \"The level-2 iteration - 1.\" , \"bitwidth\" : 5 }, { \"name\" : \"l2_step\" , \"comment\" : \"The level-2 step.\" , \"bitwidth\" : 4 , \"default_val\" : 1 }, { \"name\" : \"unused_1\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 4 , \"default_val\" : 3 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l2_delay_sd\" , \"comment\" : \"Is the level-2 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_delay\" , \"comment\" : \"The level-2 delay, repetition delay.\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"unused_2\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 6 , \"default_val\" : 0 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l1_delay_ext\" , \"comment\" : \"The extened bits near MSB of l1_delay.\" , \"controllable\" : true , \"bitwidth\" : 2 }, { \"name\" : \"l2_iter_ext\" , \"comment\" : \"The extened bits near MSB of l2_iter.\" , \"bitwidth\" : 1 }, { \"name\" : \"l2_step_ext\" , \"comment\" : \"The extened bits near MSB of l2_step.\" , \"bitwidth\" : 2 }, { \"name\" : \"unused_3\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 3 , \"default_val\" : 0 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"dimarch\" , \"comment\" : \"Is reading/writing from/to DiMArch?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] }, { \"name\" : \"compress\" , \"comment\" : \"Is the data compressed?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] } ] }, { \"code\" : 4 , \"name\" : \"DPU\" , \"phase\" : 4 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"The DPU mode.\" , \"bitwidth\" : 5 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"idle\" }, { \"key\" : 1 , \"val\" : \"add\" }, { \"key\" : 2 , \"val\" : \"sum_acc\" }, { \"key\" : 3 , \"val\" : \"add_const\" }, { \"key\" : 4 , \"val\" : \"subt\" }, { \"key\" : 5 , \"val\" : \"subt_abs\" }, { \"key\" : 6 , \"val\" : \"mode_6\" }, { \"key\" : 7 , \"val\" : \"mult\" }, { \"key\" : 8 , \"val\" : \"mult_add\" }, { \"key\" : 9 , \"val\" : \"mult_const\" }, { \"key\" : 10 , \"val\" : \"mac\" }, { \"key\" : 11 , \"val\" : \"ld_ir\" }, { \"key\" : 12 , \"val\" : \"axpy\" }, { \"key\" : 13 , \"val\" : \"max_min_acc\" }, { \"key\" : 14 , \"val\" : \"max_min_const\" }, { \"key\" : 15 , \"val\" : \"mode_15\" }, { \"key\" : 16 , \"val\" : \"max_min\" }, { \"key\" : 17 , \"val\" : \"shift_l\" }, { \"key\" : 18 , \"val\" : \"shift_r\" }, { \"key\" : 19 , \"val\" : \"sigm\" }, { \"key\" : 20 , \"val\" : \"tanhyp\" }, { \"key\" : 21 , \"val\" : \"expon\" }, { \"key\" : 22 , \"val\" : \"lk_relu\" }, { \"key\" : 23 , \"val\" : \"relu\" }, { \"key\" : 24 , \"val\" : \"div\" }, { \"key\" : 25 , \"val\" : \"acc_softmax\" }, { \"key\" : 26 , \"val\" : \"div_softmax\" }, { \"key\" : 27 , \"val\" : \"ld_acc\" }, { \"key\" : 28 , \"val\" : \"scale_dw\" }, { \"key\" : 29 , \"val\" : \"scale_up\" }, { \"key\" : 30 , \"val\" : \"mac_inter\" }, { \"key\" : 31 , \"val\" : \"mode_31\" } ] }, { \"name\" : \"control\" , \"comment\" : \"The controll mode: saturation and operator type.\" , \"bitwidth\" : 2 , \"default_val\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"nosat_int\" }, { \"key\" : 1 , \"val\" : \"nosat_fx\" }, { \"key\" : 2 , \"val\" : \"sat_int\" }, { \"key\" : 3 , \"val\" : \"sat_fx\" } ] }, { \"name\" : \"unused_0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 6 , \"default_val\" : 2 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"acc_clear\" , \"comment\" : \"The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode.\" , \"bitwidth\" : 8 }, { \"id\" : 4 , \"name\" : \"io_change\" , \"comment\" : \"The IO mode: negate input and absolute output.\" , \"bitwidth\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"no_change\" }, { \"key\" : 1 , \"val\" : \"negate_in0\" }, { \"key\" : 2 , \"val\" : \"negate_in1\" }, { \"key\" : 3 , \"val\" : \"abs_out\" } ] } ] }, { \"code\" : 5 , \"name\" : \"SWB\" , \"phase\" : 3 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"unused0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 1 , \"default_val\" : 1 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"src_row\" , \"comment\" : \"Source row.\" , \"bitwidth\" : 1 }, { \"name\" : \"src_block\" , \"comment\" : \"Source block, RF or DPU.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"rf\" }, { \"key\" : 1 , \"val\" : \"dpu\" } ] }, { \"name\" : \"src_port\" , \"comment\" : \"source port.\" , \"bitwidth\" : 1 }, { \"name\" : \"hb_index\" , \"comment\" : \"Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0.\" , \"bitwidth\" : 3 }, { \"name\" : \"send_to_other_row\" , \"comment\" : \"Flag of whether src and dest row are equal.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] }, { \"name\" : \"v_index\" , \"comment\" : \"Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2.\" , \"bitwidth\" : 3 } ] }, { \"code\" : 6 , \"name\" : \"JUMP\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"pc\" , \"comment\" : \"The PC to jump to\" , \"bitwidth\" : 6 } ] }, { \"code\" : 7 , \"name\" : \"WAIT\" , \"phase\" : 2 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"cycle_sd\" , \"comment\" : \"Is the cycle static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"cycle\" , \"comment\" : \"Number of cycles - 1\" , \"bitwidth\" : 15 } ] }, { \"code\" : 8 , \"name\" : \"LOOP\" , \"phase\" : 1 , \"max_chunk\" : 2 , \"segment_templates\" : [ { \"name\" : \"extra\" , \"comment\" : \"How many following chunks?\" , \"bitwidth\" : 1 }, { \"name\" : \"loopid\" , \"comment\" : \"The id of the loop manager slot.\" , \"bitwidth\" : 2 }, { \"name\" : \"endpc\" , \"comment\" : \"The PC where loop ends.\" , \"bitwidth\" : 6 }, { \"name\" : \"start_sd\" , \"comment\" : \"Is the start static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"start\" , \"comment\" : \"The start of iterator.\" , \"bitwidth\" : 6 }, { \"name\" : \"iter_sd\" , \"comment\" : \"Is the iteration count static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"iter\" , \"comment\" : \"The number of iteration.\" , \"bitwidth\" : 6 }, { \"name\" : \"step_sd\" , \"comment\" : \"Is the step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"step\" , \"comment\" : \"The iteration step.\" , \"bitwidth\" : 6 , \"default_val\" : 1 }, { \"name\" : \"link\" , \"comment\" : \"The loops that have the same endpc will be linked together. This field is 1-hot encoded.\" , \"bitwidth\" : 4 , \"controllable\" : false } ] }, { \"code\" : 9 , \"name\" : \"BW\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"config\" , \"comment\" : \"Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit\" , \"bitwidth\" : 2 } ] }, { \"code\" : 10 , \"name\" : \"RACCU\" , \"phase\" : 2 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"RACCU mode\" , \"bitwidth\" : 3 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"idle\" }, { \"key\" : 1 , \"val\" : \"add\" }, { \"key\" : 2 , \"val\" : \"sub\" }, { \"key\" : 3 , \"val\" : \"shift_r\" }, { \"key\" : 4 , \"val\" : \"shift_l\" }, { \"key\" : 5 , \"val\" : \"mult\" }, { \"key\" : 6 , \"val\" : \"mult_add\" }, { \"key\" : 7 , \"val\" : \"mult_sub\" } ] }, { \"name\" : \"operand1_sd\" , \"comment\" : \"Is the first operand static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"operand1\" , \"comment\" : \"First operand.\" , \"bitwidth\" : 7 }, { \"name\" : \"operand2_sd\" , \"comment\" : \"Is the second operand static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"operand2\" , \"comment\" : \"Second operand.\" , \"bitwidth\" : 7 }, { \"name\" : \"result\" , \"comment\" : \"The RACCU register to store the result.\" , \"bitwidth\" : 4 } ] }, { \"code\" : 11 , \"name\" : \"BRANCH\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"The branch mode\" , \"bitwidth\" : 2 }, { \"name\" : \"false_pc\" , \"comment\" : \"The PC to jump to in case the condition is false.\" , \"bitwidth\" : 6 } ] }, { \"code\" : 12 , \"name\" : \"ROUTE\" , \"phase\" : 4 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"horizontal_dir\" , \"comment\" : \"The horizontal direction: West or East.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"w\" }, { \"key\" : 1 , \"val\" : \"e\" } ] }, { \"name\" : \"horizontal_hops\" , \"comment\" : \"The horizontal hops.\" , \"bitwidth\" : 3 }, { \"name\" : \"vertical_dir\" , \"comment\" : \"The vertical direction: South or North.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"n\" } ] }, { \"name\" : \"vertical_hops\" , \"comment\" : \"The vertical hops.\" , \"bitwidth\" : 3 }, { \"name\" : \"direction\" , \"comment\" : \"The data transfer direction: Read or Write.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"r\" }, { \"key\" : 1 , \"val\" : \"w\" } ] }, { \"name\" : \"select_drra_row\" , \"comment\" : \"The drra row that send/recieve the data.\" , \"bitwidth\" : 1 } ] }, { \"code\" : 13 , \"name\" : \"SRAM\" , \"phase\" : 5 , \"max_chunk\" : 3 , \"segment_templates\" : [ { \"name\" : \"rw\" , \"comment\" : \"Read or Write\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"r\" }, { \"key\" : 1 , \"val\" : \"w\" } ] }, { \"name\" : \"init_addr\" , \"comment\" : \"Initial address\" , \"bitwidth\" : 7 }, { \"name\" : \"init_delay\" , \"comment\" : \"initial delay\" , \"bitwidth\" : 4 , \"controllable\" : true }, { \"name\" : \"l1_iter\" , \"comment\" : \"level-1 iteration - 1.\" , \"bitwidth\" : 7 }, { \"name\" : \"l1_step\" , \"comment\" : \"level-1 step\" , \"bitwidth\" : 8 , \"default_val\" : 1 }, { \"name\" : \"l1_delay\" , \"comment\" : \"level-1 delay\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"l2_iter\" , \"comment\" : \"level-2 iteration - 1.\" , \"bitwidth\" : 7 }, { \"name\" : \"l2_step\" , \"comment\" : \"level-2 step\" , \"bitwidth\" : 8 , \"default_val\" : 1 }, { \"name\" : \"l2_delay\" , \"comment\" : \"level-2 delay\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"init_addr_sd\" , \"comment\" : \"Is initial address static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_iter_sd\" , \"comment\" : \"Is level-1 iteration static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_iter_sd\" , \"comment\" : \"Is level-2 iteration static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_delay_sd\" , \"comment\" : \"Is initial delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_delay_sd\" , \"comment\" : \"Is level-1 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_delay_sd\" , \"comment\" : \"Is level-2 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_step_sd\" , \"comment\" : \"Is level-1 step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_step_sd\" , \"comment\" : \"Is level-2 step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"hops\" , \"comment\" : \"Number of hops to reach the DiMArch cell - 1\" , \"bitwidth\" : 4 } ] } ] }","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#instruction-set","text":"","title":"Instruction Set"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#instructions","text":"Note Instruction fields marked by bold font are controllable and observable. Users can modify these fields in Manas input file.","title":"Instructions"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#halt","text":"Field Position Width Default Value Description instr_code [26, 23] 4 0 Instruction code for HALT","title":"HALT"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#refi","text":"Field Position Width Default Value Description instr_code [80, 77] 4 1 Instruction code for REFI port_no [76, 75] 2 0 Selects one of the RFile port. [0]:w0; [1]:w1; [2]:r0; [3]:r1; extra [74, 73] 2 0 How many following chunks? init_addr_sd [72, 72] 1 0 Is init_addr static or dymamic? [0]:s; [1]:d; init_addr [71, 66] 6 0 Initial address. l1_iter [65, 60] 6 0 Level-1 iteration - 1. init_delay [59, 54] 6 0 Initial delay. l1_iter_sd [53, 53] 1 0 Is level-1 iteration static or dymamic? [0]:s; [1]:d; init_delay_sd [52, 52] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; unused_0 [51, 50] 2 2 Deprecated. l1_step_sd [49, 49] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l1_step [48, 43] 6 1 Level-1 step l1_step_sign [42, 42] 1 0 The sign of level-1 step. [0]:+; [1]:-; l1_delay_sd [41, 41] 1 0 Is the level-1 delay static or dynamic? [0]:s; [1]:d; l1_delay [40, 37] 4 0 The level-1 delay, middle delay l2_iter_sd [36, 36] 1 0 Is level-2 iteration static or dymamic? [0]:s; [1]:d; l2_iter [35, 31] 5 0 The level-2 iteration - 1. l2_step [30, 27] 4 1 The level-2 step. unused_1 [26, 23] 4 3 Deprecated. l2_delay_sd [22, 22] 1 0 Is the level-2 delay static or dynamic? [0]:s; [1]:d; l2_delay [21, 16] 6 0 The level-2 delay, repetition delay. unused_2 [15, 10] 6 0 Deprecated. l1_delay_ext [9, 8] 2 0 The extened bits near MSB of l1_delay. l2_iter_ext [7, 7] 1 0 The extened bits near MSB of l2_iter. l2_step_ext [6, 5] 2 0 The extened bits near MSB of l2_step. unused_3 [4, 2] 3 0 Deprecated. dimarch [1, 1] 1 0 Is reading/writing from/to DiMArch? [0]:n; [1]:y; compress [0, 0] 1 0 Is the data compressed? [0]:n; [1]:y;","title":"REFI"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#dpu","text":"Field Position Width Default Value Description instr_code [26, 23] 4 4 Instruction code for DPU mode [22, 18] 5 0 The DPU mode. [0]:idle; [1]:add; [2]:sum_acc; [3]:add_const; [4]:subt; [5]:subt_abs; [6]:mode_6; [7]:mult; [8]:mult_add; [9]:mult_const; [10]:mac; [11]:ld_ir; [12]:axpy; [13]:max_min_acc; [14]:max_min_const; [15]:mode_15; [16]:max_min; [17]:shift_l; [18]:shift_r; [19]:sigm; [20]:tanhyp; [21]:expon; [22]:lk_relu; [23]:relu; [24]:div; [25]:acc_softmax; [26]:div_softmax; [27]:ld_acc; [28]:scale_dw; [29]:scale_up; [30]:mac_inter; [31]:mode_31; control [17, 16] 2 2 The controll mode: saturation and operator type. [0]:nosat_int; [1]:nosat_fx; [2]:sat_int; [3]:sat_fx; unused_0 [15, 10] 6 2 Deprecated. acc_clear [9, 2] 8 0 The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode. io_change [1, 0] 2 0 The IO mode: negate input and absolute output. [0]:no_change; [1]:negate_in0; [2]:negate_in1; [3]:abs_out;","title":"DPU"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#swb","text":"Field Position Width Default Value Description instr_code [26, 23] 4 5 Instruction code for SWB unused0 [22, 22] 1 1 Deprecated. src_row [21, 21] 1 0 Source row. src_block [20, 20] 1 0 Source block, RF or DPU. [0]:rf; [1]:dpu; src_port [19, 19] 1 0 source port. hb_index [18, 16] 3 0 Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0. send_to_other_row [15, 15] 1 0 Flag of whether src and dest row are equal. [0]:n; [1]:y; v_index [14, 12] 3 0 Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2.","title":"SWB"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#jump","text":"Field Position Width Default Value Description instr_code [26, 23] 4 6 Instruction code for JUMP pc [22, 17] 6 0 The PC to jump to","title":"JUMP"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#wait","text":"Field Position Width Default Value Description instr_code [26, 23] 4 7 Instruction code for WAIT cycle_sd [22, 22] 1 0 Is the cycle static or dynamic? [0]:s; [1]:d; cycle [21, 7] 15 0 Number of cycles - 1","title":"WAIT"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#loop","text":"Field Position Width Default Value Description instr_code [53, 50] 4 8 Instruction code for LOOP extra [49, 49] 1 0 How many following chunks? loopid [48, 47] 2 0 The id of the loop manager slot. endpc [46, 41] 6 0 The PC where loop ends. start_sd [40, 40] 1 0 Is the start static or dynamic? [0]:s; [1]:d; start [39, 34] 6 0 The start of iterator. iter_sd [33, 33] 1 0 Is the iteration count static or dynamic? [0]:s; [1]:d; iter [32, 27] 6 0 The number of iteration. step_sd [26, 26] 1 0 Is the step static or dynamic? [0]:s; [1]:d; step [25, 20] 6 1 The iteration step. link [19, 16] 4 0 The loops that have the same endpc will be linked together. This field is 1-hot encoded.","title":"LOOP"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#bw","text":"Field Position Width Default Value Description instr_code [26, 23] 4 9 Instruction code for BW config [22, 21] 2 0 Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit","title":"BW"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#raccu","text":"Field Position Width Default Value Description instr_code [26, 23] 4 10 Instruction code for RACCU mode [22, 20] 3 0 RACCU mode [0]:idle; [1]:add; [2]:sub; [3]:shift_r; [4]:shift_l; [5]:mult; [6]:mult_add; [7]:mult_sub; operand1_sd [19, 19] 1 0 Is the first operand static or dynamic? [0]:s; [1]:d; operand1 [18, 12] 7 0 First operand. operand2_sd [11, 11] 1 0 Is the second operand static or dynamic? [0]:s; [1]:d; operand2 [10, 4] 7 0 Second operand. result [3, 0] 4 0 The RACCU register to store the result.","title":"RACCU"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#branch","text":"Field Position Width Default Value Description instr_code [26, 23] 4 11 Instruction code for BRANCH mode [22, 21] 2 0 The branch mode false_pc [20, 15] 6 0 The PC to jump to in case the condition is false.","title":"BRANCH"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#route","text":"Field Position Width Default Value Description instr_code [26, 23] 4 12 Instruction code for ROUTE horizontal_dir [22, 22] 1 0 The horizontal direction: West or East. [0]:w; [1]:e; horizontal_hops [21, 19] 3 0 The horizontal hops. vertical_dir [18, 18] 1 0 The vertical direction: South or North. [0]:s; [1]:n; vertical_hops [17, 15] 3 0 The vertical hops. direction [14, 14] 1 0 The data transfer direction: Read or Write. [0]:r; [1]:w; select_drra_row [13, 13] 1 0 The drra row that send/recieve the data.","title":"ROUTE"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#sram","text":"Field Position Width Default Value Description instr_code [80, 77] 4 13 Instruction code for SRAM rw [76, 76] 1 0 Read or Write [0]:r; [1]:w; init_addr [75, 69] 7 0 Initial address init_delay [68, 65] 4 0 initial delay l1_iter [64, 58] 7 0 level-1 iteration - 1. l1_step [57, 50] 8 1 level-1 step l1_delay [49, 44] 6 0 level-1 delay l2_iter [43, 37] 7 0 level-2 iteration - 1. l2_step [36, 29] 8 1 level-2 step l2_delay [28, 23] 6 0 level-2 delay init_addr_sd [22, 22] 1 0 Is initial address static or dynamic? [0]:s; [1]:d; l1_iter_sd [21, 21] 1 0 Is level-1 iteration static or dynamic? [0]:s; [1]:d; l2_iter_sd [20, 20] 1 0 Is level-2 iteration static or dynamic? [0]:s; [1]:d; init_delay_sd [19, 19] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; l1_delay_sd [18, 18] 1 0 Is level-1 delay static or dynamic? [0]:s; [1]:d; l2_delay_sd [17, 17] 1 0 Is level-2 delay static or dynamic? [0]:s; [1]:d; l1_step_sd [16, 16] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l2_step_sd [15, 15] 1 0 Is level-2 step static or dynamic? [0]:s; [1]:d; hops [14, 11] 4 0 Number of hops to reach the DiMArch cell - 1","title":"SRAM"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#isa-description-file","text":"","title":"ISA Description File"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#json-schema","text":"The ISA description file uses json format and validated by the following json schema: { \"type\" : \"object\" , \"properties\" : { \"platform\" : { \"type\" : \"string\" }, \"instr_bitwidth\" : { \"type\" : \"integer\" }, \"instr_code_bitwidth\" : { \"type\" : \"integer\" }, \"instruction_templates\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"code\" : { \"type\" : \"integer\" }, \"name\" : { \"type\" : \"string\" }, \"phase\" : { \"type\" : \"integer\" }, \"max_chunk\" : { \"type\" : \"integer\" }, \"segment_templates\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"name\" : { \"type\" : \"string\" }, \"bitwidth\" : { \"type\" : \"integer\" }, \"default_val\" : { \"type\" : \"integer\" }, \"controllable\" : { \"type\" : \"boolean\" }, \"observable\" : { \"type\" : \"boolean\" }, \"verbo_map\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"object\" , \"properties\" : { \"key\" : { \"type\" : \"integer\" }, \"val\" : { \"type\" : \"string\" } } } }, \"comment\" : { \"type\" : \"string\" } }, \"required\" : [ \"name\" , \"bitwidth\" , \"comment\" ] }, \"uniqueItems\" : true } }, \"required\" : [ \"code\" , \"name\" ] }, \"uniqueItems\" : true } }, \"required\" : [ \"platform\" , \"instr_bitwidth\" , \"instr_code_bitwidth\" , \"instruction_templates\" ] } Note You can validate a ISA description json file using this schema on Json Schema Validator .","title":"JSON Schema"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/#json","text":"The ISA description file used for DRRA is shown as follow: { \"platform\" : \"SiLago 1\" , \"instr_bitwidth\" : 27 , \"instr_code_bitwidth\" : 4 , \"instruction_templates\" : [ { \"code\" : 0 , \"name\" : \"HALT\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [] }, { \"code\" : 1 , \"name\" : \"REFI\" , \"phase\" : 4 , \"max_chunk\" : 3 , \"segment_templates\" : [ { \"name\" : \"port_no\" , \"comment\" : \"Selects one of the RFile port.\" , \"bitwidth\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"w0\" }, { \"key\" : 1 , \"val\" : \"w1\" }, { \"key\" : 2 , \"val\" : \"r0\" }, { \"key\" : 3 , \"val\" : \"r1\" } ] }, { \"name\" : \"extra\" , \"comment\" : \"How many following chunks?\" , \"bitwidth\" : 2 }, { \"name\" : \"init_addr_sd\" , \"comment\" : \"Is init_addr static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_addr\" , \"comment\" : \"Initial address.\" , \"bitwidth\" : 6 }, { \"name\" : \"l1_iter\" , \"comment\" : \"Level-1 iteration - 1.\" , \"bitwidth\" : 6 }, { \"name\" : \"init_delay\" , \"comment\" : \"Initial delay.\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"l1_iter_sd\" , \"comment\" : \"Is level-1 iteration static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_delay_sd\" , \"comment\" : \"Is initial delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"unused_0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 2 , \"default_val\" : 2 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l1_step_sd\" , \"comment\" : \"Is level-1 step static or dynamic?\" , \"bitwidth\" : 1 , \"default_val\" : 0 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_step\" , \"comment\" : \"Level-1 step\" , \"bitwidth\" : 6 , \"default_val\" : 1 }, { \"name\" : \"l1_step_sign\" , \"comment\" : \"The sign of level-1 step.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"+\" }, { \"key\" : 1 , \"val\" : \"-\" } ] }, { \"name\" : \"l1_delay_sd\" , \"comment\" : \"Is the level-1 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_delay\" , \"comment\" : \"The level-1 delay, middle delay\" , \"bitwidth\" : 4 , \"controllable\" : true }, { \"name\" : \"l2_iter_sd\" , \"comment\" : \"Is level-2 iteration static or dymamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_iter\" , \"comment\" : \"The level-2 iteration - 1.\" , \"bitwidth\" : 5 }, { \"name\" : \"l2_step\" , \"comment\" : \"The level-2 step.\" , \"bitwidth\" : 4 , \"default_val\" : 1 }, { \"name\" : \"unused_1\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 4 , \"default_val\" : 3 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l2_delay_sd\" , \"comment\" : \"Is the level-2 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_delay\" , \"comment\" : \"The level-2 delay, repetition delay.\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"unused_2\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 6 , \"default_val\" : 0 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"l1_delay_ext\" , \"comment\" : \"The extened bits near MSB of l1_delay.\" , \"controllable\" : true , \"bitwidth\" : 2 }, { \"name\" : \"l2_iter_ext\" , \"comment\" : \"The extened bits near MSB of l2_iter.\" , \"bitwidth\" : 1 }, { \"name\" : \"l2_step_ext\" , \"comment\" : \"The extened bits near MSB of l2_step.\" , \"bitwidth\" : 2 }, { \"name\" : \"unused_3\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 3 , \"default_val\" : 0 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"dimarch\" , \"comment\" : \"Is reading/writing from/to DiMArch?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] }, { \"name\" : \"compress\" , \"comment\" : \"Is the data compressed?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] } ] }, { \"code\" : 4 , \"name\" : \"DPU\" , \"phase\" : 4 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"The DPU mode.\" , \"bitwidth\" : 5 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"idle\" }, { \"key\" : 1 , \"val\" : \"add\" }, { \"key\" : 2 , \"val\" : \"sum_acc\" }, { \"key\" : 3 , \"val\" : \"add_const\" }, { \"key\" : 4 , \"val\" : \"subt\" }, { \"key\" : 5 , \"val\" : \"subt_abs\" }, { \"key\" : 6 , \"val\" : \"mode_6\" }, { \"key\" : 7 , \"val\" : \"mult\" }, { \"key\" : 8 , \"val\" : \"mult_add\" }, { \"key\" : 9 , \"val\" : \"mult_const\" }, { \"key\" : 10 , \"val\" : \"mac\" }, { \"key\" : 11 , \"val\" : \"ld_ir\" }, { \"key\" : 12 , \"val\" : \"axpy\" }, { \"key\" : 13 , \"val\" : \"max_min_acc\" }, { \"key\" : 14 , \"val\" : \"max_min_const\" }, { \"key\" : 15 , \"val\" : \"mode_15\" }, { \"key\" : 16 , \"val\" : \"max_min\" }, { \"key\" : 17 , \"val\" : \"shift_l\" }, { \"key\" : 18 , \"val\" : \"shift_r\" }, { \"key\" : 19 , \"val\" : \"sigm\" }, { \"key\" : 20 , \"val\" : \"tanhyp\" }, { \"key\" : 21 , \"val\" : \"expon\" }, { \"key\" : 22 , \"val\" : \"lk_relu\" }, { \"key\" : 23 , \"val\" : \"relu\" }, { \"key\" : 24 , \"val\" : \"div\" }, { \"key\" : 25 , \"val\" : \"acc_softmax\" }, { \"key\" : 26 , \"val\" : \"div_softmax\" }, { \"key\" : 27 , \"val\" : \"ld_acc\" }, { \"key\" : 28 , \"val\" : \"scale_dw\" }, { \"key\" : 29 , \"val\" : \"scale_up\" }, { \"key\" : 30 , \"val\" : \"mac_inter\" }, { \"key\" : 31 , \"val\" : \"mode_31\" } ] }, { \"name\" : \"control\" , \"comment\" : \"The controll mode: saturation and operator type.\" , \"bitwidth\" : 2 , \"default_val\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"nosat_int\" }, { \"key\" : 1 , \"val\" : \"nosat_fx\" }, { \"key\" : 2 , \"val\" : \"sat_int\" }, { \"key\" : 3 , \"val\" : \"sat_fx\" } ] }, { \"name\" : \"unused_0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 6 , \"default_val\" : 2 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"acc_clear\" , \"comment\" : \"The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode.\" , \"bitwidth\" : 8 }, { \"id\" : 4 , \"name\" : \"io_change\" , \"comment\" : \"The IO mode: negate input and absolute output.\" , \"bitwidth\" : 2 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"no_change\" }, { \"key\" : 1 , \"val\" : \"negate_in0\" }, { \"key\" : 2 , \"val\" : \"negate_in1\" }, { \"key\" : 3 , \"val\" : \"abs_out\" } ] } ] }, { \"code\" : 5 , \"name\" : \"SWB\" , \"phase\" : 3 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"unused0\" , \"comment\" : \"Deprecated.\" , \"bitwidth\" : 1 , \"default_val\" : 1 , \"controllable\" : false , \"observable\" : false }, { \"name\" : \"src_row\" , \"comment\" : \"Source row.\" , \"bitwidth\" : 1 }, { \"name\" : \"src_block\" , \"comment\" : \"Source block, RF or DPU.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"rf\" }, { \"key\" : 1 , \"val\" : \"dpu\" } ] }, { \"name\" : \"src_port\" , \"comment\" : \"source port.\" , \"bitwidth\" : 1 }, { \"name\" : \"hb_index\" , \"comment\" : \"Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0.\" , \"bitwidth\" : 3 }, { \"name\" : \"send_to_other_row\" , \"comment\" : \"Flag of whether src and dest row are equal.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"n\" }, { \"key\" : 1 , \"val\" : \"y\" } ] }, { \"name\" : \"v_index\" , \"comment\" : \"Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2.\" , \"bitwidth\" : 3 } ] }, { \"code\" : 6 , \"name\" : \"JUMP\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"pc\" , \"comment\" : \"The PC to jump to\" , \"bitwidth\" : 6 } ] }, { \"code\" : 7 , \"name\" : \"WAIT\" , \"phase\" : 2 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"cycle_sd\" , \"comment\" : \"Is the cycle static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"cycle\" , \"comment\" : \"Number of cycles - 1\" , \"bitwidth\" : 15 } ] }, { \"code\" : 8 , \"name\" : \"LOOP\" , \"phase\" : 1 , \"max_chunk\" : 2 , \"segment_templates\" : [ { \"name\" : \"extra\" , \"comment\" : \"How many following chunks?\" , \"bitwidth\" : 1 }, { \"name\" : \"loopid\" , \"comment\" : \"The id of the loop manager slot.\" , \"bitwidth\" : 2 }, { \"name\" : \"endpc\" , \"comment\" : \"The PC where loop ends.\" , \"bitwidth\" : 6 }, { \"name\" : \"start_sd\" , \"comment\" : \"Is the start static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"start\" , \"comment\" : \"The start of iterator.\" , \"bitwidth\" : 6 }, { \"name\" : \"iter_sd\" , \"comment\" : \"Is the iteration count static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"iter\" , \"comment\" : \"The number of iteration.\" , \"bitwidth\" : 6 }, { \"name\" : \"step_sd\" , \"comment\" : \"Is the step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"step\" , \"comment\" : \"The iteration step.\" , \"bitwidth\" : 6 , \"default_val\" : 1 }, { \"name\" : \"link\" , \"comment\" : \"The loops that have the same endpc will be linked together. This field is 1-hot encoded.\" , \"bitwidth\" : 4 , \"controllable\" : false } ] }, { \"code\" : 9 , \"name\" : \"BW\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"config\" , \"comment\" : \"Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit\" , \"bitwidth\" : 2 } ] }, { \"code\" : 10 , \"name\" : \"RACCU\" , \"phase\" : 2 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"RACCU mode\" , \"bitwidth\" : 3 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"idle\" }, { \"key\" : 1 , \"val\" : \"add\" }, { \"key\" : 2 , \"val\" : \"sub\" }, { \"key\" : 3 , \"val\" : \"shift_r\" }, { \"key\" : 4 , \"val\" : \"shift_l\" }, { \"key\" : 5 , \"val\" : \"mult\" }, { \"key\" : 6 , \"val\" : \"mult_add\" }, { \"key\" : 7 , \"val\" : \"mult_sub\" } ] }, { \"name\" : \"operand1_sd\" , \"comment\" : \"Is the first operand static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"operand1\" , \"comment\" : \"First operand.\" , \"bitwidth\" : 7 }, { \"name\" : \"operand2_sd\" , \"comment\" : \"Is the second operand static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"operand2\" , \"comment\" : \"Second operand.\" , \"bitwidth\" : 7 }, { \"name\" : \"result\" , \"comment\" : \"The RACCU register to store the result.\" , \"bitwidth\" : 4 } ] }, { \"code\" : 11 , \"name\" : \"BRANCH\" , \"phase\" : 1 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"mode\" , \"comment\" : \"The branch mode\" , \"bitwidth\" : 2 }, { \"name\" : \"false_pc\" , \"comment\" : \"The PC to jump to in case the condition is false.\" , \"bitwidth\" : 6 } ] }, { \"code\" : 12 , \"name\" : \"ROUTE\" , \"phase\" : 4 , \"max_chunk\" : 1 , \"segment_templates\" : [ { \"name\" : \"horizontal_dir\" , \"comment\" : \"The horizontal direction: West or East.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"w\" }, { \"key\" : 1 , \"val\" : \"e\" } ] }, { \"name\" : \"horizontal_hops\" , \"comment\" : \"The horizontal hops.\" , \"bitwidth\" : 3 }, { \"name\" : \"vertical_dir\" , \"comment\" : \"The vertical direction: South or North.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"n\" } ] }, { \"name\" : \"vertical_hops\" , \"comment\" : \"The vertical hops.\" , \"bitwidth\" : 3 }, { \"name\" : \"direction\" , \"comment\" : \"The data transfer direction: Read or Write.\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"r\" }, { \"key\" : 1 , \"val\" : \"w\" } ] }, { \"name\" : \"select_drra_row\" , \"comment\" : \"The drra row that send/recieve the data.\" , \"bitwidth\" : 1 } ] }, { \"code\" : 13 , \"name\" : \"SRAM\" , \"phase\" : 5 , \"max_chunk\" : 3 , \"segment_templates\" : [ { \"name\" : \"rw\" , \"comment\" : \"Read or Write\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"r\" }, { \"key\" : 1 , \"val\" : \"w\" } ] }, { \"name\" : \"init_addr\" , \"comment\" : \"Initial address\" , \"bitwidth\" : 7 }, { \"name\" : \"init_delay\" , \"comment\" : \"initial delay\" , \"bitwidth\" : 4 , \"controllable\" : true }, { \"name\" : \"l1_iter\" , \"comment\" : \"level-1 iteration - 1.\" , \"bitwidth\" : 7 }, { \"name\" : \"l1_step\" , \"comment\" : \"level-1 step\" , \"bitwidth\" : 8 , \"default_val\" : 1 }, { \"name\" : \"l1_delay\" , \"comment\" : \"level-1 delay\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"l2_iter\" , \"comment\" : \"level-2 iteration - 1.\" , \"bitwidth\" : 7 }, { \"name\" : \"l2_step\" , \"comment\" : \"level-2 step\" , \"bitwidth\" : 8 , \"default_val\" : 1 }, { \"name\" : \"l2_delay\" , \"comment\" : \"level-2 delay\" , \"bitwidth\" : 6 , \"controllable\" : true }, { \"name\" : \"init_addr_sd\" , \"comment\" : \"Is initial address static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_iter_sd\" , \"comment\" : \"Is level-1 iteration static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_iter_sd\" , \"comment\" : \"Is level-2 iteration static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"init_delay_sd\" , \"comment\" : \"Is initial delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_delay_sd\" , \"comment\" : \"Is level-1 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_delay_sd\" , \"comment\" : \"Is level-2 delay static or dynamic?\" , \"bitwidth\" : 1 , \"controllable\" : true , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l1_step_sd\" , \"comment\" : \"Is level-1 step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"l2_step_sd\" , \"comment\" : \"Is level-2 step static or dynamic?\" , \"bitwidth\" : 1 , \"verbo_map\" : [ { \"key\" : 0 , \"val\" : \"s\" }, { \"key\" : 1 , \"val\" : \"d\" } ] }, { \"name\" : \"hops\" , \"comment\" : \"Number of hops to reach the DiMArch cell - 1\" , \"bitwidth\" : 4 } ] } ] }","title":"JSON"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/","text":"Manas Programming Guide Note This page is written for both vesyla-suite version 2 and version 3 . Warning This programming guide is intended to fine-grained control of Manas. We do not recommend you to use this guide unless you are familiar with the internal structure of Manas. For most cases, you can use the Vesyla Programming Guide to generate inputs for Manas. Basics General Guide Manas is an assembler for SiLago platform (DRRA+DiMArch). It accepts defination of instructions and their dependencies and generates a RTL testbench for simulation. Manas uses the scheduling engine of Vesyla to schedule these instructions based on user-defined dependencies. The input file of Manas is a plan text file with four segments: the DATA segment the CODE segment the RELATION segment the DEPENDENCY segment. DATA Segment Data layout in DiMArch and Register Files are defined in DATA segment. A DATA segment starts with a segment identifier: .DATA A variable is defined by the following syntax: VAR_NAME VAR_LOCATION VAR_TYPE ROW COL INIT_DATA VAR_NAME: the name of a variable. It must start with the symbol $ . It must be unique. VAR_LOCATION: the location of the varialbe, either DiMArch (VAR_LOCATION=1) or Register File (VAR_LOCATION=0). VAR_TYPE: the type of the variable, either integer (VAR_TYPE=0) or fixpoint(VAR_TYPE=1) ROW & COL: The coordinate of the DiMArch or Register File. INIT_DATA: The initialization data of the variable. It also defines the variable size. The size must be multiple of 16 for DiMArch variables since each DiMArch row has 16 words. To initialize the variable, one can use any of the following method: Example Example of variable initialization $A 1 0 0 0 ONES(16) $B 1 0 0 0 ZEROS(16) $C 1 0 0 0 [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1] CODE Segment Instructions are defined in CODE segment. A CODE segment starts with segment identifier: .CODE All statements after the CODE segment identifer and before any other segment identifier are considered part of the CODE segment. A code segment can include multiple sections leading by a cell location identifier: CELL <r, c> It defines the coordinate in terms of row ( r ) and column ( c ) of each instructions that follow it. It applies to all instructions until another cell location identifier or the end of the CODE segment. An instruction consists a instruction name and an argument list. They are seperated by space. All arguments should be integers unless specified otherwise. You can find all supported instructions in the Instruction Set . Each instruction has multiple fields. Some fields are controllable which means one can set the value of that field through the assembly language. All the controllable fields are marked by bold text in the Instruction Set . Each field in an instruction has a default value. In the Instruction Set page, the default value is explicitly written in the Range/Value section unless the default value is 0. While wring the Assebly language, you only need to set the field whoes expected value is not the default value. To write a instruction, use the following format: LABEL INSTR_NAME NAME_0 = VALUE_0, NAME_1 = VALUE_1, ... Example This is a example for code segment .CODE CELL <0,0> \"label_0\" REFI port_no=2, init_addr=16 \"label_1\" REFI port_no=0 \"label_2\" DPU mode=10 RELATION Segment Relation segment specifies the hierarchical structure of the mapping. The entire mapping is organized as a hierarichical graph. The outer most node is called ROOT . Inside the ROOT node, there are other nodes, such as loop node, branch node, and other normal instruction node. Each node represents either an hierarchical structure or an instruction phase. For example, a node can represent the whole loop structure and it contains all instructions and inner loops inside its children graph. Each instruction in the CODE segment can be divided into multiple instruction phases. Each phase marks a critical timing point when the instruction changes behavior. For example, a REFI instruction has four phases: FETCH, ISSUE, ACTIVE, and END. The name of the node that represents an instruction phase is to combine the instruction label and the phase index. For example, if a REFI instruction has a label called instr_refi_0 , then the FETCH phase will be mapped to the node named as instr_refi_0_0 since the FETCH phase is the first phase of the REFI instruction. See Instruction Phase Each relation record in the RELATION segment specifies the children of one hierarchical node. The format is: \"NODE_NAME\" 1 IS_BULK [NODE0_IN_CHILD0, NODE1_IN_CHILD0, ...] [NODE0_IN_CHILD1, NODE1_IN_CHILD1, ...] EXPAND_LOOP The NODE_NAME can be any string, it's the name of the hierarchical node. The second parameter is deprecated, it's always 1. The third parameter IS_BULK specifies whether this node should be treated as bulk node. A bulk node does not allow overlap with other nodes. The array of child0 and child1 are used to specify the children node in the 0 th and 1th child graph. All hierarchical node other than IF-ELSE branch has only child0. The brach node has two children, child0 is the true branch, and child1 is the false branch. The last parameter is the EXPAND_LOOP. It's a flag to suggest the assembler to do cross-iteration software pipelining. Note The IS_BULK and EXPAND_LOOP are very confusing in manas. We will modify manas to make it more clear. Right now, all nodes other than loop should set both parameters to 0. For most inner loop, you should let IS_BULK=0 and EXPAND_LOOP=1. For other loops, set IS_BULK=1 and EXPAND_LOOP=1. When write node names in child graph array, you can use regular expression to include a group of nodes. For example, instr_refi_0_.* will include all the phases of the instruction named as \"instr_refi_0\". Example This is a example for relation segment .CODE CELL <0,0> \"instr0\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0, select_drra_row=0 \"instr1\" SWB src_row=0, src_block=0, src_port=0, hb_index=2, send_to_other_row=0, v_index=2 \"instr2\" SWB src_row=0, src_block=0, src_port=0, hb_index=3, send_to_other_row=0, v_index=3 \"instr3\" SWB src_row=0, src_block=0, src_port=1, hb_index=2, send_to_other_row=0, v_index=4 \"instr4\" SWB src_row=0, src_block=0, src_port=1, hb_index=3, send_to_other_row=0, v_index=5 \"instr5\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr6\" LOOP loopid=1, iter=3, step=2 \"instr7\" RACCU mode=1, operand1_sd=1, operand1=14, operand2_sd=1, operand2=15, result=0 \"instr8\" SRAM rw=0, init_addr=0, l1_iter=3, l1_step=1, l1_delay=0, init_addr_sd=1, hops=0 \"instr9\" REFI port_no=0, extra=2, init_addr_sd=0, init_addr=0, l1_iter=3, l1_step=1, l1_delay=0, dimarch=1 \"instr10\" REFI port_no=2, extra=2, init_addr=0, l1_iter=3, l1_step=1, l2_delay=2, l2_iter=28, l2_step=1 \"instr11\" REFI port_no=3, extra=2, init_addr=32, l1_iter=3, l1_step=1, l2_delay=2, l2_iter=28, l2_step=1 \"instr12\" LOOP loopid=2, iter=29, step=1 \"instr13\" DPU mode=10, control=2 CELL <0,1> \"instr14\" DPU mode=1, control=2 \"instr15\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0 \"instr16\" SWB src_row=0, src_block=1, src_port=0, hb_index=1, v_index=2 \"instr17\" SWB src_row=0, src_block=1, src_port=1, hb_index=1, v_index=3 \"instr18\" SRAM l1_iter=1, l1_step=1, l1_delay=0, l2_iter=1, l2_step=2, l2_delay=0, hops=0 \"instr19\" REFI port_no=0, extra=2, l1_iter=1, l1_step=1, dimarch=1 \"instr20\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr21\" LOOP extra=0, loopid=1, iter=3, step=2 \"instr22\" REFI port_no=2, extra=2, init_addr= 0, l1_iter=3, l1_step=1, l2_iter=28, l2_delay=2, l2_step=0 \"instr23\" REFI port_no=3, extra=2, init_addr=16, l1_iter=3, l1_step=1, l2_iter=28, l2_delay=2, l2_step=0 \"instr24\" LOOP loopid=2, iter=29, step=1 CELL <0,2> \"instr25\" DPU mode=1, control=2 \"instr26\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0 \"instr27\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=1 \"instr28\" SWB src_row=0, src_block=0, src_port=1, hb_index=2, v_index=2 \"instr29\" SWB src_row=0, src_block=1, src_port=0, hb_index=2, v_index=1 \"instr30\" SWB src_row=0, src_block=1, src_port=0, hb_index=1, v_index=3 \"instr31\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr32\" REFI port_no=3, extra=2, l1_step=1, l1_iter=28, l1_delay=5, l2_iter=2, l2_delay=25, l2_step=0 \"instr33\" REFI port_no=1, extra=2, l1_step=1, l1_iter=28, l1_delay=5, l2_iter=2, l2_delay=25, l2_step=0 \"instr34\" LOOP extra=0, loopid=1, iter=3, step=2 \"instr35\" SRAM rw=0, l1_iter=1, l1_step=1, l1_delay=0, hops=0, init_addr_sd=d, init_addr=14 \"instr36\" REFI port_no=0, extra=2, l1_iter=1, l1_step=1, dimarch=1 \"instr37\" LOOP loopid=2, iter=29, step=1 \"instr38\" SRAM rw=1, l1_iter=1, l1_step=1, l1_delay=0, hops= 0, init_addr_sd=d, init_addr=14 \"instr39\" REFI port_no=2, extra=2, l1_iter=1, l1_step=1, dimarch=1 .RELATION \"ROOT\" 1 0 [\"LOOP0\",\"Op_0_0_0_1\", \"Op_0_0_0_2\", \"Op_0_0_1_1\", \"Op_0_0_1_2\", \"Op_0_0_2_1\",\"Op_0_0_2_2\", \"Op_0_0_3_1\", \"Op_0_0_3_2\", \"Op_0_0_4_1\", \"Op_0_0_4_2\",\"Op_0_1_0_1\", \"Op_0_1_0_2\", \"Op_0_1_0_3\", \"Op_0_1_1_1\", \"Op_0_1_1_2\",\"Op_0_1_2_1\", \"Op_0_1_2_2\", \"Op_0_1_3_1\", \"Op_0_1_3_2\", \"Op_0_1_4_1\", \"Op_0_1_4_2\", \"Op_0_1_5_1\",\"Op_0_2_0_1\", \"Op_0_2_0_2\", \"Op_0_2_0_3\", \"Op_0_2_1_1\", \"Op_0_2_1_2\",\"Op_0_2_2_1\", \"Op_0_2_2_2\", \"Op_0_2_3_1\", \"Op_0_2_3_2\", \"Op_0_2_4_1\", \"Op_0_2_4_2\",\"Op_0_2_5_1\", \"Op_0_2_5_2\"] [] 0 \"LOOP0\" 1 1 [\"LOOP0_BODY\",\"Op_0_0_5_1\",\"Op_0_1_6_1\",\"Op_0_2_6_1\"] [] 1 \"LOOP0_BODY\" 1 0 [\"LOOP1\",\"Op_0_1_4_3\", \"Op_0_1_4_4\", \"Op_0_1_5_2\", \"Op_0_1_5_3\",\"Op_0_2_7_1\",\"Op_0_2_8_1\"] [] 0 \"LOOP1\" 1 1 [\"LOOP1_BODY\",\"Op_0_0_6_1\",\"Op_0_1_7_1\",\"Op_0_2_9_1\"] [] 1 \"LOOP1_BODY\" 1 0 [\"LOOP2\",\"Op_0_0_7_1\", \"Op_0_0_8_1\", \"Op_0_0_8_2\", \"Op_0_0_8_3\", \"Op_0_0_8_4\", \"Op_0_0_10_1\", \"Op_0_0_11_1\",\"Op_0_0_9_1\", \"Op_0_0_9_2\", \"Op_0_0_9_3\",\"Op_0_1_8_1\", \"Op_0_1_9_1\", \"Op_0_2_10_1\", \"Op_0_2_10_2\", \"Op_0_2_10_3\", \"Op_0_2_10_4\",\"Op_0_2_11_1\",\"Op_0_2_11_2\", \"Op_0_2_11_3\",\"Op_0_2_13_1\",\"Op_0_2_13_2\",\"Op_0_2_13_3\", \"Op_0_2_13_4\", \"Op_0_2_14_1\", \"Op_0_2_14_2\",\"Op_0_2_14_3\"] [] 0 \"LOOP2\" 1 0 [\"LOOP2_BODY\", \"Op_0_0_12_1\",\"Op_0_1_10_1\", \"Op_0_2_12_1\"] [] 1 \"LOOP2_BODY\" 1 0 [\"Op_0_0_13_1\", \"Op_0_0_13_2\", \"Op_0_0_13_3\", \"Op_0_0_10_2\", \"Op_0_0_10_3\", \"Op_0_0_11_2\",\"Op_0_0_11_3\", \"Op_0_1_8_2\", \"Op_0_1_8_3\", \"Op_0_1_9_2\", \"Op_0_1_9_3\",\"Op_0_2_7_2\",\"Op_0_2_7_3\", \"Op_0_2_8_2\",\"Op_0_2_8_3\"] [] 0 DEPENDENCY Segment Dependencies among instructions are defined in dependency segment. A dependency segment starts with segment identifier: .DEPENDENCY Each instruction of DRRA has 5 phases: FETCH, ISSUE, ARRIVE, ACTIVE, END. They are represented by number: 1 to 5 respectively. User can define dependencies among instruction phases. These dependencies will guide the scheduler to order instructions properly. Each phase corresponds to a vertex in the dependency graph. You should know the naming convension when reference those phases. For example, the 2 nd phase of the 1 st instruction in cell <3,5> will be mapped to a vertex called Op_3_5_0_2 . A dependency is defined by four fields: SRC : the source vertex name. DEST: the destination vertex name. D_LO: the lower bound of distance. D_HI: the higher bound of distance. The format is: SRC DEST D_LO D_HI Example This is a example for dependency segment .DEPENDENCY \"0_0_0_0\" \"0_0_1_1\" 1 +INF \"0_0_1_1\" \"0_0_1_3\" 0 +INF \"1_0_1_1\" \"1_0_1_1\" 2 5","title":"Manas Programming Guide"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#manas-programming-guide","text":"Note This page is written for both vesyla-suite version 2 and version 3 . Warning This programming guide is intended to fine-grained control of Manas. We do not recommend you to use this guide unless you are familiar with the internal structure of Manas. For most cases, you can use the Vesyla Programming Guide to generate inputs for Manas.","title":"Manas Programming Guide"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#basics","text":"","title":"Basics"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#general-guide","text":"Manas is an assembler for SiLago platform (DRRA+DiMArch). It accepts defination of instructions and their dependencies and generates a RTL testbench for simulation. Manas uses the scheduling engine of Vesyla to schedule these instructions based on user-defined dependencies. The input file of Manas is a plan text file with four segments: the DATA segment the CODE segment the RELATION segment the DEPENDENCY segment.","title":"General Guide"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#data-segment","text":"Data layout in DiMArch and Register Files are defined in DATA segment. A DATA segment starts with a segment identifier: .DATA A variable is defined by the following syntax: VAR_NAME VAR_LOCATION VAR_TYPE ROW COL INIT_DATA VAR_NAME: the name of a variable. It must start with the symbol $ . It must be unique. VAR_LOCATION: the location of the varialbe, either DiMArch (VAR_LOCATION=1) or Register File (VAR_LOCATION=0). VAR_TYPE: the type of the variable, either integer (VAR_TYPE=0) or fixpoint(VAR_TYPE=1) ROW & COL: The coordinate of the DiMArch or Register File. INIT_DATA: The initialization data of the variable. It also defines the variable size. The size must be multiple of 16 for DiMArch variables since each DiMArch row has 16 words. To initialize the variable, one can use any of the following method: Example Example of variable initialization $A 1 0 0 0 ONES(16) $B 1 0 0 0 ZEROS(16) $C 1 0 0 0 [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1]","title":"DATA Segment"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#code-segment","text":"Instructions are defined in CODE segment. A CODE segment starts with segment identifier: .CODE All statements after the CODE segment identifer and before any other segment identifier are considered part of the CODE segment. A code segment can include multiple sections leading by a cell location identifier: CELL <r, c> It defines the coordinate in terms of row ( r ) and column ( c ) of each instructions that follow it. It applies to all instructions until another cell location identifier or the end of the CODE segment. An instruction consists a instruction name and an argument list. They are seperated by space. All arguments should be integers unless specified otherwise. You can find all supported instructions in the Instruction Set . Each instruction has multiple fields. Some fields are controllable which means one can set the value of that field through the assembly language. All the controllable fields are marked by bold text in the Instruction Set . Each field in an instruction has a default value. In the Instruction Set page, the default value is explicitly written in the Range/Value section unless the default value is 0. While wring the Assebly language, you only need to set the field whoes expected value is not the default value. To write a instruction, use the following format: LABEL INSTR_NAME NAME_0 = VALUE_0, NAME_1 = VALUE_1, ... Example This is a example for code segment .CODE CELL <0,0> \"label_0\" REFI port_no=2, init_addr=16 \"label_1\" REFI port_no=0 \"label_2\" DPU mode=10","title":"CODE Segment"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#relation-segment","text":"Relation segment specifies the hierarchical structure of the mapping. The entire mapping is organized as a hierarichical graph. The outer most node is called ROOT . Inside the ROOT node, there are other nodes, such as loop node, branch node, and other normal instruction node. Each node represents either an hierarchical structure or an instruction phase. For example, a node can represent the whole loop structure and it contains all instructions and inner loops inside its children graph. Each instruction in the CODE segment can be divided into multiple instruction phases. Each phase marks a critical timing point when the instruction changes behavior. For example, a REFI instruction has four phases: FETCH, ISSUE, ACTIVE, and END. The name of the node that represents an instruction phase is to combine the instruction label and the phase index. For example, if a REFI instruction has a label called instr_refi_0 , then the FETCH phase will be mapped to the node named as instr_refi_0_0 since the FETCH phase is the first phase of the REFI instruction. See Instruction Phase Each relation record in the RELATION segment specifies the children of one hierarchical node. The format is: \"NODE_NAME\" 1 IS_BULK [NODE0_IN_CHILD0, NODE1_IN_CHILD0, ...] [NODE0_IN_CHILD1, NODE1_IN_CHILD1, ...] EXPAND_LOOP The NODE_NAME can be any string, it's the name of the hierarchical node. The second parameter is deprecated, it's always 1. The third parameter IS_BULK specifies whether this node should be treated as bulk node. A bulk node does not allow overlap with other nodes. The array of child0 and child1 are used to specify the children node in the 0 th and 1th child graph. All hierarchical node other than IF-ELSE branch has only child0. The brach node has two children, child0 is the true branch, and child1 is the false branch. The last parameter is the EXPAND_LOOP. It's a flag to suggest the assembler to do cross-iteration software pipelining. Note The IS_BULK and EXPAND_LOOP are very confusing in manas. We will modify manas to make it more clear. Right now, all nodes other than loop should set both parameters to 0. For most inner loop, you should let IS_BULK=0 and EXPAND_LOOP=1. For other loops, set IS_BULK=1 and EXPAND_LOOP=1. When write node names in child graph array, you can use regular expression to include a group of nodes. For example, instr_refi_0_.* will include all the phases of the instruction named as \"instr_refi_0\". Example This is a example for relation segment .CODE CELL <0,0> \"instr0\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0, select_drra_row=0 \"instr1\" SWB src_row=0, src_block=0, src_port=0, hb_index=2, send_to_other_row=0, v_index=2 \"instr2\" SWB src_row=0, src_block=0, src_port=0, hb_index=3, send_to_other_row=0, v_index=3 \"instr3\" SWB src_row=0, src_block=0, src_port=1, hb_index=2, send_to_other_row=0, v_index=4 \"instr4\" SWB src_row=0, src_block=0, src_port=1, hb_index=3, send_to_other_row=0, v_index=5 \"instr5\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr6\" LOOP loopid=1, iter=3, step=2 \"instr7\" RACCU mode=1, operand1_sd=1, operand1=14, operand2_sd=1, operand2=15, result=0 \"instr8\" SRAM rw=0, init_addr=0, l1_iter=3, l1_step=1, l1_delay=0, init_addr_sd=1, hops=0 \"instr9\" REFI port_no=0, extra=2, init_addr_sd=0, init_addr=0, l1_iter=3, l1_step=1, l1_delay=0, dimarch=1 \"instr10\" REFI port_no=2, extra=2, init_addr=0, l1_iter=3, l1_step=1, l2_delay=2, l2_iter=28, l2_step=1 \"instr11\" REFI port_no=3, extra=2, init_addr=32, l1_iter=3, l1_step=1, l2_delay=2, l2_iter=28, l2_step=1 \"instr12\" LOOP loopid=2, iter=29, step=1 \"instr13\" DPU mode=10, control=2 CELL <0,1> \"instr14\" DPU mode=1, control=2 \"instr15\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0 \"instr16\" SWB src_row=0, src_block=1, src_port=0, hb_index=1, v_index=2 \"instr17\" SWB src_row=0, src_block=1, src_port=1, hb_index=1, v_index=3 \"instr18\" SRAM l1_iter=1, l1_step=1, l1_delay=0, l2_iter=1, l2_step=2, l2_delay=0, hops=0 \"instr19\" REFI port_no=0, extra=2, l1_iter=1, l1_step=1, dimarch=1 \"instr20\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr21\" LOOP extra=0, loopid=1, iter=3, step=2 \"instr22\" REFI port_no=2, extra=2, init_addr= 0, l1_iter=3, l1_step=1, l2_iter=28, l2_delay=2, l2_step=0 \"instr23\" REFI port_no=3, extra=2, init_addr=16, l1_iter=3, l1_step=1, l2_iter=28, l2_delay=2, l2_step=0 \"instr24\" LOOP loopid=2, iter=29, step=1 CELL <0,2> \"instr25\" DPU mode=1, control=2 \"instr26\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=0 \"instr27\" ROUTE horizontal_dir=0, horizontal_hops=0, vertical_dir=1, vertical_hops=1, direction=1 \"instr28\" SWB src_row=0, src_block=0, src_port=1, hb_index=2, v_index=2 \"instr29\" SWB src_row=0, src_block=1, src_port=0, hb_index=2, v_index=1 \"instr30\" SWB src_row=0, src_block=1, src_port=0, hb_index=1, v_index=3 \"instr31\" LOOP extra=1, loopid=0, iter=2, step=4 \"instr32\" REFI port_no=3, extra=2, l1_step=1, l1_iter=28, l1_delay=5, l2_iter=2, l2_delay=25, l2_step=0 \"instr33\" REFI port_no=1, extra=2, l1_step=1, l1_iter=28, l1_delay=5, l2_iter=2, l2_delay=25, l2_step=0 \"instr34\" LOOP extra=0, loopid=1, iter=3, step=2 \"instr35\" SRAM rw=0, l1_iter=1, l1_step=1, l1_delay=0, hops=0, init_addr_sd=d, init_addr=14 \"instr36\" REFI port_no=0, extra=2, l1_iter=1, l1_step=1, dimarch=1 \"instr37\" LOOP loopid=2, iter=29, step=1 \"instr38\" SRAM rw=1, l1_iter=1, l1_step=1, l1_delay=0, hops= 0, init_addr_sd=d, init_addr=14 \"instr39\" REFI port_no=2, extra=2, l1_iter=1, l1_step=1, dimarch=1 .RELATION \"ROOT\" 1 0 [\"LOOP0\",\"Op_0_0_0_1\", \"Op_0_0_0_2\", \"Op_0_0_1_1\", \"Op_0_0_1_2\", \"Op_0_0_2_1\",\"Op_0_0_2_2\", \"Op_0_0_3_1\", \"Op_0_0_3_2\", \"Op_0_0_4_1\", \"Op_0_0_4_2\",\"Op_0_1_0_1\", \"Op_0_1_0_2\", \"Op_0_1_0_3\", \"Op_0_1_1_1\", \"Op_0_1_1_2\",\"Op_0_1_2_1\", \"Op_0_1_2_2\", \"Op_0_1_3_1\", \"Op_0_1_3_2\", \"Op_0_1_4_1\", \"Op_0_1_4_2\", \"Op_0_1_5_1\",\"Op_0_2_0_1\", \"Op_0_2_0_2\", \"Op_0_2_0_3\", \"Op_0_2_1_1\", \"Op_0_2_1_2\",\"Op_0_2_2_1\", \"Op_0_2_2_2\", \"Op_0_2_3_1\", \"Op_0_2_3_2\", \"Op_0_2_4_1\", \"Op_0_2_4_2\",\"Op_0_2_5_1\", \"Op_0_2_5_2\"] [] 0 \"LOOP0\" 1 1 [\"LOOP0_BODY\",\"Op_0_0_5_1\",\"Op_0_1_6_1\",\"Op_0_2_6_1\"] [] 1 \"LOOP0_BODY\" 1 0 [\"LOOP1\",\"Op_0_1_4_3\", \"Op_0_1_4_4\", \"Op_0_1_5_2\", \"Op_0_1_5_3\",\"Op_0_2_7_1\",\"Op_0_2_8_1\"] [] 0 \"LOOP1\" 1 1 [\"LOOP1_BODY\",\"Op_0_0_6_1\",\"Op_0_1_7_1\",\"Op_0_2_9_1\"] [] 1 \"LOOP1_BODY\" 1 0 [\"LOOP2\",\"Op_0_0_7_1\", \"Op_0_0_8_1\", \"Op_0_0_8_2\", \"Op_0_0_8_3\", \"Op_0_0_8_4\", \"Op_0_0_10_1\", \"Op_0_0_11_1\",\"Op_0_0_9_1\", \"Op_0_0_9_2\", \"Op_0_0_9_3\",\"Op_0_1_8_1\", \"Op_0_1_9_1\", \"Op_0_2_10_1\", \"Op_0_2_10_2\", \"Op_0_2_10_3\", \"Op_0_2_10_4\",\"Op_0_2_11_1\",\"Op_0_2_11_2\", \"Op_0_2_11_3\",\"Op_0_2_13_1\",\"Op_0_2_13_2\",\"Op_0_2_13_3\", \"Op_0_2_13_4\", \"Op_0_2_14_1\", \"Op_0_2_14_2\",\"Op_0_2_14_3\"] [] 0 \"LOOP2\" 1 0 [\"LOOP2_BODY\", \"Op_0_0_12_1\",\"Op_0_1_10_1\", \"Op_0_2_12_1\"] [] 1 \"LOOP2_BODY\" 1 0 [\"Op_0_0_13_1\", \"Op_0_0_13_2\", \"Op_0_0_13_3\", \"Op_0_0_10_2\", \"Op_0_0_10_3\", \"Op_0_0_11_2\",\"Op_0_0_11_3\", \"Op_0_1_8_2\", \"Op_0_1_8_3\", \"Op_0_1_9_2\", \"Op_0_1_9_3\",\"Op_0_2_7_2\",\"Op_0_2_7_3\", \"Op_0_2_8_2\",\"Op_0_2_8_3\"] [] 0","title":"RELATION Segment"},{"location":"Docs/ToolChain/Vesyla-suite/ManasProgrammingGuide/#dependency-segment","text":"Dependencies among instructions are defined in dependency segment. A dependency segment starts with segment identifier: .DEPENDENCY Each instruction of DRRA has 5 phases: FETCH, ISSUE, ARRIVE, ACTIVE, END. They are represented by number: 1 to 5 respectively. User can define dependencies among instruction phases. These dependencies will guide the scheduler to order instructions properly. Each phase corresponds to a vertex in the dependency graph. You should know the naming convension when reference those phases. For example, the 2 nd phase of the 1 st instruction in cell <3,5> will be mapped to a vertex called Op_3_5_0_2 . A dependency is defined by four fields: SRC : the source vertex name. DEST: the destination vertex name. D_LO: the lower bound of distance. D_HI: the higher bound of distance. The format is: SRC DEST D_LO D_HI Example This is a example for dependency segment .DEPENDENCY \"0_0_0_0\" \"0_0_1_1\" 1 +INF \"0_0_1_1\" \"0_0_1_3\" 0 +INF \"1_0_1_1\" \"1_0_1_1\" 2 5","title":"DEPENDENCY Segment"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/","text":"Vesyla-suite Overview Version 2 Vesyla-suite version 2 is used for compiling Matlab code to DRRA and DiMArch based SiLago fabric. It does not support general input and output buffer for application-level synthesis. This version is deprecated and will be removed soon. You should only use it for old project such as DRRA characterization. Tool collection vesyla manas Usage Installation on Mozzarella Vesyla-suite version 2 has already been installed on Mozzarella. Since it's a deprecated version, you shouldn't try to compile it by yourself. Just use the installed instance on Mozzarella. To access vesyla-suite commands, you need to first load the vesyla-suite module by command: module load vesyla-suite / 2 Now you should be able to access vesyla and manas command. Tutorial See Turorial v2 for vesyla and manas version 2. Programming Guide See Vesyla Programming Guide v2 Version 3 Tool collection vs-vesyla vs-manas vs-alimpsim vs-init vs-expand vs-imecc Installation and Usage Installation on Mozzarella Vesyla-suite version 3 has already been installed on Mozzarella. To access vesyla-suite commands, you need to first load the vesyla-suite module by command: module load vesyla-suite / 3 Docker See Installation Compile from Source See Installation Tutorial See DRRA-based AlImp Design Tutorial and RISCV-based AlImp Design Tutorial . Programming Guide See Vesyla Programming Guide","title":"Vesyla-suite Overview"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#vesyla-suite-overview","text":"","title":"Vesyla-suite Overview"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#version-2","text":"Vesyla-suite version 2 is used for compiling Matlab code to DRRA and DiMArch based SiLago fabric. It does not support general input and output buffer for application-level synthesis. This version is deprecated and will be removed soon. You should only use it for old project such as DRRA characterization.","title":"Version 2"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#tool-collection","text":"vesyla manas","title":"Tool collection"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#usage","text":"","title":"Usage"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#installation-on-mozzarella","text":"Vesyla-suite version 2 has already been installed on Mozzarella. Since it's a deprecated version, you shouldn't try to compile it by yourself. Just use the installed instance on Mozzarella. To access vesyla-suite commands, you need to first load the vesyla-suite module by command: module load vesyla-suite / 2 Now you should be able to access vesyla and manas command.","title":"Installation on Mozzarella"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#tutorial","text":"See Turorial v2 for vesyla and manas version 2.","title":"Tutorial"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#programming-guide","text":"See Vesyla Programming Guide v2","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#version-3","text":"","title":"Version 3"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#tool-collection_1","text":"vs-vesyla vs-manas vs-alimpsim vs-init vs-expand vs-imecc","title":"Tool collection"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#installation-and-usage","text":"","title":"Installation and Usage"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#installation-on-mozzarella_1","text":"Vesyla-suite version 3 has already been installed on Mozzarella. To access vesyla-suite commands, you need to first load the vesyla-suite module by command: module load vesyla-suite / 3","title":"Installation on Mozzarella"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#docker","text":"See Installation","title":"Docker"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#compile-from-source","text":"See Installation","title":"Compile from Source"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#tutorial_1","text":"See DRRA-based AlImp Design Tutorial and RISCV-based AlImp Design Tutorial .","title":"Tutorial"},{"location":"Docs/ToolChain/Vesyla-suite/Overview/#programming-guide_1","text":"See Vesyla Programming Guide","title":"Programming Guide"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/","text":"Repo Organization Vesyla eco-system is constructed by many modules. One can create a new app in this eco-system by combining several modules. Module Type Executable Module The executable modules create executable applications. If written in C++, it will be compiled to an executable binary file. Data Module The data modules define classes for various data structures. In vesyla eco-system, we encourage developer to define pure data structure using descriptive language or library. The protobuf (version 3) from Google is a very good libarary for such purpose because it's language-neutral and platform-neutral. Besides the pure data structure, developers should also include a handler class to provide a data access interface. Several programming language specific interfaces could be provided. Process Module The process modules manupilate the data structer defined by other data modules. The process modules usually implement one or more algorithms to refine the data structure. Utility Module The utility modules include the basic functionality that is needed by the majority of other modules, such as event logging, configuration file searching, and global variable mantainance. Module Implementation Each module is implemented by github submodule function. Module Testing Each module should have a top-level folder for testing. For executable module, the tests could be overall general testcases. We recommend to use the Robot Framework to automatically run all testcases. For other type of modules, the tests are mostly unit-tests. C++ based modules can easily be tested via standard boost test library Organization The top-level repo is called vesyla suite . It contains all the other repo as modules. The flat and shallow dependency strucutre makes it easier to manage. There are two major executable modules: vesyla and manas . Branch We recommend to use two branches in each repo: master and develop . The master branch keeps stable version of the repo and the develop branch is for adding new features and fixing bugs. The develop branch should be merged/rebased to the master branch at least once per month.","title":"Repo Organization"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#repo-organization","text":"Vesyla eco-system is constructed by many modules. One can create a new app in this eco-system by combining several modules.","title":"Repo Organization"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#module-type","text":"","title":"Module Type"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#executable-module","text":"The executable modules create executable applications. If written in C++, it will be compiled to an executable binary file.","title":"Executable Module"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#data-module","text":"The data modules define classes for various data structures. In vesyla eco-system, we encourage developer to define pure data structure using descriptive language or library. The protobuf (version 3) from Google is a very good libarary for such purpose because it's language-neutral and platform-neutral. Besides the pure data structure, developers should also include a handler class to provide a data access interface. Several programming language specific interfaces could be provided.","title":"Data Module"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#process-module","text":"The process modules manupilate the data structer defined by other data modules. The process modules usually implement one or more algorithms to refine the data structure.","title":"Process Module"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#utility-module","text":"The utility modules include the basic functionality that is needed by the majority of other modules, such as event logging, configuration file searching, and global variable mantainance.","title":"Utility Module"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#module-implementation","text":"Each module is implemented by github submodule function.","title":"Module Implementation"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#module-testing","text":"Each module should have a top-level folder for testing. For executable module, the tests could be overall general testcases. We recommend to use the Robot Framework to automatically run all testcases. For other type of modules, the tests are mostly unit-tests. C++ based modules can easily be tested via standard boost test library","title":"Module Testing"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#organization","text":"The top-level repo is called vesyla suite . It contains all the other repo as modules. The flat and shallow dependency strucutre makes it easier to manage. There are two major executable modules: vesyla and manas .","title":"Organization"},{"location":"Docs/ToolChain/Vesyla-suite/RepoOrganization/#branch","text":"We recommend to use two branches in each repo: master and develop . The master branch keeps stable version of the repo and the develop branch is for adding new features and fixing bugs. The develop branch should be merged/rebased to the master branch at least once per month.","title":"Branch"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/","text":"DRRA-based AlImp Design Tutorial (v3) Note This page is written for vesyla-suite version 3 . For vesyla-suite version 2, please see DRRA-based AlImp Design Tutorial v3 . Introduction Programming Model Each algorithm compiled by vesyla-suite will be mapped to a DRRA fabric. The DRRA fabric has a globally addressable input buffer and a globally addressable output buffer, as shown in the following figure. The input buffer is used to store the input data of the algorithm. The output buffer is used to store the output data of the algorithm. The input buffer and the output buffer are connected to the DRRA fabric through the input and output ports of the fabric. The input and output ports are used to connect the DRRA fabric to the outside world. Currently, we assume that all DRRA cells have access to both input and output buffer. This assumption might be modified in the future when introducing SiLago 2 DRRA fabric. The input bandwidth and output bandwith are determined by the number of columns of the DRRA fabric. Right now, we don't support scratch-pad memory implemented by DiMArch rows. This will change when migrating to SiLago 2 DRRA fabric. The assumption of giant globally addressable memory buffers is not realistic. However, these buffers will not be implemented as it is. Instead, application-level synthesis (ALS) tool will synthesize the input and output buffers to the actual hardware. The input and output buffers are used to simplify the algorithmic compilation process. Initialization In any directory, you can initialize a vesyla-suite project by using the command: vs-init - s vs-vesyla If this directory has already been initialized, you can force the re-initialization by using the command: vs-init - f - s vs-vesyla You will notice that several files has been created in this directory. One of the files is config.json . This file contains the configuration of the vesyla-suite project. You can modify this file to change the configuration of the project. The configuration file is described in the following section. Another file you need to modify is main.cpp.jinja2 . This file is a template file used to generate the main.cpp file. You need to define some of the functions in this file. The functions are described in the following section. Implementation We use a simple example to demonstrate the implementation of algorithms. The example is a element-wise addition of two vectors. It has two inputs: vector A and vector B . It has one output: vector C . All of them have size equal to 16. The element-wise addition is defined as: C[i] = A[i] + B[i] . We first define the hardware architecture in config.json . { \"ARCH_DRRA_ROW\" : 1 , \"ARCH_DRRA_COL\" : 1 , \"ARCH_SRAM_ROW\" : 0 , \"ARCH_SRAM_COL\" : 0 , \"ARCH_SRAM_DEPTH\" : 64 , \"ARCH_SRAM_WIDTH\" : 256 , \"ARCH_RF_DEPTH\" : 64 , \"ARCH_RF_WIDTH\" : 16 , \"ARCH_IO_DEPTH\" : 1024 , \"ARCH_IO_WIDTH\" : 256 , \"ARCH_IRAM_DEPTH\" : 64 } ARCH_DRRA_ROW and ARCH_DRRA_COL are the number of rows and columns of the DRRA fabric. ARCH_SRAM_ROW and ARCH_SRAM_COL are the number of rows and columns of the SRAM array used as scratch-pad memory. ARCH_SRAM_DEPTH is the depth of each SRAM cell. ARCH_SRAM_WIDTH is the width of each SRAM cell in terms of bits. In this example, we will not use any SRAM cell. ARCH_RF_DEPTH is the depth of each register file. ARCH_RF_WIDTH is the width of each register file in terms of bits. ARCH_IO_DEPTH is the depth of each input and output buffer. ARCH_IO_WIDTH is the width of each input and output buffer in terms of bits. ARCH_IRAM_DEPTH is the depth of the instruction RAM in each DRRA cell. Before we implement the algorithm in main.cpp.jinja2 , we need to define the input and output data layout in input and output buffer. Both input and output buffer has width that equals to 256 bits. So, each row can be divided by 16 16-bit chunks, each of which stores an element of A , B , or C . The layout is described by the following table. Input Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | A[0]| A[1]| A[2]| A[3]| A[4]| A[5]| A[6]| A[7]| A[8]| A[9]|A[10]|A[11]|A[12]|A[13]|A[14]|A[15]| | 1 | B[0]| B[1]| B[2]| B[3]| B[4]| B[5]| B[6]| B[7]| B[8]| B[9]|B[10]|B[11]|B[12]|B[13]|B[14]|B[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ Output Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | C[0]| C[1]| C[2]| C[3]| C[4]| C[5]| C[6]| C[7]| C[8]| C[9]|C[10]|C[11]|C[12]|C[13]|C[14]|C[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ In main.cpp.jinja2 , you need to implement the following functions: void init() : This function is used to initialize the input buffer. void model_l0() : This function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. void model_l1() : This function is used to implement the algorithm in the level 1 model. It will be the input of vesyla-suite compiler. It's a software implementation of the algorithm with some hardware primitives. For syntax, plaese refer to Vesyla Programming Guide . We implement these functions one by one. The init() function is used to initialize the input buffer. It's a pure software implementation. The following code shows how to initialize the input buffer. void init (){ // Set the seed for random number generator srand (( unsigned ) time ( NULL )); // Generate 32 random numbers in range [0,100) for both vector A and B vector < int16_t > v ( 32 ); for ( auto i = 0 ; i < 32 ; i ++ ){ v [ i ] = rand () % 100 ; } // Write the random numbers to the input buffer at starting address 0, and the number of row to write is 2. __input_buffer__ . write < int16_t > ( 0 , 2 , v ); } The model_l0() function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. The following code shows how to implement the algorithm in the level 0 model. void model_l0 (){ // Read the input buffer to A. The starting address is 0, and the number of row to read is 1. vector < int16_t > a = __input_buffer__ . read < int16_t > ( 0 , 1 ); // Read the input buffer to B. The starting address is 1, and the number of row to read is 1. vector < int16_t > b = __input_buffer__ . read < int16_t > ( 1 , 1 ); // Add A and B vector < int16_t > c ( 16 ); for ( auto i = 0 ; i < 16 ; i ++ ){ c [ i ] = a [ i ] + b [ i ]; } // Write the result C to the output buffer at starting address 0, and the number of row to write is 1. __output_buffer__ . write < int16_t > ( 0 , 1 , c ); } Now, it's time to implement the algorithm in the level 1 model. The level 1 model is a software implementation of the algorithm with some hardware primitives. It serves dual purposes. First, it's used to verify the correctness of the algorithm. Second, it's used as the input of the compiler. The following code shows how to implement the algorithm in the level 1 model. void model_l1 (){ // Declare the input and output streams. The input and output streams are disorganized data after reading or before writing to the input and output buffer. STREAM_IO_CHUNK sab , sc ; // Read the input buffer to sab. The starting address is 0, the step is 1, and the number of row to read is 2. This stream include data for both A and B. sab = silago_io_read ( __input_buffer__ , silago_agu_affine_1 ( 0 , 1 , 2 )); // Declare the RF variable to model register file. We use pragma to bind it to the register file in cell [0,0]. We then store the data stream to the register file. #pragma bind rf_0_0 RF rf_0_0 ; rf_0_0 = silago_rf_write_from_io_stream ( sab , silago_agu_affine_1 ( 0 , 1 , 2 ), rf_0_0 ); // Declare the register file streams. STREAM_RF_CHUNK aa , bb , cc ; // Read the data from the register file to aa and bb. aa = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 16 )); bb = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 16 , 1 , 16 )); // We use pragma to bind the following arithmetic operation to DPU[0,0]. We then add aa and bb and produce cc. #pragma bind dpu_0_0 cc = silago_dpu_add ( aa , bb ); // The stream cc is stored to the register file. rf_0_0 = silago_rf_write ( cc , silago_agu_affine_1 ( 0 , 1 , 16 ), rf_0_0 ); // Read the data from the register file to sc to generate the output stream sc. sc = silago_rf_read_to_io_stream ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 1 )); // We then write the output stream sc to the output buffer. __output_buffer__ = silago_io_write ( sc , silago_agu_affine_1 ( 0 , 1 , 1 ), __output_buffer__ ); } Simulation and Verification To simulate the algorithm, simply run: . / run.sh If the output shows the simulation is successful, then the algorithm is correct.","title":"DRRA-based AlImp Design Tutorial (v3)"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#drra-based-alimp-design-tutorial-v3","text":"Note This page is written for vesyla-suite version 3 . For vesyla-suite version 2, please see DRRA-based AlImp Design Tutorial v3 .","title":"DRRA-based AlImp Design Tutorial (v3)"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#introduction","text":"","title":"Introduction"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#programming-model","text":"Each algorithm compiled by vesyla-suite will be mapped to a DRRA fabric. The DRRA fabric has a globally addressable input buffer and a globally addressable output buffer, as shown in the following figure. The input buffer is used to store the input data of the algorithm. The output buffer is used to store the output data of the algorithm. The input buffer and the output buffer are connected to the DRRA fabric through the input and output ports of the fabric. The input and output ports are used to connect the DRRA fabric to the outside world. Currently, we assume that all DRRA cells have access to both input and output buffer. This assumption might be modified in the future when introducing SiLago 2 DRRA fabric. The input bandwidth and output bandwith are determined by the number of columns of the DRRA fabric. Right now, we don't support scratch-pad memory implemented by DiMArch rows. This will change when migrating to SiLago 2 DRRA fabric. The assumption of giant globally addressable memory buffers is not realistic. However, these buffers will not be implemented as it is. Instead, application-level synthesis (ALS) tool will synthesize the input and output buffers to the actual hardware. The input and output buffers are used to simplify the algorithmic compilation process.","title":"Programming Model"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#initialization","text":"In any directory, you can initialize a vesyla-suite project by using the command: vs-init - s vs-vesyla If this directory has already been initialized, you can force the re-initialization by using the command: vs-init - f - s vs-vesyla You will notice that several files has been created in this directory. One of the files is config.json . This file contains the configuration of the vesyla-suite project. You can modify this file to change the configuration of the project. The configuration file is described in the following section. Another file you need to modify is main.cpp.jinja2 . This file is a template file used to generate the main.cpp file. You need to define some of the functions in this file. The functions are described in the following section.","title":"Initialization"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#implementation","text":"We use a simple example to demonstrate the implementation of algorithms. The example is a element-wise addition of two vectors. It has two inputs: vector A and vector B . It has one output: vector C . All of them have size equal to 16. The element-wise addition is defined as: C[i] = A[i] + B[i] . We first define the hardware architecture in config.json . { \"ARCH_DRRA_ROW\" : 1 , \"ARCH_DRRA_COL\" : 1 , \"ARCH_SRAM_ROW\" : 0 , \"ARCH_SRAM_COL\" : 0 , \"ARCH_SRAM_DEPTH\" : 64 , \"ARCH_SRAM_WIDTH\" : 256 , \"ARCH_RF_DEPTH\" : 64 , \"ARCH_RF_WIDTH\" : 16 , \"ARCH_IO_DEPTH\" : 1024 , \"ARCH_IO_WIDTH\" : 256 , \"ARCH_IRAM_DEPTH\" : 64 } ARCH_DRRA_ROW and ARCH_DRRA_COL are the number of rows and columns of the DRRA fabric. ARCH_SRAM_ROW and ARCH_SRAM_COL are the number of rows and columns of the SRAM array used as scratch-pad memory. ARCH_SRAM_DEPTH is the depth of each SRAM cell. ARCH_SRAM_WIDTH is the width of each SRAM cell in terms of bits. In this example, we will not use any SRAM cell. ARCH_RF_DEPTH is the depth of each register file. ARCH_RF_WIDTH is the width of each register file in terms of bits. ARCH_IO_DEPTH is the depth of each input and output buffer. ARCH_IO_WIDTH is the width of each input and output buffer in terms of bits. ARCH_IRAM_DEPTH is the depth of the instruction RAM in each DRRA cell. Before we implement the algorithm in main.cpp.jinja2 , we need to define the input and output data layout in input and output buffer. Both input and output buffer has width that equals to 256 bits. So, each row can be divided by 16 16-bit chunks, each of which stores an element of A , B , or C . The layout is described by the following table. Input Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | A[0]| A[1]| A[2]| A[3]| A[4]| A[5]| A[6]| A[7]| A[8]| A[9]|A[10]|A[11]|A[12]|A[13]|A[14]|A[15]| | 1 | B[0]| B[1]| B[2]| B[3]| B[4]| B[5]| B[6]| B[7]| B[8]| B[9]|B[10]|B[11]|B[12]|B[13]|B[14]|B[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ Output Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | C[0]| C[1]| C[2]| C[3]| C[4]| C[5]| C[6]| C[7]| C[8]| C[9]|C[10]|C[11]|C[12]|C[13]|C[14]|C[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ In main.cpp.jinja2 , you need to implement the following functions: void init() : This function is used to initialize the input buffer. void model_l0() : This function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. void model_l1() : This function is used to implement the algorithm in the level 1 model. It will be the input of vesyla-suite compiler. It's a software implementation of the algorithm with some hardware primitives. For syntax, plaese refer to Vesyla Programming Guide . We implement these functions one by one. The init() function is used to initialize the input buffer. It's a pure software implementation. The following code shows how to initialize the input buffer. void init (){ // Set the seed for random number generator srand (( unsigned ) time ( NULL )); // Generate 32 random numbers in range [0,100) for both vector A and B vector < int16_t > v ( 32 ); for ( auto i = 0 ; i < 32 ; i ++ ){ v [ i ] = rand () % 100 ; } // Write the random numbers to the input buffer at starting address 0, and the number of row to write is 2. __input_buffer__ . write < int16_t > ( 0 , 2 , v ); } The model_l0() function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. The following code shows how to implement the algorithm in the level 0 model. void model_l0 (){ // Read the input buffer to A. The starting address is 0, and the number of row to read is 1. vector < int16_t > a = __input_buffer__ . read < int16_t > ( 0 , 1 ); // Read the input buffer to B. The starting address is 1, and the number of row to read is 1. vector < int16_t > b = __input_buffer__ . read < int16_t > ( 1 , 1 ); // Add A and B vector < int16_t > c ( 16 ); for ( auto i = 0 ; i < 16 ; i ++ ){ c [ i ] = a [ i ] + b [ i ]; } // Write the result C to the output buffer at starting address 0, and the number of row to write is 1. __output_buffer__ . write < int16_t > ( 0 , 1 , c ); } Now, it's time to implement the algorithm in the level 1 model. The level 1 model is a software implementation of the algorithm with some hardware primitives. It serves dual purposes. First, it's used to verify the correctness of the algorithm. Second, it's used as the input of the compiler. The following code shows how to implement the algorithm in the level 1 model. void model_l1 (){ // Declare the input and output streams. The input and output streams are disorganized data after reading or before writing to the input and output buffer. STREAM_IO_CHUNK sab , sc ; // Read the input buffer to sab. The starting address is 0, the step is 1, and the number of row to read is 2. This stream include data for both A and B. sab = silago_io_read ( __input_buffer__ , silago_agu_affine_1 ( 0 , 1 , 2 )); // Declare the RF variable to model register file. We use pragma to bind it to the register file in cell [0,0]. We then store the data stream to the register file. #pragma bind rf_0_0 RF rf_0_0 ; rf_0_0 = silago_rf_write_from_io_stream ( sab , silago_agu_affine_1 ( 0 , 1 , 2 ), rf_0_0 ); // Declare the register file streams. STREAM_RF_CHUNK aa , bb , cc ; // Read the data from the register file to aa and bb. aa = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 16 )); bb = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 16 , 1 , 16 )); // We use pragma to bind the following arithmetic operation to DPU[0,0]. We then add aa and bb and produce cc. #pragma bind dpu_0_0 cc = silago_dpu_add ( aa , bb ); // The stream cc is stored to the register file. rf_0_0 = silago_rf_write ( cc , silago_agu_affine_1 ( 0 , 1 , 16 ), rf_0_0 ); // Read the data from the register file to sc to generate the output stream sc. sc = silago_rf_read_to_io_stream ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 1 )); // We then write the output stream sc to the output buffer. __output_buffer__ = silago_io_write ( sc , silago_agu_affine_1 ( 0 , 1 , 1 ), __output_buffer__ ); }","title":"Implementation"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA/#simulation-and-verification","text":"To simulate the algorithm, simply run: . / run.sh If the output shows the simulation is successful, then the algorithm is correct.","title":"Simulation and Verification"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/","text":"DRRA-based AlImp Design Tutorial (v2) Note This page is written for vesyla-suite version 2 . It's deprecated and will be removed soon. You should only use it for old project such as DRRA characterization. For vesyla-suite version 3, please see Tutorial . Introduction Vesyla-suite provides two commands: vesyla and manas. Vesyla is used for compiling Matlab code to DRRA and DiMArch based SiLago fabric. Manas is used for instruction scheduling and generating RTL simulation environment. Write the source code Please Check the Vesyla Programming Guide v2 . Compilation To compile a program that is purely matlab script by using Vesyla and Manas, use the following command: vesyla - o $PathToOutputDirectory $PathToMatlabFile manas - o $PathToOutputDirectory - t json $PathToOutputDirectory / filegen RTL simulation Vesyla also generates environment for RTL simulation. It's in $OUTPUT/filegen/sim_vsim . However, you can't directly simulate it under QuestaSim because you need to specify the path to the DRRA+DiMArch fabric. To specify the path to the fabric, use the command: export FABRIC_PATH = $PathToFabric Then, you can use Questasim to run the simulation script genereated by Vesyla: cd $OUTPUT / filegen / vsim - c - do run_gui.do","title":"DRRA-based AlImp Design Tutorial (v2)"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/#drra-based-alimp-design-tutorial-v2","text":"Note This page is written for vesyla-suite version 2 . It's deprecated and will be removed soon. You should only use it for old project such as DRRA characterization. For vesyla-suite version 3, please see Tutorial .","title":"DRRA-based AlImp Design Tutorial (v2)"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/#introduction","text":"Vesyla-suite provides two commands: vesyla and manas. Vesyla is used for compiling Matlab code to DRRA and DiMArch based SiLago fabric. Manas is used for instruction scheduling and generating RTL simulation environment.","title":"Introduction"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/#write-the-source-code","text":"Please Check the Vesyla Programming Guide v2 .","title":"Write the source code"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/#compilation","text":"To compile a program that is purely matlab script by using Vesyla and Manas, use the following command: vesyla - o $PathToOutputDirectory $PathToMatlabFile manas - o $PathToOutputDirectory - t json $PathToOutputDirectory / filegen","title":"Compilation"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_DRRA_v2/#rtl-simulation","text":"Vesyla also generates environment for RTL simulation. It's in $OUTPUT/filegen/sim_vsim . However, you can't directly simulate it under QuestaSim because you need to specify the path to the DRRA+DiMArch fabric. To specify the path to the fabric, use the command: export FABRIC_PATH = $PathToFabric Then, you can use Questasim to run the simulation script genereated by Vesyla: cd $OUTPUT / filegen / vsim - c - do run_gui.do","title":"RTL simulation"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/","text":"RISCV-based AlImp Design Tutorial Introduction Programming Model Algorithms with intensive control flow or scalar computation should be mapped on processor-like computation nodes. Vesyla-suite support the mapping of algorithms to RISC-V processor. The RISC-V based computation nodes have the same I/O interface as the DRRA-based computation nodes to communicate with a globally addressable input buffer and a globally addressable output buffer, as shown in the following figure. The input buffer is used to store the input data of the algorithm. The output buffer is used to store the output data of the algorithm. The input buffer and the output buffer are connected to the RISC V computation node through the input and output ports of the fabric. The input and output ports are used to connect the RISC V to the outside world. Currently, we assume that RISC V core accesses both input and output buffer through peripheral interface: the read_unit and write_unit. The bandwith of the read_unit and write_unit are fixed as 1 channel because a RISC V core only has 1 thread. The wide bandwidth of the input and output ports are more than enough for the RISC V core. The RISC V core considers the read_unit and write_unit as memory mapped peripheral devices. Each of them has a 64-bit configuration register that can be accessed by the RISC V core via the bus. The address for the read_unit configuration register is 0x80000000 , and the write_unit configuration register is 0x80000008 . All data are organized in little endian style. The configuration register fields are shown in the following table. Field Name (MSB to LSB) Bit Width Description enable 1 Enable the read_unit or write_unit. addr_ext 25 The address of the input or output buffer. addr_int 5 The address of the internal SRAM. unused 1 Unused. step_ext 5 The step size of the input or output buffer. step_int 5 The step size of the internal SRAM. iter 5 The number of iterations. unused 17 Unused. There is a 1 kB scratch-pad SRAM array working as the main data memory for the RISC V core. The RISC V core can access the SRAM array through the load and store instructions. The read_unit and write_unit can also bring data from or store data to the outside world. The assumption of giant globally addressable memory buffers is not realistic. However, these buffers will not be implemented as it is. Instead, application-level synthesis (ALS) tool will synthesize the input and output buffers to the actual hardware. The input and output buffers are used to simplify the algorithmic compilation process. Initialization In any directory, you can initialize a vesyla-suite project for RISC V by using the command: vs-init - s vs-rvsim If this directory has already been initialized, you can force the re-initialization by using the command: vs-init - f - s vs-rvsim You will notice that several files has been created in this directory. One of the files is config.json . This file contains the configuration of the vesyla-suite project. You can modify this file to change the configuration of the project. The configuration file is described in the following section. Another file you need to modify is main.cpp.jinja2 . This file is a template file used to generate the main.cpp file. You need to define some of the functions in this file. The functions are described in the following section. The last file you need to modify is instruction.bin . This file contains the instructions of the RISC V core in binary or hex form. You need to generate the instructions and write them to this file. The easiest way is to write assembly code and compile it by using RISC V assembler. Implementation We use a simple example to demonstrate the implementation of algorithms. The example is a element-wise addition of two vectors. It has two inputs: vector A and vector B . It has one output: vector C . All of them have size equal to 16. The element-wise addition is defined as: C[i] = A[i] + B[i] . We first define the hardware architecture in config.json . { \"style\" : \"vs-rvsim\" , \"ARCH_IO_DEPTH\" : 1024 , \"ARCH_IO_WIDTH\" : 256 , \"ARCH_SRAM_SIZE\" : 1024 , \"ARCH_IRAM_SIZE\" : 1024 } ARCH_IO_DEPTH is the depth of each input and output buffer. ARCH_IO_WIDTH is the width of each input and output buffer in terms of bits. ARCH_SRAM_SIZE is the size of SRAM in terms of bytes. ARCH_IRAM_SIZE is the depth of the instruction RAM in terms of bytes. Before we implement the algorithm in main.cpp.jinja2 , we need to define the input and output data layout in input and output buffer. Both input and output buffer has width that equals to 256 bits. So, each row can be divided by 16 16-bit chunks, each of which stores an element of A , B , or C . The layout is described by the following table. Input Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | A[0]| A[1]| A[2]| A[3]| A[4]| A[5]| A[6]| A[7]| A[8]| A[9]|A[10]|A[11]|A[12]|A[13]|A[14]|A[15]| | 1 | B[0]| B[1]| B[2]| B[3]| B[4]| B[5]| B[6]| B[7]| B[8]| B[9]|B[10]|B[11]|B[12]|B[13]|B[14]|B[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ Output Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | C[0]| C[1]| C[2]| C[3]| C[4]| C[5]| C[6]| C[7]| C[8]| C[9]|C[10]|C[11]|C[12]|C[13]|C[14]|C[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ In main.cpp.jinja2 , you need to implement the following functions: void init() : This function is used to initialize the input buffer. void model_l0() : This function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. We implement these functions one by one. The init() function is used to initialize the input buffer. It's a pure software implementation. The following code shows how to initialize the input buffer. void init (){ // Set the seed for random number generator srand (( unsigned ) time ( NULL )); // Generate 32 random numbers in range [0,100) for both vector A and B vector < int16_t > v ( 32 ); for ( auto i = 0 ; i < 32 ; i ++ ){ v [ i ] = rand () % 100 ; } // Write the random numbers to the input buffer at starting address 0, and the number of row to write is 2. __input_buffer__ . write < int16_t > ( 0 , 2 , v ); } The model_l0() function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. The following code shows how to implement the algorithm in the level 0 model. void model_l0 (){ // Read the input buffer to A. The starting address is 0, and the number of row to read is 1. vector < int16_t > a = __input_buffer__ . read < int16_t > ( 0 , 1 ); // Read the input buffer to B. The starting address is 1, and the number of row to read is 1. vector < int16_t > b = __input_buffer__ . read < int16_t > ( 1 , 1 ); // Add A and B vector < int16_t > c ( 16 ); for ( auto i = 0 ; i < 16 ; i ++ ){ c [ i ] = a [ i ] + b [ i ]; } // Write the result C to the output buffer at starting address 0, and the number of row to write is 1. __output_buffer__ . write < int16_t > ( 0 , 1 , c ); } Now, it's time to get the instructions for RISC V core. We first write the assembly code as following: lui x1 , 0x80000 # load the base address of read_unit and write_unit conf reg lui x2 , 0x80000 # composing the configuration words for read_unit: lui x3 , 0x08440 # enable=1, addr_ext=0, addr_int=0, step_ext=1, step_int=1, iter=2 sw x3 , 0 ( x1 ) # write to conf reg, lower half sw x2 , 4 ( x1 ) # write to conf reg, upper half addi x4 , x0 , 32 # offset address boundry, used for loop end condition addi x5 , x0 , 0 # loop iterator, also work as address __back: lh x7 , 0 ( x5 ) # load one element in A (16-bit) lh x8 , 32 ( x5 ) # load one element in B (16-bit) add x7 , x7 , x8 # add sh x7 , 64 ( x5 ) # store the result addi x5 , x5 , 2 # update iterator by 2 since 16-bit is 2 bytes blt x5 , x4 , __back # check loop condition and jump __done: lui x2 , 0x80000 # composing the configuration words for read_unit: addi x2 , x2 , 0x004 # enable=1, addr_ext=0, addr_int=2, step_ext=1, step_int=1, iter=1 lui x3 , 0x08420 sw x3 , 8 ( x1 ) # write to conf reg, lower half sw x2 , 12 ( x1 ) # write to conf reg, upper half addi x0 , x0 , 0 # NOP, wait the data transfer to complete addi x0 , x0 , 0 # NOP, wait the data transfer to complete Then, we use the online RISC V assembler to compile and get the hex instructions. The following figure shows the result. 800000b7 80000137 084401b7 0030a023 0020a223 02000213 00000293 00029383 02029403 008383b3 04729023 00228293 fe42c6e3 80000137 00410113 084201b7 0030a423 0020a623 00000013 00000013 Simulation and Verification To simulate the algorithm, simply run: . / run.sh If the output shows the simulation is successful, then the algorithm is correct.","title":"RISCV-based AlImp Design Tutorial"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#riscv-based-alimp-design-tutorial","text":"","title":"RISCV-based AlImp Design Tutorial"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#introduction","text":"","title":"Introduction"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#programming-model","text":"Algorithms with intensive control flow or scalar computation should be mapped on processor-like computation nodes. Vesyla-suite support the mapping of algorithms to RISC-V processor. The RISC-V based computation nodes have the same I/O interface as the DRRA-based computation nodes to communicate with a globally addressable input buffer and a globally addressable output buffer, as shown in the following figure. The input buffer is used to store the input data of the algorithm. The output buffer is used to store the output data of the algorithm. The input buffer and the output buffer are connected to the RISC V computation node through the input and output ports of the fabric. The input and output ports are used to connect the RISC V to the outside world. Currently, we assume that RISC V core accesses both input and output buffer through peripheral interface: the read_unit and write_unit. The bandwith of the read_unit and write_unit are fixed as 1 channel because a RISC V core only has 1 thread. The wide bandwidth of the input and output ports are more than enough for the RISC V core. The RISC V core considers the read_unit and write_unit as memory mapped peripheral devices. Each of them has a 64-bit configuration register that can be accessed by the RISC V core via the bus. The address for the read_unit configuration register is 0x80000000 , and the write_unit configuration register is 0x80000008 . All data are organized in little endian style. The configuration register fields are shown in the following table. Field Name (MSB to LSB) Bit Width Description enable 1 Enable the read_unit or write_unit. addr_ext 25 The address of the input or output buffer. addr_int 5 The address of the internal SRAM. unused 1 Unused. step_ext 5 The step size of the input or output buffer. step_int 5 The step size of the internal SRAM. iter 5 The number of iterations. unused 17 Unused. There is a 1 kB scratch-pad SRAM array working as the main data memory for the RISC V core. The RISC V core can access the SRAM array through the load and store instructions. The read_unit and write_unit can also bring data from or store data to the outside world. The assumption of giant globally addressable memory buffers is not realistic. However, these buffers will not be implemented as it is. Instead, application-level synthesis (ALS) tool will synthesize the input and output buffers to the actual hardware. The input and output buffers are used to simplify the algorithmic compilation process.","title":"Programming Model"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#initialization","text":"In any directory, you can initialize a vesyla-suite project for RISC V by using the command: vs-init - s vs-rvsim If this directory has already been initialized, you can force the re-initialization by using the command: vs-init - f - s vs-rvsim You will notice that several files has been created in this directory. One of the files is config.json . This file contains the configuration of the vesyla-suite project. You can modify this file to change the configuration of the project. The configuration file is described in the following section. Another file you need to modify is main.cpp.jinja2 . This file is a template file used to generate the main.cpp file. You need to define some of the functions in this file. The functions are described in the following section. The last file you need to modify is instruction.bin . This file contains the instructions of the RISC V core in binary or hex form. You need to generate the instructions and write them to this file. The easiest way is to write assembly code and compile it by using RISC V assembler.","title":"Initialization"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#implementation","text":"We use a simple example to demonstrate the implementation of algorithms. The example is a element-wise addition of two vectors. It has two inputs: vector A and vector B . It has one output: vector C . All of them have size equal to 16. The element-wise addition is defined as: C[i] = A[i] + B[i] . We first define the hardware architecture in config.json . { \"style\" : \"vs-rvsim\" , \"ARCH_IO_DEPTH\" : 1024 , \"ARCH_IO_WIDTH\" : 256 , \"ARCH_SRAM_SIZE\" : 1024 , \"ARCH_IRAM_SIZE\" : 1024 } ARCH_IO_DEPTH is the depth of each input and output buffer. ARCH_IO_WIDTH is the width of each input and output buffer in terms of bits. ARCH_SRAM_SIZE is the size of SRAM in terms of bytes. ARCH_IRAM_SIZE is the depth of the instruction RAM in terms of bytes. Before we implement the algorithm in main.cpp.jinja2 , we need to define the input and output data layout in input and output buffer. Both input and output buffer has width that equals to 256 bits. So, each row can be divided by 16 16-bit chunks, each of which stores an element of A , B , or C . The layout is described by the following table. Input Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | A[0]| A[1]| A[2]| A[3]| A[4]| A[5]| A[6]| A[7]| A[8]| A[9]|A[10]|A[11]|A[12]|A[13]|A[14]|A[15]| | 1 | B[0]| B[1]| B[2]| B[3]| B[4]| B[5]| B[6]| B[7]| B[8]| B[9]|B[10]|B[11]|B[12]|B[13]|B[14]|B[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ Output Buffer: +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | addr | CHK0| CHK1| CHK2| CHK3| CHK4| CHK5| CHK6| CHK7| CHK8| CHK9|CHK10|CHK11|CHK12|CHK13|CHK14|CHK15| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ | 0 | C[0]| C[1]| C[2]| C[3]| C[4]| C[5]| C[6]| C[7]| C[8]| C[9]|C[10]|C[11]|C[12]|C[13]|C[14]|C[15]| +------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+ In main.cpp.jinja2 , you need to implement the following functions: void init() : This function is used to initialize the input buffer. void model_l0() : This function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. We implement these functions one by one. The init() function is used to initialize the input buffer. It's a pure software implementation. The following code shows how to initialize the input buffer. void init (){ // Set the seed for random number generator srand (( unsigned ) time ( NULL )); // Generate 32 random numbers in range [0,100) for both vector A and B vector < int16_t > v ( 32 ); for ( auto i = 0 ; i < 32 ; i ++ ){ v [ i ] = rand () % 100 ; } // Write the random numbers to the input buffer at starting address 0, and the number of row to write is 2. __input_buffer__ . write < int16_t > ( 0 , 2 , v ); } The model_l0() function is used to implement the algorithm in the level 0 model. It's a pure software implementation of the algorithm. It's used to verify the correctness of the algorithm. The following code shows how to implement the algorithm in the level 0 model. void model_l0 (){ // Read the input buffer to A. The starting address is 0, and the number of row to read is 1. vector < int16_t > a = __input_buffer__ . read < int16_t > ( 0 , 1 ); // Read the input buffer to B. The starting address is 1, and the number of row to read is 1. vector < int16_t > b = __input_buffer__ . read < int16_t > ( 1 , 1 ); // Add A and B vector < int16_t > c ( 16 ); for ( auto i = 0 ; i < 16 ; i ++ ){ c [ i ] = a [ i ] + b [ i ]; } // Write the result C to the output buffer at starting address 0, and the number of row to write is 1. __output_buffer__ . write < int16_t > ( 0 , 1 , c ); } Now, it's time to get the instructions for RISC V core. We first write the assembly code as following: lui x1 , 0x80000 # load the base address of read_unit and write_unit conf reg lui x2 , 0x80000 # composing the configuration words for read_unit: lui x3 , 0x08440 # enable=1, addr_ext=0, addr_int=0, step_ext=1, step_int=1, iter=2 sw x3 , 0 ( x1 ) # write to conf reg, lower half sw x2 , 4 ( x1 ) # write to conf reg, upper half addi x4 , x0 , 32 # offset address boundry, used for loop end condition addi x5 , x0 , 0 # loop iterator, also work as address __back: lh x7 , 0 ( x5 ) # load one element in A (16-bit) lh x8 , 32 ( x5 ) # load one element in B (16-bit) add x7 , x7 , x8 # add sh x7 , 64 ( x5 ) # store the result addi x5 , x5 , 2 # update iterator by 2 since 16-bit is 2 bytes blt x5 , x4 , __back # check loop condition and jump __done: lui x2 , 0x80000 # composing the configuration words for read_unit: addi x2 , x2 , 0x004 # enable=1, addr_ext=0, addr_int=2, step_ext=1, step_int=1, iter=1 lui x3 , 0x08420 sw x3 , 8 ( x1 ) # write to conf reg, lower half sw x2 , 12 ( x1 ) # write to conf reg, upper half addi x0 , x0 , 0 # NOP, wait the data transfer to complete addi x0 , x0 , 0 # NOP, wait the data transfer to complete Then, we use the online RISC V assembler to compile and get the hex instructions. The following figure shows the result. 800000b7 80000137 084401b7 0030a023 0020a223 02000213 00000293 00029383 02029403 008383b3 04729023 00228293 fe42c6e3 80000137 00410113 084201b7 0030a423 0020a623 00000013 00000013","title":"Implementation"},{"location":"Docs/ToolChain/Vesyla-suite/Tutorial_RISCV/#simulation-and-verification","text":"To simulate the algorithm, simply run: . / run.sh If the output shows the simulation is successful, then the algorithm is correct.","title":"Simulation and Verification"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/","text":"Vesyla Programming Guide (v3) Note This page is written for vesyla-suite version 3 . For vesyla-suite version 2, please see Vesyla Programming Guide v2 . Note Vesyla-suite version 3 is under active development. Some of the features that exists on version 2 may not be available on version 3. We will update this page actively to reflect the changes. Basics General Guide Vesyla accept modified C++ code as input language. You shouldn't write the C++ code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of C++ grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variables except for constant variable and loop iterator should always model real memory components, and should be declared with implicit or explicit pragma. Supported constant numbers are integers. For-loop is supported. If-statement is largely supported. While-loop is not supported. Pragma Pragma is the notation that guides Vesyla during synthesis process. Vesyla recognize pragma starting with symbols #pragma . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail. There are two types of pragmas: single-line pragma and block pragma. Single-line pragma only affects the statement immediately following it. Block pragma affects all statements within the block. Block pragma is started with #pragma start and ended with #pragma end . The following example shows how to use pragmas to allocate and bind resources. Example Explicit single-line pragma that binds the variable a to register file [0,0] #pragma bind rf_0_0 RF a ; Implicit binding without pragma that binds the variable rf_0_1 to register file [0,1] RF rf_0_1 ; Block pragma that makes declare a conflict-free zone. #pragma start conflict_free_zone ... ... #pragma end conflict_free_zone Variable Declaration Storage Variable There is three type of vector storage variables: Register file variable, SRAM variable and I/O variable. Register file variable is used to model register file. SRAM variable is used to model SRAM scratch-pad memory. I/O variable is used to model input and output buffer. Example Declare a register file variable. #pragma bind rf_0_0 RF a ; Declare a SRAM variable. #pragma bind sram_0_0 SRAM b ; You should not declare any I/O variables. They are defined as global varialbes in the generated header file. You can use them as normal variables. The input buffer is named __input_buffer__ and the output buffer is named __output_buffer__ . You can only read from input buffer and write to output buffer. Writing to input buffer and reading from output buffer are not allowed. Transient Variable Transient variables are not tight to any hardware resource. It describes the unorganized stream of data after reading from the source storage variables and before writing to the destination storage variables. The type of transient variables depend on the supported data transfer mode on DRRA fabric. Currently, we support four types of transient variable types: STREAM_IO_CHUNK : Data stream between IO and RF. STREAM_SRAM_CHUNK : Data stream between SRAM and RF. STREAM_RF_CHUNK : Data stream between RF and RF, between RF and DPU, and between DPU and DPU. STREAM_ADDR : A stream of address made of integers. Scalar Auxiliary Variable Auxiliary variables are usually used for address calculation. They are not tight to any hardware resource. They can only be declared as int type at the moment. Example Declare and use scalar auxiliary variables. int i , j ; for ( i = 0 ; i < 10 ; i = i + 1 ){ j = i + 1 ; ... } Primitive Function for Address Generation Vesyla has certain reading or writing primitive functions to interact with storage variables. These primitive functions usually require address stream to specify which chunk of data is affected. To generate such address stream, you need to use primitive functions designed for address generation. Currently, three primitive functions are supported. The following example shows how to use these primitive functions to generate address stream. Example Generate an address stream that contains only one address. STREAM_ADDR addr = silago_agu_constant ( 1 ); Generate a 1-d affine address stream that start from 0, increment by 1, and has 10 elements. STREAM_ADDR addr = silago_agu_affine_1 ( 0 , 1 , 10 ); Generate a 2-d affine address stream that start from 0, increment by 1, and has 10 elements as level 1 and increment by 2 and has 20 elements as level 2. STREAM_ADDR addr = silago_agu_affine_2 ( 0 , 1 , 10 , 2 , 20 ); Primitive Function for Arithmetic Operation Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, etc. Other arithmetic operations need to be mapped to special DPU mode by primitive function call. We recommend to always use primitive function call to perform arithmetic operation. The following example shows how to use these primitive functions to perform arithmetic operation. Example Perform operation: c = a + b #pragma bind dpu_0_0 c = silago_dpu_add ( a , b ); Note that, you should always specify the binding information for arithmetic operations mapped to DPU. Otherwise, Vesyla will not be able to perform allocation and binding. If a primitive function has multiple outputs, you can use the tie() function to bundle them to a tuple. For example: Example Perform operation: e = a + b and f = c + d #pragma bind dpu_0_0 tie ( e , f ) = silago_dpu_add_2 ( a , b , c , d ); Loop Vesyla accept very restrict loop syntax to simplify the parsing process. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example int n ; n = 3 ; for ( i = 0 ; i < n + 1 ; i = i + 1 ){ ... end Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point. But the iteration number should be constant. Example of such dynamic loop is shown below: Example for ( i = 1 ; i < 4 ; i = i + 1 ) for ( j = i ; j < i + 3 ; j = j + 1 ) ... end end Warning Vesyla does not support while-loop style dynamic loop with dynamic iteration number. Free style for-loop that implements a dynamic loop is not supported as well. Advanced Features DPU Chain Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example #pragma bind dpu_0_0 t = silago_dpu_mac ( x , y ); #pragma bind dpu_0_1 z = silago_dpu_sigm ( t ); A Complete Example Here is a complete example of a Vesyla program. The program is a simple vector addition. void model_l1 (){ // Read from input buffer STREAM_IO_CHUNK sab , sc ; #pragma bind rf_0_0 RF rf_0_0 ; sab = silago_io_read ( __input_buffer__ , silago_agu_affine_1 ( 0 , 1 , 2 )); rf_0_0 = silago_rf_write_from_io_stream ( sab , silago_agu_affine_1 ( 0 , 1 , 2 ), rf_0_0 ); // Read from register file STREAM_RF_CHUNK aa , bb , cc ; aa = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 16 )); bb = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 16 , 1 , 16 )); // Computation #pragma bind dpu_0_0 cc = silago_dpu_add ( aa , bb ); // Write to register file rf_0_0 = silago_rf_write ( cc , silago_agu_affine_1 ( 0 , 1 , 16 ), rf_0_0 ); // Write to output buffer sc = silago_rf_read_to_io_stream ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 1 )); __output_buffer__ = silago_io_write ( sc , silago_agu_affine_1 ( 0 , 1 , 1 ), __output_buffer__ ); }","title":"Vesyla Programming Guide (v3)"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#vesyla-programming-guide-v3","text":"Note This page is written for vesyla-suite version 3 . For vesyla-suite version 2, please see Vesyla Programming Guide v2 . Note Vesyla-suite version 3 is under active development. Some of the features that exists on version 2 may not be available on version 3. We will update this page actively to reflect the changes.","title":"Vesyla Programming Guide (v3)"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#basics","text":"","title":"Basics"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#general-guide","text":"Vesyla accept modified C++ code as input language. You shouldn't write the C++ code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of C++ grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variables except for constant variable and loop iterator should always model real memory components, and should be declared with implicit or explicit pragma. Supported constant numbers are integers. For-loop is supported. If-statement is largely supported. While-loop is not supported.","title":"General Guide"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#pragma","text":"Pragma is the notation that guides Vesyla during synthesis process. Vesyla recognize pragma starting with symbols #pragma . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail. There are two types of pragmas: single-line pragma and block pragma. Single-line pragma only affects the statement immediately following it. Block pragma affects all statements within the block. Block pragma is started with #pragma start and ended with #pragma end . The following example shows how to use pragmas to allocate and bind resources. Example Explicit single-line pragma that binds the variable a to register file [0,0] #pragma bind rf_0_0 RF a ; Implicit binding without pragma that binds the variable rf_0_1 to register file [0,1] RF rf_0_1 ; Block pragma that makes declare a conflict-free zone. #pragma start conflict_free_zone ... ... #pragma end conflict_free_zone","title":"Pragma"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#variable-declaration","text":"","title":"Variable Declaration"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#storage-variable","text":"There is three type of vector storage variables: Register file variable, SRAM variable and I/O variable. Register file variable is used to model register file. SRAM variable is used to model SRAM scratch-pad memory. I/O variable is used to model input and output buffer. Example Declare a register file variable. #pragma bind rf_0_0 RF a ; Declare a SRAM variable. #pragma bind sram_0_0 SRAM b ; You should not declare any I/O variables. They are defined as global varialbes in the generated header file. You can use them as normal variables. The input buffer is named __input_buffer__ and the output buffer is named __output_buffer__ . You can only read from input buffer and write to output buffer. Writing to input buffer and reading from output buffer are not allowed.","title":"Storage Variable"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#transient-variable","text":"Transient variables are not tight to any hardware resource. It describes the unorganized stream of data after reading from the source storage variables and before writing to the destination storage variables. The type of transient variables depend on the supported data transfer mode on DRRA fabric. Currently, we support four types of transient variable types: STREAM_IO_CHUNK : Data stream between IO and RF. STREAM_SRAM_CHUNK : Data stream between SRAM and RF. STREAM_RF_CHUNK : Data stream between RF and RF, between RF and DPU, and between DPU and DPU. STREAM_ADDR : A stream of address made of integers.","title":"Transient Variable"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#scalar-auxiliary-variable","text":"Auxiliary variables are usually used for address calculation. They are not tight to any hardware resource. They can only be declared as int type at the moment. Example Declare and use scalar auxiliary variables. int i , j ; for ( i = 0 ; i < 10 ; i = i + 1 ){ j = i + 1 ; ... }","title":"Scalar Auxiliary Variable"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#primitive-function-for-address-generation","text":"Vesyla has certain reading or writing primitive functions to interact with storage variables. These primitive functions usually require address stream to specify which chunk of data is affected. To generate such address stream, you need to use primitive functions designed for address generation. Currently, three primitive functions are supported. The following example shows how to use these primitive functions to generate address stream. Example Generate an address stream that contains only one address. STREAM_ADDR addr = silago_agu_constant ( 1 ); Generate a 1-d affine address stream that start from 0, increment by 1, and has 10 elements. STREAM_ADDR addr = silago_agu_affine_1 ( 0 , 1 , 10 ); Generate a 2-d affine address stream that start from 0, increment by 1, and has 10 elements as level 1 and increment by 2 and has 20 elements as level 2. STREAM_ADDR addr = silago_agu_affine_2 ( 0 , 1 , 10 , 2 , 20 );","title":"Primitive Function for Address Generation"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#primitive-function-for-arithmetic-operation","text":"Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, etc. Other arithmetic operations need to be mapped to special DPU mode by primitive function call. We recommend to always use primitive function call to perform arithmetic operation. The following example shows how to use these primitive functions to perform arithmetic operation. Example Perform operation: c = a + b #pragma bind dpu_0_0 c = silago_dpu_add ( a , b ); Note that, you should always specify the binding information for arithmetic operations mapped to DPU. Otherwise, Vesyla will not be able to perform allocation and binding. If a primitive function has multiple outputs, you can use the tie() function to bundle them to a tuple. For example: Example Perform operation: e = a + b and f = c + d #pragma bind dpu_0_0 tie ( e , f ) = silago_dpu_add_2 ( a , b , c , d );","title":"Primitive Function for Arithmetic Operation"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#loop","text":"Vesyla accept very restrict loop syntax to simplify the parsing process. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example int n ; n = 3 ; for ( i = 0 ; i < n + 1 ; i = i + 1 ){ ... end Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point. But the iteration number should be constant. Example of such dynamic loop is shown below: Example for ( i = 1 ; i < 4 ; i = i + 1 ) for ( j = i ; j < i + 3 ; j = j + 1 ) ... end end Warning Vesyla does not support while-loop style dynamic loop with dynamic iteration number. Free style for-loop that implements a dynamic loop is not supported as well.","title":"Loop"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#advanced-features","text":"","title":"Advanced Features"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#dpu-chain","text":"Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example #pragma bind dpu_0_0 t = silago_dpu_mac ( x , y ); #pragma bind dpu_0_1 z = silago_dpu_sigm ( t );","title":"DPU Chain"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide/#a-complete-example","text":"Here is a complete example of a Vesyla program. The program is a simple vector addition. void model_l1 (){ // Read from input buffer STREAM_IO_CHUNK sab , sc ; #pragma bind rf_0_0 RF rf_0_0 ; sab = silago_io_read ( __input_buffer__ , silago_agu_affine_1 ( 0 , 1 , 2 )); rf_0_0 = silago_rf_write_from_io_stream ( sab , silago_agu_affine_1 ( 0 , 1 , 2 ), rf_0_0 ); // Read from register file STREAM_RF_CHUNK aa , bb , cc ; aa = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 16 )); bb = silago_rf_read ( rf_0_0 , silago_agu_affine_1 ( 16 , 1 , 16 )); // Computation #pragma bind dpu_0_0 cc = silago_dpu_add ( aa , bb ); // Write to register file rf_0_0 = silago_rf_write ( cc , silago_agu_affine_1 ( 0 , 1 , 16 ), rf_0_0 ); // Write to output buffer sc = silago_rf_read_to_io_stream ( rf_0_0 , silago_agu_affine_1 ( 0 , 1 , 1 )); __output_buffer__ = silago_io_write ( sc , silago_agu_affine_1 ( 0 , 1 , 1 ), __output_buffer__ ); }","title":"A Complete Example"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/","text":"Vesyla Programming Guide (v2) Note This page is written for vesyla-suite version 2 . It's deprecated and will be removed soon. You should only use it for old project such as DRRA characterization. For vesyla-suite version 3, please see Vesyla Programming Guide . Basics General Guide Vesyla accept modified matlab code as input language. You shouldn't write the matlab code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of matlab grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variable except for constant variable and loop iterator should always be decleared via pragma. Statement should always ends with semicolon ( ; ) to avoid unexpected outputs while simulating in matlab. Constant number is normally treated as integers, not double floating point. Pragma Pragma is the notation that guides Vesyla during synthesis process. Vesyla recongnize pragma starting with symbols %! . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail. Variable Declaration Variables supported by Vesyla are vectored Register file variables and SRAM variables. Register file variables will bind to register file and SRAM variables will bind to DiMArch. Since matlab dosen't require variable declaration, we need to give initial value to declare them. You can use the standard initialization assignment for matlab 1-D arry to declare a variable. Function such as zeros() and ones() are also supported. To declear SRAM variable, you need to use %! MEM[row, col] pragma. row and col are the coordinate of the SRAM block you want to bind for this variable. SRAM usually organized as a 2-D bit matrix without bit-level and word-level access. Data communication with SRAM happens in bulk mode where each data exchange need to be a complete SRAM row. Suppose SRAM with is N N and Register width (1 word) is M M bit. Each SRAM row will have N/M N/M words. Typical value for M M and N N are M=256 M=256 and N=16 N=16 . Since SRAM only support whole line reading and writing, the SRAM variable you defined should always have multiple of M/N M/N elements. Example The example shows how to define a SRAM variable y on SRAM block [0,0] . y is initialized by a 1-D vector [1,2,3,4,5,...,16] . y = [ 1 : 16 ]; %! MEM[0,0] To declear register file variable, you need to use %! RFIL[row, col] pragma. row and col are the coordinate of the DRRA cell you want to bind for this variable. Unlike SRAM, register file is organized in the way that each row will always represent a word. So there is no restriction on the size of register file variable as long as it doesn't exceed the register depth limit. Example The example shows how to define a register file variable x on DRRA cell [0,0] . x has 5 elements and is initialized by a zeros() function which will set all elements in x to 0 . x = zeros ( 1 , 5 ); %! REFI[0,0] For debugging purpose, vesyla allows initialization of register file variable. However, register should not be initialized with any value other than zeros because the real DRRA cell doesn't have interface to support the register initalization. Register file variables hence should always get data from SRAM variables. Error The following variable declaration style is incorrect: No storage pragma specified x = zeros ( 1 , 5 ); Initialized to scalar x = 1 ; %! RFILE[1,1] Initialized to 2-D array x = ones ( 2 , 3 ); %! RFILE[1,1] SRAM varible is not the size of SRAM row x = [ 1 : 3 ]; %! MEM[0,1] Initialization function randi() is not supported x = randi ( 10 , 1 , 16 ); %! MEM[0,1] Vector Slicing and Address Generation Each DPU can only process one scalar data each time, so the vectored register variable should be slice first before sending to DPU. The slicing operation is mapped on AGU by REFI instruction. While writing matlab code, you don't have to worry about the slicing since matlab directly support vector slicing. Here is an example of slicing a vector: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] If you don't use any slicing and directly feed a vectored register variable to arithmetic operaion, Vesyla will use the full range of that variable. When slicing a SRAM varialbe, the minimal slice should always be multiple of 16. Except for the matlab default slicing method, you can also use two primitive AGU function to linear slice a vectored varialbe both in 1-D or 2-D. Example is given below. All address sequence in the following example are \"1,2,3,4,5\". Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( silago_agu_linear_1d ( 1 , 1 , 5 )) + y ( silago_agu_linear_2d ( 1 , 0 , 1 , 1 , 5 )); %! DPU[0,0] Arithmetic Operation Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, sum, abs, etc. Special arithmetic operation need to be mapped to special DPU mode by primitive function call, see section Primitive Function . Bug Symbol ~ is not supported yet! For arithmetic assignment, you can have a multiple variables as output depending on the DPU mode. The ignored output can be muted by symbol ~ . Arithmetic operation need a computation resource to perform required operation, that is the DPU. So, every arithmetic operation need to bind to a DPU resource via pragma. Example of an arithmetic assignment is demonstrated as following: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] Static Loop Vesyla accept all static loops. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example n = 3 ; for i = 1 : 1 : n + 1 ... end Dynamic Loop Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point, and dynamic iteration. However, those number should be in address domain, a.k.a computed by RACCU and is fully determinastic after unrolling all the loops. Example of such dynamic loop is shown below: Example for i = 1 : 1 : 4 for j = i : 1 : i + 3 ... end end Branch Vesyla support normal matlab branch except for both operands of condition are constants. The usage of branch is the same as the original matlab code. For example: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] w = [ 3 , 5 ]; %! REFI[0,0] if w ( 1 ) > w ( 2 ) y = x ; else y = x + y ; %! DPU[0,0] end Address Constraint Address constraints are parameters used by address generation in AGU. Address constraints can be constant or RACCU variable calculated at run-time in RACCU. Dynamic address constraint variables are usually used in loops. Example below shows how to use a RACCU variable to serve as address constraint. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] a = 1 ; %! RACCU_VAR for i = 1 : 1 : 4 y ( a + 1 : a + 1 + 5 ) = x ( 1 : 5 ) + y ( a : a + 5 ); %! DPU[0,0] a = a + 1 ; end Advanced Features Macro Vesyla support symbolic expression to enable fast design space exploration. One of the technique is to use macros. Before the lexecal analysis, vesyla will expand all macro to normal program code. Macro gives programmer the tool to generate multiple program with small variations. Programmer need to provide a template and a series of data. Data is organized in json format and will be loaded in to evaluate those macros defined in template. Template use a grammar like the templating package inja . Infact, vesyla directly use inja library to evaluate macros. Example below demonstrate how to define a loop in template: Example An template file defined as following: { % for x in range(par_col) %} x0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] y0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] { % endfor %} With a json-formated data file: { \"par_col\" : 2 } This template will generate a real matlab code as following by expanding the FOR-LOOP macro: x0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] y0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] x0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] y0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] Tip More complex usage please visit inja website. Primitive Function Primitive DPU functions are functions that corresponds to a complete DPU mode. Different DPUs targeting on different application domain may have some special modes specifically made for such application domain. For example, sigmoid function for neural network application. Those primitive function is not directly supported by matlab, but they are supported by vesyla. To use a specific DPU mode as primitive function, first you need to make sure the DRRA cell you are using has such mode. Then you need to change the configuration of vesyla to recongnize such mode. The configuration file is $Vesyla_root/config/primitive_func_def.xml . Finally, you can use the function inside your program. All primitive DPU functions have name should start with silago_dpu_ to be accepted by Vesyla. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] x = silago_dpu_sigmoid ( x ); %! DPU[0,0] AUGs also have special primitive functions to express the complex addressing mode. But AGU primitive functions are not custom. There are two AGU primitive function: silago_agu_linear_1d() and silago_agu_linear_2d() . More AGU primitive functions will be added if some application domain requires. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] a = [ 1 ]; %! REFI[0,0] x = x + a ( silago_agu_linear_1d ( 1 , 0 , 5 )); %! DPU[0,0] Resource Sharing Region When multiple operations need some common operands, due to the limit of the number of reading ports, those operations can't happen at the same time in normal condition. Resource sharing region tries to solve the problem. By enabling the broadcasting mechanism, all operation will recieve the same common operand at the same time generated by single reading port of the register file. The datapath of transmitting the common operand is now shared among those operations. Resource sharing region requires a fixed datapath layout. Dynamic change of datapath structure is forbidden inside resource sharing region. So, you should only use it when needed. Following example shows how to active resource sharing region. Example x0 = [ 1 : 5 ]; %! REFI[0,0] x1 = [ 1 : 5 ]; %! REFI[1,0] a2 = [ 1 : 5 ]; %! REFI[2,0] x3 = [ 1 : 5 ]; %! REFI[3,0] x4 = [ 1 : 5 ]; %! REFI[4,0] %! RESOURCE_SHARING_BEGIN x0 = x0 + a2 ; %! DPU[0,0] x1 = x1 + a2 ; %! DPU[1,0] x3 = x3 + a2 ; %! DPU[3,0] x4 = x4 + a2 ; %! DPU[4,0] %! RESOURCE_SHARING_END DPU Chain Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] z = [ 1 : 5 ]; %! REFI[0,0] t = zeros ( 1 , 5 ); %! CDPU[0,0] t = x + y ; z = silago_dpu_sigmoid ( t ); %! DPU[1,0] DPU Internal Scalar Register Inside each DPU, there are two internal scalar registers which can be explicitly used via high-level matlab program. One can use them by declearing them with the pragma %! CDPU[row, col] . The available functions to load and store values to/from internal scalar registers are: r0 = silago_dpu_load_reg_0 ( x ( 1 )); r1 = silago_dpu_load_reg_1 ( x ( 1 )); [ r0 , r1 ] = silago_dpu_load_reg_both ( x ( 1 ), x ( 2 )); x ( 1 ) = silago_dpu_load_store_0 ( r0 ); x ( 1 ) = silago_dpu_load_store_1 ( r1 ); [ x ( 1 ), y ( 1 )] = silago_dpu_load_store_both ( r0 , r1 ); Warning Programmer should keep in mind that lifetime and physical location of those variable. Vesyla has very weak semantic checking on those internal scalar register variables. Example For example, if one want to calculate a function: y = ax.y y = ax.y . Instead of put the coefficient a a inside a normal register and waste other register entries of the same register block, you can put the coefficient to the internal register, and configure DPU to a scaled multiplication mode to get the correct result. a_mem = [ 1 : 16 ]; %! SRAM[0,0] x_mem = [ 1 : 16 ]; %! SRAM[0,0] y_mem = [ 1 : 16 ]; %! SRAM[0,0] x = [ 1 : 16 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] r = zeros ( 1 , 1 ); %! CDPU[0,0] x = a_mem ; r = silago_dpu_load_reg_1 ( x ( 1 )); x = x_mem ; y = y_mem ; y = silago_dpu_scaled_mul ( x , y , r ); %! DPU[0,0] y_mem = y ; Not Supported Some matlab code is not accepted by Vesyla because it can't execute on DRRA fabric. They are: While-loop. For-loop inside branch. Arithmetic statement that can't be mapped to single DPU mode. Normal function call except for primitive function call. Indirect addressing.","title":"Vesyla Programming Guide (v2)"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#vesyla-programming-guide-v2","text":"Note This page is written for vesyla-suite version 2 . It's deprecated and will be removed soon. You should only use it for old project such as DRRA characterization. For vesyla-suite version 3, please see Vesyla Programming Guide .","title":"Vesyla Programming Guide (v2)"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#basics","text":"","title":"Basics"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#general-guide","text":"Vesyla accept modified matlab code as input language. You shouldn't write the matlab code like a programming language. You should instead use it as a tool to model the behaviour of the hardware. Vesyla supports small portion of matlab grammar. There are some generic rules expressing the programming style vesyla accepts. General function call is not allowed unless the function is predefined as primitive function. Variable except for constant variable and loop iterator should always be decleared via pragma. Statement should always ends with semicolon ( ; ) to avoid unexpected outputs while simulating in matlab. Constant number is normally treated as integers, not double floating point.","title":"General Guide"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#pragma","text":"Pragma is the notation that guides Vesyla during synthesis process. Vesyla recongnize pragma starting with symbols %! . The main function of pragmas is specify allocation and binding information since Vesyla can't perform automatic allocation and binding. Section Variable Declaration , Arithmetic Operation , Address Constraint DPU Chain and DPU Internal Scalar Register describe how to use pragmas to allocate and bind resources. Some other usage of pragma also exist, check section Resource Sharing Region for more detail.","title":"Pragma"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#variable-declaration","text":"Variables supported by Vesyla are vectored Register file variables and SRAM variables. Register file variables will bind to register file and SRAM variables will bind to DiMArch. Since matlab dosen't require variable declaration, we need to give initial value to declare them. You can use the standard initialization assignment for matlab 1-D arry to declare a variable. Function such as zeros() and ones() are also supported. To declear SRAM variable, you need to use %! MEM[row, col] pragma. row and col are the coordinate of the SRAM block you want to bind for this variable. SRAM usually organized as a 2-D bit matrix without bit-level and word-level access. Data communication with SRAM happens in bulk mode where each data exchange need to be a complete SRAM row. Suppose SRAM with is N N and Register width (1 word) is M M bit. Each SRAM row will have N/M N/M words. Typical value for M M and N N are M=256 M=256 and N=16 N=16 . Since SRAM only support whole line reading and writing, the SRAM variable you defined should always have multiple of M/N M/N elements. Example The example shows how to define a SRAM variable y on SRAM block [0,0] . y is initialized by a 1-D vector [1,2,3,4,5,...,16] . y = [ 1 : 16 ]; %! MEM[0,0] To declear register file variable, you need to use %! RFIL[row, col] pragma. row and col are the coordinate of the DRRA cell you want to bind for this variable. Unlike SRAM, register file is organized in the way that each row will always represent a word. So there is no restriction on the size of register file variable as long as it doesn't exceed the register depth limit. Example The example shows how to define a register file variable x on DRRA cell [0,0] . x has 5 elements and is initialized by a zeros() function which will set all elements in x to 0 . x = zeros ( 1 , 5 ); %! REFI[0,0] For debugging purpose, vesyla allows initialization of register file variable. However, register should not be initialized with any value other than zeros because the real DRRA cell doesn't have interface to support the register initalization. Register file variables hence should always get data from SRAM variables. Error The following variable declaration style is incorrect: No storage pragma specified x = zeros ( 1 , 5 ); Initialized to scalar x = 1 ; %! RFILE[1,1] Initialized to 2-D array x = ones ( 2 , 3 ); %! RFILE[1,1] SRAM varible is not the size of SRAM row x = [ 1 : 3 ]; %! MEM[0,1] Initialization function randi() is not supported x = randi ( 10 , 1 , 16 ); %! MEM[0,1]","title":"Variable Declaration"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#vector-slicing-and-address-generation","text":"Each DPU can only process one scalar data each time, so the vectored register variable should be slice first before sending to DPU. The slicing operation is mapped on AGU by REFI instruction. While writing matlab code, you don't have to worry about the slicing since matlab directly support vector slicing. Here is an example of slicing a vector: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0] If you don't use any slicing and directly feed a vectored register variable to arithmetic operaion, Vesyla will use the full range of that variable. When slicing a SRAM varialbe, the minimal slice should always be multiple of 16. Except for the matlab default slicing method, you can also use two primitive AGU function to linear slice a vectored varialbe both in 1-D or 2-D. Example is given below. All address sequence in the following example are \"1,2,3,4,5\". Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( silago_agu_linear_1d ( 1 , 1 , 5 )) + y ( silago_agu_linear_2d ( 1 , 0 , 1 , 1 , 5 )); %! DPU[0,0]","title":"Vector Slicing and Address Generation"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#arithmetic-operation","text":"Certain type of arithmetic operations are supported by Vesyla. They are addition, subtraction, dot multiplication, sum, abs, etc. Special arithmetic operation need to be mapped to special DPU mode by primitive function call, see section Primitive Function . Bug Symbol ~ is not supported yet! For arithmetic assignment, you can have a multiple variables as output depending on the DPU mode. The ignored output can be muted by symbol ~ . Arithmetic operation need a computation resource to perform required operation, that is the DPU. So, every arithmetic operation need to bind to a DPU resource via pragma. Example of an arithmetic assignment is demonstrated as following: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] y ( 1 : 5 ) = x ( 1 : 5 ) + y ( 1 : 5 ); %! DPU[0,0]","title":"Arithmetic Operation"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#static-loop","text":"Vesyla accept all static loops. A static loop should have constant start point, static increment as well as static iteration. If an expression that can be simplified to a constant number, it also considered as constant, hence can be used in static loop. Example below shows how to use a static loop. Example n = 3 ; for i = 1 : 1 : n + 1 ... end","title":"Static Loop"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#dynamic-loop","text":"Vesyla support limited dynamic loops. Dynamic loop can have dynamic start point, and dynamic iteration. However, those number should be in address domain, a.k.a computed by RACCU and is fully determinastic after unrolling all the loops. Example of such dynamic loop is shown below: Example for i = 1 : 1 : 4 for j = i : 1 : i + 3 ... end end","title":"Dynamic Loop"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#branch","text":"Vesyla support normal matlab branch except for both operands of condition are constants. The usage of branch is the same as the original matlab code. For example: Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] w = [ 3 , 5 ]; %! REFI[0,0] if w ( 1 ) > w ( 2 ) y = x ; else y = x + y ; %! DPU[0,0] end","title":"Branch"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#address-constraint","text":"Address constraints are parameters used by address generation in AGU. Address constraints can be constant or RACCU variable calculated at run-time in RACCU. Dynamic address constraint variables are usually used in loops. Example below shows how to use a RACCU variable to serve as address constraint. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] a = 1 ; %! RACCU_VAR for i = 1 : 1 : 4 y ( a + 1 : a + 1 + 5 ) = x ( 1 : 5 ) + y ( a : a + 5 ); %! DPU[0,0] a = a + 1 ; end","title":"Address Constraint"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#advanced-features","text":"","title":"Advanced Features"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#macro","text":"Vesyla support symbolic expression to enable fast design space exploration. One of the technique is to use macros. Before the lexecal analysis, vesyla will expand all macro to normal program code. Macro gives programmer the tool to generate multiple program with small variations. Programmer need to provide a template and a series of data. Data is organized in json format and will be loaded in to evaluate those macros defined in template. Template use a grammar like the templating package inja . Infact, vesyla directly use inja library to evaluate macros. Example below demonstrate how to define a loop in template: Example An template file defined as following: { % for x in range(par_col) %} x0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] y0_mem_ {{ x }} = [ 1 : n / col ]; %! MEM[0, {{x}}] { % endfor %} With a json-formated data file: { \"par_col\" : 2 } This template will generate a real matlab code as following by expanding the FOR-LOOP macro: x0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] y0_mem_0 = [ 1 : n / col ]; %! MEM[0, 0] x0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] y0_mem_1 = [ 1 : n / col ]; %! MEM[0, 1] Tip More complex usage please visit inja website.","title":"Macro"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#primitive-function","text":"Primitive DPU functions are functions that corresponds to a complete DPU mode. Different DPUs targeting on different application domain may have some special modes specifically made for such application domain. For example, sigmoid function for neural network application. Those primitive function is not directly supported by matlab, but they are supported by vesyla. To use a specific DPU mode as primitive function, first you need to make sure the DRRA cell you are using has such mode. Then you need to change the configuration of vesyla to recongnize such mode. The configuration file is $Vesyla_root/config/primitive_func_def.xml . Finally, you can use the function inside your program. All primitive DPU functions have name should start with silago_dpu_ to be accepted by Vesyla. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] x = silago_dpu_sigmoid ( x ); %! DPU[0,0] AUGs also have special primitive functions to express the complex addressing mode. But AGU primitive functions are not custom. There are two AGU primitive function: silago_agu_linear_1d() and silago_agu_linear_2d() . More AGU primitive functions will be added if some application domain requires. Example of using primitive DPU function: Example x = [ 1 : 5 ]; %! REFI[0,0] a = [ 1 ]; %! REFI[0,0] x = x + a ( silago_agu_linear_1d ( 1 , 0 , 5 )); %! DPU[0,0]","title":"Primitive Function"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#resource-sharing-region","text":"When multiple operations need some common operands, due to the limit of the number of reading ports, those operations can't happen at the same time in normal condition. Resource sharing region tries to solve the problem. By enabling the broadcasting mechanism, all operation will recieve the same common operand at the same time generated by single reading port of the register file. The datapath of transmitting the common operand is now shared among those operations. Resource sharing region requires a fixed datapath layout. Dynamic change of datapath structure is forbidden inside resource sharing region. So, you should only use it when needed. Following example shows how to active resource sharing region. Example x0 = [ 1 : 5 ]; %! REFI[0,0] x1 = [ 1 : 5 ]; %! REFI[1,0] a2 = [ 1 : 5 ]; %! REFI[2,0] x3 = [ 1 : 5 ]; %! REFI[3,0] x4 = [ 1 : 5 ]; %! REFI[4,0] %! RESOURCE_SHARING_BEGIN x0 = x0 + a2 ; %! DPU[0,0] x1 = x1 + a2 ; %! DPU[1,0] x3 = x3 + a2 ; %! DPU[3,0] x4 = x4 + a2 ; %! DPU[4,0] %! RESOURCE_SHARING_END","title":"Resource Sharing Region"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#dpu-chain","text":"Datapath can be configured as a chain of DPU operation. The output of the previous DPU will immediately enter the next DPU without any register file involved in between. Consider we want to compute a vector addition and a sigmoid function: z = \\sigma (x+y) z = \\sigma (x+y) . We can employ two DPUs to perform the complete operation in pipelined fashion. By writing the matlab like the following, you can enable the feature. Example x = [ 1 : 5 ]; %! REFI[0,0] y = [ 1 : 5 ]; %! REFI[0,0] z = [ 1 : 5 ]; %! REFI[0,0] t = zeros ( 1 , 5 ); %! CDPU[0,0] t = x + y ; z = silago_dpu_sigmoid ( t ); %! DPU[1,0]","title":"DPU Chain"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#dpu-internal-scalar-register","text":"Inside each DPU, there are two internal scalar registers which can be explicitly used via high-level matlab program. One can use them by declearing them with the pragma %! CDPU[row, col] . The available functions to load and store values to/from internal scalar registers are: r0 = silago_dpu_load_reg_0 ( x ( 1 )); r1 = silago_dpu_load_reg_1 ( x ( 1 )); [ r0 , r1 ] = silago_dpu_load_reg_both ( x ( 1 ), x ( 2 )); x ( 1 ) = silago_dpu_load_store_0 ( r0 ); x ( 1 ) = silago_dpu_load_store_1 ( r1 ); [ x ( 1 ), y ( 1 )] = silago_dpu_load_store_both ( r0 , r1 ); Warning Programmer should keep in mind that lifetime and physical location of those variable. Vesyla has very weak semantic checking on those internal scalar register variables. Example For example, if one want to calculate a function: y = ax.y y = ax.y . Instead of put the coefficient a a inside a normal register and waste other register entries of the same register block, you can put the coefficient to the internal register, and configure DPU to a scaled multiplication mode to get the correct result. a_mem = [ 1 : 16 ]; %! SRAM[0,0] x_mem = [ 1 : 16 ]; %! SRAM[0,0] y_mem = [ 1 : 16 ]; %! SRAM[0,0] x = [ 1 : 16 ]; %! REFI[0,0] y = [ 1 : 16 ]; %! REFI[0,0] r = zeros ( 1 , 1 ); %! CDPU[0,0] x = a_mem ; r = silago_dpu_load_reg_1 ( x ( 1 )); x = x_mem ; y = y_mem ; y = silago_dpu_scaled_mul ( x , y , r ); %! DPU[0,0] y_mem = y ;","title":"DPU Internal Scalar Register"},{"location":"Docs/ToolChain/Vesyla-suite/VesylaProgrammingGuide_v2/#not-supported","text":"Some matlab code is not accepted by Vesyla because it can't execute on DRRA fabric. They are: While-loop. For-loop inside branch. Arithmetic statement that can't be mapped to single DPU mode. Normal function call except for primitive function call. Indirect addressing.","title":"Not Supported"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/","text":"Note Instruction fields marked by bold font are controllable and observable. Users can modify these fields in Manas input file. HALT Field Position Width Default Value Description instr_code [26, 23] 4 0 Instruction code for HALT REFI Field Position Width Default Value Description instr_code [80, 77] 4 1 Instruction code for REFI port_no [76, 75] 2 0 Selects one of the RFile port. [0]:w0; [1]:w1; [2]:r0; [3]:r1; extra [74, 73] 2 0 How many following chunks? init_addr_sd [72, 72] 1 0 Is init_addr static or dymamic? [0]:s; [1]:d; init_addr [71, 66] 6 0 Initial address. l1_iter [65, 60] 6 0 Level-1 iteration - 1. init_delay [59, 54] 6 0 Initial delay. l1_iter_sd [53, 53] 1 0 Is level-1 iteration static or dymamic? [0]:s; [1]:d; init_delay_sd [52, 52] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; unused_0 [51, 50] 2 2 Deprecated. l1_step_sd [49, 49] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l1_step [48, 43] 6 1 Level-1 step l1_step_sign [42, 42] 1 0 The sign of level-1 step. [0]:+; [1]:-; l1_delay_sd [41, 41] 1 0 Is the level-1 delay static or dynamic? [0]:s; [1]:d; l1_delay [40, 37] 4 0 The level-1 delay, middle delay l2_iter_sd [36, 36] 1 0 Is level-2 iteration static or dymamic? [0]:s; [1]:d; l2_iter [35, 31] 5 0 The level-2 iteration - 1. l2_step [30, 27] 4 1 The level-2 step. unused_1 [26, 23] 4 3 Deprecated. l2_delay_sd [22, 22] 1 0 Is the level-2 delay static or dynamic? [0]:s; [1]:d; l2_delay [21, 16] 6 0 The level-2 delay, repetition delay. unused_2 [15, 10] 6 0 Deprecated. l1_delay_ext [9, 8] 2 0 The extened bits near MSB of l1_delay. l2_iter_ext [7, 7] 1 0 The extened bits near MSB of l2_iter. l2_step_ext [6, 5] 2 0 The extened bits near MSB of l2_step. unused_3 [4, 2] 3 0 Deprecated. dimarch [1, 1] 1 0 Is reading/writing from/to DiMArch? [0]:n; [1]:y; compress [0, 0] 1 0 Is the data compressed? [0]:n; [1]:y; DPU Field Position Width Default Value Description instr_code [26, 23] 4 4 Instruction code for DPU mode [22, 18] 5 0 The DPU mode. [0]:idle; [1]:add; [2]:sum_acc; [3]:add_const; [4]:subt; [5]:subt_abs; [6]:mode_6; [7]:mult; [8]:mult_add; [9]:mult_const; [10]:mac; [11]:ld_ir; [12]:axpy; [13]:max_min_acc; [14]:max_min_const; [15]:mode_15; [16]:max_min; [17]:shift_l; [18]:shift_r; [19]:sigm; [20]:tanhyp; [21]:expon; [22]:lk_relu; [23]:relu; [24]:div; [25]:acc_softmax; [26]:div_softmax; [27]:ld_acc; [28]:scale_dw; [29]:scale_up; [30]:mac_inter; [31]:mode_31; control [17, 16] 2 2 The controll mode: saturation and operator type. [0]:nosat_int; [1]:nosat_fx; [2]:sat_int; [3]:sat_fx; unused_0 [15, 10] 6 2 Deprecated. acc_clear [9, 2] 8 0 The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode. io_change [1, 0] 2 0 The IO mode: negate input and absolute output. [0]:no_change; [1]:negate_in0; [2]:negate_in1; [3]:abs_out; SWB Field Position Width Default Value Description instr_code [26, 23] 4 5 Instruction code for SWB unused0 [22, 22] 1 1 Deprecated. src_row [21, 21] 1 0 Source row. src_block [20, 20] 1 0 Source block, RF or DPU. [0]:rf; [1]:dpu; src_port [19, 19] 1 0 source port. hb_index [18, 16] 3 0 Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0. send_to_other_row [15, 15] 1 0 Flag of whether src and dest row are equal. [0]:n; [1]:y; v_index [14, 12] 3 0 Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2. JUMP Field Position Width Default Value Description instr_code [26, 23] 4 6 Instruction code for JUMP pc [22, 17] 6 0 The PC to jump to WAIT Field Position Width Default Value Description instr_code [26, 23] 4 7 Instruction code for WAIT cycle_sd [22, 22] 1 0 Is the cycle static or dynamic? [0]:s; [1]:d; cycle [21, 7] 15 0 Number of cycles - 1 LOOP Field Position Width Default Value Description instr_code [53, 50] 4 8 Instruction code for LOOP extra [49, 49] 1 0 How many following chunks? loopid [48, 47] 2 0 The id of the loop manager slot. endpc [46, 41] 6 0 The PC where loop ends. start_sd [40, 40] 1 0 Is the start static or dynamic? [0]:s; [1]:d; start [39, 34] 6 0 The start of iterator. iter_sd [33, 33] 1 0 Is the iteration count static or dynamic? [0]:s; [1]:d; iter [32, 27] 6 0 The number of iteration. step_sd [26, 26] 1 0 Is the step static or dynamic? [0]:s; [1]:d; step [25, 20] 6 1 The iteration step. link [19, 16] 4 0 The loops that have the same endpc will be linked together. This field is 1-hot encoded. BW Field Position Width Default Value Description instr_code [26, 23] 4 9 Instruction code for BW config [22, 21] 2 0 Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit RACCU Field Position Width Default Value Description instr_code [26, 23] 4 10 Instruction code for RACCU mode [22, 20] 3 0 RACCU mode [0]:idle; [1]:add; [2]:sub; [3]:shift_r; [4]:shift_l; [5]:mult; [6]:mult_add; [7]:mult_sub; operand1_sd [19, 19] 1 0 Is the first operand static or dynamic? [0]:s; [1]:d; operand1 [18, 12] 7 0 First operand. operand2_sd [11, 11] 1 0 Is the second operand static or dynamic? [0]:s; [1]:d; operand2 [10, 4] 7 0 Second operand. result [3, 0] 4 0 The RACCU register to store the result. BRANCH Field Position Width Default Value Description instr_code [26, 23] 4 11 Instruction code for BRANCH mode [22, 21] 2 0 The branch mode false_pc [20, 15] 6 0 The PC to jump to in case the condition is false. ROUTE Field Position Width Default Value Description instr_code [26, 23] 4 12 Instruction code for ROUTE horizontal_dir [22, 22] 1 0 The horizontal direction: West or East. [0]:w; [1]:e; horizontal_hops [21, 19] 3 0 The horizontal hops. vertical_dir [18, 18] 1 0 The vertical direction: South or North. [0]:s; [1]:n; vertical_hops [17, 15] 3 0 The vertical hops. direction [14, 14] 1 0 The data transfer direction: Read or Write. [0]:r; [1]:w; select_drra_row [13, 13] 1 0 The drra row that send/recieve the data. SRAM Field Position Width Default Value Description instr_code [80, 77] 4 13 Instruction code for SRAM rw [76, 76] 1 0 Read or Write [0]:r; [1]:w; init_addr [75, 69] 7 0 Initial address init_delay [68, 65] 4 0 initial delay l1_iter [64, 58] 7 0 level-1 iteration - 1. l1_step [57, 50] 8 1 level-1 step l1_delay [49, 44] 6 0 level-1 delay l2_iter [43, 37] 7 0 level-2 iteration - 1. l2_step [36, 29] 8 1 level-2 step l2_delay [28, 23] 6 0 level-2 delay init_addr_sd [22, 22] 1 0 Is initial address static or dynamic? [0]:s; [1]:d; l1_iter_sd [21, 21] 1 0 Is level-1 iteration static or dynamic? [0]:s; [1]:d; l2_iter_sd [20, 20] 1 0 Is level-2 iteration static or dynamic? [0]:s; [1]:d; init_delay_sd [19, 19] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; l1_delay_sd [18, 18] 1 0 Is level-1 delay static or dynamic? [0]:s; [1]:d; l2_delay_sd [17, 17] 1 0 Is level-2 delay static or dynamic? [0]:s; [1]:d; l1_step_sd [16, 16] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l2_step_sd [15, 15] 1 0 Is level-2 step static or dynamic? [0]:s; [1]:d; hops [14, 11] 4 0 Number of hops to reach the DiMArch cell - 1","title":"Isa"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#halt","text":"Field Position Width Default Value Description instr_code [26, 23] 4 0 Instruction code for HALT","title":"HALT"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#refi","text":"Field Position Width Default Value Description instr_code [80, 77] 4 1 Instruction code for REFI port_no [76, 75] 2 0 Selects one of the RFile port. [0]:w0; [1]:w1; [2]:r0; [3]:r1; extra [74, 73] 2 0 How many following chunks? init_addr_sd [72, 72] 1 0 Is init_addr static or dymamic? [0]:s; [1]:d; init_addr [71, 66] 6 0 Initial address. l1_iter [65, 60] 6 0 Level-1 iteration - 1. init_delay [59, 54] 6 0 Initial delay. l1_iter_sd [53, 53] 1 0 Is level-1 iteration static or dymamic? [0]:s; [1]:d; init_delay_sd [52, 52] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; unused_0 [51, 50] 2 2 Deprecated. l1_step_sd [49, 49] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l1_step [48, 43] 6 1 Level-1 step l1_step_sign [42, 42] 1 0 The sign of level-1 step. [0]:+; [1]:-; l1_delay_sd [41, 41] 1 0 Is the level-1 delay static or dynamic? [0]:s; [1]:d; l1_delay [40, 37] 4 0 The level-1 delay, middle delay l2_iter_sd [36, 36] 1 0 Is level-2 iteration static or dymamic? [0]:s; [1]:d; l2_iter [35, 31] 5 0 The level-2 iteration - 1. l2_step [30, 27] 4 1 The level-2 step. unused_1 [26, 23] 4 3 Deprecated. l2_delay_sd [22, 22] 1 0 Is the level-2 delay static or dynamic? [0]:s; [1]:d; l2_delay [21, 16] 6 0 The level-2 delay, repetition delay. unused_2 [15, 10] 6 0 Deprecated. l1_delay_ext [9, 8] 2 0 The extened bits near MSB of l1_delay. l2_iter_ext [7, 7] 1 0 The extened bits near MSB of l2_iter. l2_step_ext [6, 5] 2 0 The extened bits near MSB of l2_step. unused_3 [4, 2] 3 0 Deprecated. dimarch [1, 1] 1 0 Is reading/writing from/to DiMArch? [0]:n; [1]:y; compress [0, 0] 1 0 Is the data compressed? [0]:n; [1]:y;","title":"REFI"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#dpu","text":"Field Position Width Default Value Description instr_code [26, 23] 4 4 Instruction code for DPU mode [22, 18] 5 0 The DPU mode. [0]:idle; [1]:add; [2]:sum_acc; [3]:add_const; [4]:subt; [5]:subt_abs; [6]:mode_6; [7]:mult; [8]:mult_add; [9]:mult_const; [10]:mac; [11]:ld_ir; [12]:axpy; [13]:max_min_acc; [14]:max_min_const; [15]:mode_15; [16]:max_min; [17]:shift_l; [18]:shift_r; [19]:sigm; [20]:tanhyp; [21]:expon; [22]:lk_relu; [23]:relu; [24]:div; [25]:acc_softmax; [26]:div_softmax; [27]:ld_acc; [28]:scale_dw; [29]:scale_up; [30]:mac_inter; [31]:mode_31; control [17, 16] 2 2 The controll mode: saturation and operator type. [0]:nosat_int; [1]:nosat_fx; [2]:sat_int; [3]:sat_fx; unused_0 [15, 10] 6 2 Deprecated. acc_clear [9, 2] 8 0 The accumulator clear signal will be triggered if the accumulation reaches this number. It also serves as immediate value for some DPU mode. io_change [1, 0] 2 0 The IO mode: negate input and absolute output. [0]:no_change; [1]:negate_in0; [2]:negate_in1; [3]:abs_out;","title":"DPU"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#swb","text":"Field Position Width Default Value Description instr_code [26, 23] 4 5 Instruction code for SWB unused0 [22, 22] 1 1 Deprecated. src_row [21, 21] 1 0 Source row. src_block [20, 20] 1 0 Source block, RF or DPU. [0]:rf; [1]:dpu; src_port [19, 19] 1 0 source port. hb_index [18, 16] 3 0 Index of horizontal bus. This is the column difference of the src and dest cell shifting by 2. For example if the path is from [0,0] to [1,2], the column difference is -2, so the hb_index = -2+2=0. send_to_other_row [15, 15] 1 0 Flag of whether src and dest row are equal. [0]:n; [1]:y; v_index [14, 12] 3 0 Index of vertical bus. This is the dest port. If destination is RF, the v_index is the port number, if the dest is DPU, the v_index is port number + 2.","title":"SWB"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#jump","text":"Field Position Width Default Value Description instr_code [26, 23] 4 6 Instruction code for JUMP pc [22, 17] 6 0 The PC to jump to","title":"JUMP"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#wait","text":"Field Position Width Default Value Description instr_code [26, 23] 4 7 Instruction code for WAIT cycle_sd [22, 22] 1 0 Is the cycle static or dynamic? [0]:s; [1]:d; cycle [21, 7] 15 0 Number of cycles - 1","title":"WAIT"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#loop","text":"Field Position Width Default Value Description instr_code [53, 50] 4 8 Instruction code for LOOP extra [49, 49] 1 0 How many following chunks? loopid [48, 47] 2 0 The id of the loop manager slot. endpc [46, 41] 6 0 The PC where loop ends. start_sd [40, 40] 1 0 Is the start static or dynamic? [0]:s; [1]:d; start [39, 34] 6 0 The start of iterator. iter_sd [33, 33] 1 0 Is the iteration count static or dynamic? [0]:s; [1]:d; iter [32, 27] 6 0 The number of iteration. step_sd [26, 26] 1 0 Is the step static or dynamic? [0]:s; [1]:d; step [25, 20] 6 1 The iteration step. link [19, 16] 4 0 The loops that have the same endpc will be linked together. This field is 1-hot encoded.","title":"LOOP"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#bw","text":"Field Position Width Default Value Description instr_code [26, 23] 4 9 Instruction code for BW config [22, 21] 2 0 Bitwidth configuration for DPU: 4-bit, 8-bit, 16-bit","title":"BW"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#raccu","text":"Field Position Width Default Value Description instr_code [26, 23] 4 10 Instruction code for RACCU mode [22, 20] 3 0 RACCU mode [0]:idle; [1]:add; [2]:sub; [3]:shift_r; [4]:shift_l; [5]:mult; [6]:mult_add; [7]:mult_sub; operand1_sd [19, 19] 1 0 Is the first operand static or dynamic? [0]:s; [1]:d; operand1 [18, 12] 7 0 First operand. operand2_sd [11, 11] 1 0 Is the second operand static or dynamic? [0]:s; [1]:d; operand2 [10, 4] 7 0 Second operand. result [3, 0] 4 0 The RACCU register to store the result.","title":"RACCU"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#branch","text":"Field Position Width Default Value Description instr_code [26, 23] 4 11 Instruction code for BRANCH mode [22, 21] 2 0 The branch mode false_pc [20, 15] 6 0 The PC to jump to in case the condition is false.","title":"BRANCH"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#route","text":"Field Position Width Default Value Description instr_code [26, 23] 4 12 Instruction code for ROUTE horizontal_dir [22, 22] 1 0 The horizontal direction: West or East. [0]:w; [1]:e; horizontal_hops [21, 19] 3 0 The horizontal hops. vertical_dir [18, 18] 1 0 The vertical direction: South or North. [0]:s; [1]:n; vertical_hops [17, 15] 3 0 The vertical hops. direction [14, 14] 1 0 The data transfer direction: Read or Write. [0]:r; [1]:w; select_drra_row [13, 13] 1 0 The drra row that send/recieve the data.","title":"ROUTE"},{"location":"Docs/ToolChain/Vesyla-suite/InstructionSet/isa/#sram","text":"Field Position Width Default Value Description instr_code [80, 77] 4 13 Instruction code for SRAM rw [76, 76] 1 0 Read or Write [0]:r; [1]:w; init_addr [75, 69] 7 0 Initial address init_delay [68, 65] 4 0 initial delay l1_iter [64, 58] 7 0 level-1 iteration - 1. l1_step [57, 50] 8 1 level-1 step l1_delay [49, 44] 6 0 level-1 delay l2_iter [43, 37] 7 0 level-2 iteration - 1. l2_step [36, 29] 8 1 level-2 step l2_delay [28, 23] 6 0 level-2 delay init_addr_sd [22, 22] 1 0 Is initial address static or dynamic? [0]:s; [1]:d; l1_iter_sd [21, 21] 1 0 Is level-1 iteration static or dynamic? [0]:s; [1]:d; l2_iter_sd [20, 20] 1 0 Is level-2 iteration static or dynamic? [0]:s; [1]:d; init_delay_sd [19, 19] 1 0 Is initial delay static or dynamic? [0]:s; [1]:d; l1_delay_sd [18, 18] 1 0 Is level-1 delay static or dynamic? [0]:s; [1]:d; l2_delay_sd [17, 17] 1 0 Is level-2 delay static or dynamic? [0]:s; [1]:d; l1_step_sd [16, 16] 1 0 Is level-1 step static or dynamic? [0]:s; [1]:d; l2_step_sd [15, 15] 1 0 Is level-2 step static or dynamic? [0]:s; [1]:d; hops [14, 11] 4 0 Number of hops to reach the DiMArch cell - 1","title":"SRAM"},{"location":"Guideline/Mkdocs-tutorial/","text":"MkDocs Tutorial This tutorial will teach you how to use MkDocs to edit SiLagoDoc. What is MkDocs? MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs is based on python . The SiLagoDoc uses python 3 . How to install MkDocs? Like all python packages, you can install MkDocs and its theme via pip . pip install mkdocs mkdocs-material How to use MkDocs? Clone SiLagoDoc repo Use the following command: git clone git@github.com:silagokth/SiLagoDoc.git Check the modification Note The render result is just on your local machine. It hasn't been commited to the server yet. Use the the follwing command: cd SiLagoDoc mkdocs serve Now you can view the SiLagoDoc on your browser via the url: http://127.0.0.1:8000 . The site will be automatically refreshed when you save your changes. Automatically deploy the site By simply commit your change to the repository, the site will be automatically updated. It might take several minutes. Manually Build and deploy the site Warning SiLagoDoc has been configured with continous integration. You should not use this step to manually deploy the site. You should instead directly commit your source code to github and let it automatically generate the site. Once you are satisfied with the modification, you can build the site using the command: mkdocs build You will notice that a folder called site has been created. This site can then be deployed to the server. SiLagoDoc uses github pages to host the site. So you can use the following command to deploy: mkdocs gh-deploy How to write documentation? Add a page You can add a documentation page in /docs . Some files already exist under the directory. There are three folders: /docs/About , /docs/Guideline , and /docs/Docs . Choose the correct folder to add your page. The documentation page uses Markdown format. The page file should have appendix of \".md\". Once a page is added, you should also update the configuration file to make it available on the navagation bar. The configuation file is: /mkdocs.yaml . Edit a page You can edit a page and commit the change to github repo. Please see Markdown syntax . You can also directly edit a page through the website. Each page has a pencil icon on the top-right corner. You can click the icon, and you shall be directed to the github source code editing interface. You can just edit the file and save the change. Since SiLagoDoc has the continuous integration, your change will be automatically build and deploy to the website. It might take several minuts to refresh the site. Delete a page Just remove the Markdown file and remove the corresponding entry in /mkdocs.yaml . Theme and advanced features SiLagoDoc uses material theme for MkDocs. Besides the looks, the material theme also provides some extra features. The complete list of supported extensions can be found Here .","title":"MkDocs Tutorial"},{"location":"Guideline/Mkdocs-tutorial/#mkdocs-tutorial","text":"This tutorial will teach you how to use MkDocs to edit SiLagoDoc.","title":"MkDocs Tutorial"},{"location":"Guideline/Mkdocs-tutorial/#what-is-mkdocs","text":"MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. MkDocs is based on python . The SiLagoDoc uses python 3 .","title":"What is MkDocs?"},{"location":"Guideline/Mkdocs-tutorial/#how-to-install-mkdocs","text":"Like all python packages, you can install MkDocs and its theme via pip . pip install mkdocs mkdocs-material","title":"How to install MkDocs?"},{"location":"Guideline/Mkdocs-tutorial/#how-to-use-mkdocs","text":"","title":"How to use MkDocs?"},{"location":"Guideline/Mkdocs-tutorial/#clone-silagodoc-repo","text":"Use the following command: git clone git@github.com:silagokth/SiLagoDoc.git","title":"Clone SiLagoDoc repo"},{"location":"Guideline/Mkdocs-tutorial/#check-the-modification","text":"Note The render result is just on your local machine. It hasn't been commited to the server yet. Use the the follwing command: cd SiLagoDoc mkdocs serve Now you can view the SiLagoDoc on your browser via the url: http://127.0.0.1:8000 . The site will be automatically refreshed when you save your changes.","title":"Check the modification"},{"location":"Guideline/Mkdocs-tutorial/#automatically-deploy-the-site","text":"By simply commit your change to the repository, the site will be automatically updated. It might take several minutes.","title":"Automatically deploy the site"},{"location":"Guideline/Mkdocs-tutorial/#manually-build-and-deploy-the-site","text":"Warning SiLagoDoc has been configured with continous integration. You should not use this step to manually deploy the site. You should instead directly commit your source code to github and let it automatically generate the site. Once you are satisfied with the modification, you can build the site using the command: mkdocs build You will notice that a folder called site has been created. This site can then be deployed to the server. SiLagoDoc uses github pages to host the site. So you can use the following command to deploy: mkdocs gh-deploy","title":"Manually Build and deploy the site"},{"location":"Guideline/Mkdocs-tutorial/#how-to-write-documentation","text":"","title":"How to write documentation?"},{"location":"Guideline/Mkdocs-tutorial/#add-a-page","text":"You can add a documentation page in /docs . Some files already exist under the directory. There are three folders: /docs/About , /docs/Guideline , and /docs/Docs . Choose the correct folder to add your page. The documentation page uses Markdown format. The page file should have appendix of \".md\". Once a page is added, you should also update the configuration file to make it available on the navagation bar. The configuation file is: /mkdocs.yaml .","title":"Add a page"},{"location":"Guideline/Mkdocs-tutorial/#edit-a-page","text":"You can edit a page and commit the change to github repo. Please see Markdown syntax . You can also directly edit a page through the website. Each page has a pencil icon on the top-right corner. You can click the icon, and you shall be directed to the github source code editing interface. You can just edit the file and save the change. Since SiLagoDoc has the continuous integration, your change will be automatically build and deploy to the website. It might take several minuts to refresh the site.","title":"Edit a page"},{"location":"Guideline/Mkdocs-tutorial/#delete-a-page","text":"Just remove the Markdown file and remove the corresponding entry in /mkdocs.yaml .","title":"Delete a page"},{"location":"Guideline/Mkdocs-tutorial/#theme-and-advanced-features","text":"SiLagoDoc uses material theme for MkDocs. Besides the looks, the material theme also provides some extra features. The complete list of supported extensions can be found Here .","title":"Theme and advanced features"},{"location":"Guideline/Style-guide-cpp/","text":"C++ Style Guide Basics In general, all C++ code should follow the LLVM Style . The preferred editor for C++ program is Visual Studio Code . It works on all major operating systems. Package Organization The package should be organized in the following way: ROOT_DIR/ +--README.md +--LICENSE.md +--CMakeLists.txt +--config/ +--[some files] +--src/ +--[some files] +--test/ +--[some files] +--build/ +--[some files] Naming Convention Each class Foo is defined by a header file Foo.hpp and a source file Foo.cpp . Class name will uses capital letters to disdinguish each words. For example, FooBar is a valid class name. Example class FooBar { ... }; Each header file will have a gardian macro. The gardian marcro will be the logic path of the header file. The macro should be in upper case letters and seperated by underscore symbol ( _ ). It should also begin and end with double underscore symbols ( __ ). Example #ifndef __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ #define __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ ... #endif // __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ One should use hierarchical namespaces if required. There is no limitation on the level of namespace nor the amount of namespaces in each level. Name space should be all lower case letters. When enclose a piece of code with hierarchical namespaces, write them in seperate bracks. Note You shouldn't put indentation space for namespaces. Example namespace foo { namespace bar { ... } } Macro names in general should be in all upper case letters and seperated by underscore symbol. Example #define MACRO_ONE 1 #define MACRO_TWO 2 Function names in general should be in all lower case letters and seperated by underscore symbol. Example int FooBar::foo_bar (){ ... } Variable names should be in all lower case letters and seperated by underscore symbol. If the variable is a private or protected variable in a class, it should also start with an underscore symbol. Public variables should not start with underscore symbol. If the variable is the input argument of a function, it should also end with an underscore symbol. Example class FooBar { private : int _var_1 ; public : float var_2 ; public : void func_1 ( int arg_1_ , int arg_2_ ); }; There is no rule to name temporary variables. As long as the variable name does not confuse readers, it can be accepted. However, there are some tradition of naming temporary variables one should follow. For example, i , j , k are usually reserved for loop iterators. Example int func_1 (){ int a ; for ( int i = 0 ; i < 5 ; i ++ ){ int b = 2 ; int a = a + i ; } return a ; }","title":"C++ Style Guide"},{"location":"Guideline/Style-guide-cpp/#c-style-guide","text":"","title":"C++ Style Guide"},{"location":"Guideline/Style-guide-cpp/#basics","text":"In general, all C++ code should follow the LLVM Style . The preferred editor for C++ program is Visual Studio Code . It works on all major operating systems.","title":"Basics"},{"location":"Guideline/Style-guide-cpp/#package-organization","text":"The package should be organized in the following way: ROOT_DIR/ +--README.md +--LICENSE.md +--CMakeLists.txt +--config/ +--[some files] +--src/ +--[some files] +--test/ +--[some files] +--build/ +--[some files]","title":"Package Organization"},{"location":"Guideline/Style-guide-cpp/#naming-convention","text":"Each class Foo is defined by a header file Foo.hpp and a source file Foo.cpp . Class name will uses capital letters to disdinguish each words. For example, FooBar is a valid class name. Example class FooBar { ... }; Each header file will have a gardian macro. The gardian marcro will be the logic path of the header file. The macro should be in upper case letters and seperated by underscore symbol ( _ ). It should also begin and end with double underscore symbols ( __ ). Example #ifndef __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ #define __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ ... #endif // __PRIMARY_NAMESPACE_SECONDARY_NAMESPACE_FOO_BAR_HPP__ One should use hierarchical namespaces if required. There is no limitation on the level of namespace nor the amount of namespaces in each level. Name space should be all lower case letters. When enclose a piece of code with hierarchical namespaces, write them in seperate bracks. Note You shouldn't put indentation space for namespaces. Example namespace foo { namespace bar { ... } } Macro names in general should be in all upper case letters and seperated by underscore symbol. Example #define MACRO_ONE 1 #define MACRO_TWO 2 Function names in general should be in all lower case letters and seperated by underscore symbol. Example int FooBar::foo_bar (){ ... } Variable names should be in all lower case letters and seperated by underscore symbol. If the variable is a private or protected variable in a class, it should also start with an underscore symbol. Public variables should not start with underscore symbol. If the variable is the input argument of a function, it should also end with an underscore symbol. Example class FooBar { private : int _var_1 ; public : float var_2 ; public : void func_1 ( int arg_1_ , int arg_2_ ); }; There is no rule to name temporary variables. As long as the variable name does not confuse readers, it can be accepted. However, there are some tradition of naming temporary variables one should follow. For example, i , j , k are usually reserved for loop iterators. Example int func_1 (){ int a ; for ( int i = 0 ; i < 5 ; i ++ ){ int b = 2 ; int a = a + i ; } return a ; }","title":"Naming Convention"},{"location":"Guideline/Style-guide-rtl/","text":"Coding Guidelines for RTL and VHDL coding File Header Each file in the SiLago project has to contain a header that includes the copyright, license, author and change log information. The header should have the following form: ------------------------------------------------------- --! @file <name of the file> --! @brief <Brief description of the file> --! @details <Detail description of the file (optional)> --! @author <Author\u2019s Name> --! @version <Version> --! @date <Date of last edit> --! @bug <Known Bugs (\u201cNONE\u201d if there are no bugs)> --! @todo <Todo, create one \u201c--! @todo\u201d for every todo> --! @copyright GNU Public License [GPL-3.0]. ------------------------------------------------------- ---------------- Copyright (c) notice ----------------------------------------- -- -- The VHDL code, the logic and concepts described in this file constitute -- the intellectual property of the authors listed below, who are affiliated -- to KTH(Kungliga Tekniska H\u00f6gskolan), School of EECS, Kista. -- Any unauthorised use, copy or distribution is strictly prohibited. -- Any authorised use, copy or distribution should carry this copyright notice -- unaltered. ------------------------------------------------------------------------------- -- Title : <Title of the Entity or Package> -- Project : <Project that file belongs to (e.g. SiLago, eBrain, etc)> ------------------------------------------------------------------------------- -- File : <name of the file> -- Library : <Name of the library that this file should be compiled in> -- Author : <Author\u2019s Name> -- Company : KTH -- Created : <Date of creation> -- Last update: <Date of last edit> -- Platform : SiLago -- Standard : VHDL'08 ------------------------------------------------------------------------------- -- Copyright (c) <year of creation> ------------------------------------------------------------------------------- -- Contact : <Main contact person eg. Dimitrios Stathis <stathis@kth.se>> ------------------------------------------------------------------------------- -- Revisions : -- Date Version Author Description -- 2020-12-07 1.0 <Authors Name> <description> ------------------------------------------------------------------------------- --~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# -- # --This file is part of SiLago. # -- # -- SiLago platform source code is distributed freely: you can # -- redistribute it and/or modify it under the terms of the GNU # -- General Public License as published by the Free Software Foundation, # -- either version 3 of the License, or (at your option) any # -- later version. # -- # -- SiLago is distributed in the hope that it will be useful, # -- but WITHOUT ANY WARRANTY; without even the implied warranty of # -- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # -- GNU General Public License for more details. # -- # -- You should have received a copy of the GNU General Public License # -- along with SiLago. If not, see <https://www.gnu.org/licenses/>. # -- # --~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# VSCODE Snippet This is the snippet code for vs-code. You can modify the code and add it as a snippet in your favorite editor. \"vhdl_notice\": { \"scope\": \"vhdl\", \"prefix\": \"note\", \"body\": [ \"-------------------------------------------------------\", \"--! @file $TM_FILENAME\", \"--! @brief ${1:UnitX}\", \"--! @details \", \"--! @author ${3:Dimitrios Stathis}\", \"--! @version 1.0\", \"--! @date $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"--! @bug NONE\", \"--! @todo NONE\", \"--! @copyright GNU Public License [GPL-3.0].\", \"-------------------------------------------------------\", \"---------------- Copyright (c) notice -----------------------------------------\", \"--\", \"-- The VHDL code, the logic and concepts described in this file constitute\", \"-- the intellectual property of the authors listed below, who are affiliated\", \"-- to KTH(Kungliga Tekniska H\u00f6gskolan), School of EECS, Kista.\", \"-- Any unauthorised use, copy or distribution is strictly prohibited.\", \"-- Any authorised use, copy or distribution should carry this copyright notice\", \"-- unaltered.\", \"-------------------------------------------------------------------------------\", \"-- Title : ${1:UnitX}\", \"-- Project : ${2:SiLago}\", \"-------------------------------------------------------------------------------\", \"-- File : $TM_FILENAME\", \"-- Library : ${4:work}$\" \"-- Author : ${3:Dimitrios Stathis}\", \"-- Company : KTH\", \"-- Created : $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"-- Last update: $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"-- Platform : ${2:SiLago}\", \"-- Standard : VHDL'08\", \"-------------------------------------------------------------------------------\", \"-- Copyright (c) $CURRENT_YEAR\", \"-------------------------------------------------------------------------------\", \"-- Contact : ${3:Dimitrios Stathis} ${4:<stathis@kth.se>}\", \"-------------------------------------------------------------------------------\", \"-- Revisions :\", \"-- Date Version Author Description\", \"-- $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE 1.0 ${3:Dimitrios Stathis} Created\", \"-------------------------------------------------------------------------------\", \"\", \"--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\", \"-- #\", \"--This file is part of ${2:SiLago}. #\", \"-- #\", \"-- ${2:SiLago} platform source code is distributed freely: you can #\", \"-- redistribute it and/or modify it under the terms of the GNU #\", \"-- General Public License as published by the Free Software Foundation, #\", \"-- either version 3 of the License, or (at your option) any #\", \"-- later version. #\", \"-- #\", \"-- ${2:SiLago} is distributed in the hope that it will be useful, #\", \"-- but WITHOUT ANY WARRANTY; without even the implied warranty of #\", \"-- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the #\", \"-- GNU General Public License for more details. #\", \"-- #\", \"-- You should have received a copy of the GNU General Public License #\", \"-- along with ${2:SiLago}. If not, see <https://www.gnu.org/licenses/>. #\", \"-- #\", \"--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\", Style and Formatting Tabs and indentation : Each indentation and tab should be 2 spaces. Remember to change the settings of your editor so that it adds 2 space characters when pressing tab, and not a \u2018tab\u2019 character. Keywords : All VHDL keywords, such as SIGNAL, VARIABLE, etc., should be capitalized. =, <=, =>, :, and := : All VHDL operands should be aligned as best as possible. Constant\u2019s name : The names of all constants should be capitalized. Signal\u2019s & variable\u2019s name : A Signal/Variable\u2019s name should be low-case. The name should be descriptive and multiple words should be separated with \u2018_\u2019. Type\u2019s name : A type or subtype name should be in low-case letters and end with the suffix _ty. For example conf_ty. Special suffix for signal names : When a signal is active on a negative level (for example a negative triggered reset) use the suffix _n. For example rst_n. Entity\u2019s name : The name of the entity should be the same as the name of the file and low-case. Architecture\u2019s name : The name of the architecture should be the name of the entity with the suffix \u2018_BEH\u2019, \u2018_STR\u2019 for behavioral or structural style. ENTITY : When defying an entity the GENERIC and PORT should always start in a new line. The declaration of the signals and generics should also start in a new line. For example: ENTITY <NAME> IS GENERIC ( width : NATURAL := 8 --! Input width (N) ); PORT ( in_a : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); in_b : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); conf : IN STD_LOGIC; out : OUT STD_LOGIC_VECTOR(2 * width - 1 DOWNTO 0) ); IF - THEN \u2026 ELSE \u2026 END : IF - THEN \u2026 ELSE statements should always start in a new line and comments should be added in the previous line, before the condition. Always leave an empty line before and after the code block for readability. For example: -- This if statement checks condition A, if True it does code A IF condition A THEN Code A -- IF condition B is true it does code B ELSIF condition B THEN Code B -- In other case do code other ELSE Code other END; CASE, FOR, etc. : Use the same guide as IF. WHEN \u2026 ELSE : When using WHEN \u2026 ELSE there should be a new line after the ELSE. For example: -- Description comment <signal> <= '1' WHEN <condition> ELSE '0'; IF/FOR \u2026 GENERATE : Generate statements should always have a descriptive name. PORT MAPS : When instantiating a component, the GENERIC/PORT MAP should always start in a new line and the port/generic connection should also start in a new line. The component should always have a descriptive name starting with U_. Also, it is recommended to instantiate using ENTITY instead of COMPONENT. Before the installation there should be a comment to describe the component. For example: --! This component is doing something DUT : ENTITY work.conf_mul_Beh GENERIC MAP( width => bit_width ) PORT MAP( in_a => STD_LOGIC_VECTOR(inst_a), in_b => STD_LOGIC_VECTOR(inst_b), conf => conf, prod => prod ); ASSERTIONS : ASSERT, REPORT and SEVERITY should always start in a new line. There should be a maximum of 1 empty line between code segments and comments should be directly above or next to the code that they comment. Coding style Each entity should implement a specific function of the design. It is not recommended to have large entities that implement complex functions. We recommend that when describing a complex function, you use one entity for each FSM of the design and a separate entity for each register files, data computation, etc. Libraries For all VHDL files always use numeric_std library and do not use std_logic_arith , std_logic_signed , or std_logic_unsigned . Clocking Always use the rising_edge or falling_edge for checking the clock edge and not clk=\u20191\u2019 and clk\u2019event . FSM description When describing in VHDL it is recommended that you use a two-process design. In the two process design each ARCHITECTURE has two processes. The first process is a clocked process and registers the state of the FSM and any other signal that is required. The second process is combinatorial, and it is used to describe the FSM, using a CASE statement. When writing the combinatorial process the designer needs to be careful to include all the required signals in the sensitivity list and make sure that no latches are generated. While debugging, the ALL keyword can be used in the sensitivity list to make sure that the behavior of the process is correct. To avoid any latches, all signals that are edited inside the combinatorial process should be assigned a default value in the beginning of the process (before the case statement). Alternatively, a single process design can be used. In a single process design, only one process is required in the entity. The process is clocked and it both describes the FSM and registers its state. The single process design should be used with care since it can only describe registered FSMs (i.e. the outputs of the FSM are always registered). COMMENTING AND DOCUMENTATION Commenting in RTL is important for you as a designer, and for the people taking over your code. It is important to remember that RTL is not programming, when you code in RTL you describe something real. So you should add descriptions before your entities or modules and your architecture that describe what exactly your entity, module or architecture is meant to implement. If you can not describe it in words, then you can not implement it. In the following examples we follow the Doxygen commenting style, but this is not necessary. Entities Each entity should have a brief and possible a detail description. The brief description should explain the basic function of the component. The detail description should describe its interface, such as special relation between signals, and a more detail view of its functionality. For example: --! This is a reconfigurable multiplier. It can operate in different fixed point precision. --! The input of the multiplier is a N-bit bit stream. The stream can be treated as a N-bit signed --! number, two N/2-bit signed numbers, or four N/4-bit signed numbers. The output is a 2N-bit bit stream. --! The output is splitted in one, two, or four, depending on the configuration. ENTITY conf_mul_Beh IS GENERIC ( width : NATURAL := 8 --! Input width (N) ); PORT ( in_a : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); --! Input A, N-bit in_b : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); --! Input B, N-bit conf : IN STD_LOGIC; --! Configuration bits, define prod : OUT STD_LOGIC_VECTOR(2 * width - 1 DOWNTO 0) --! Product output, 2N-bit ); END ENTITY conf_mul_Beh; IN/OUT/SIGNALS/VARIABLES/GENERICS All signals, variables, generics, etc. should include a description comment after its definition, see the code above. Architectures All architectures should have possible a brief and mandatory a detail description. The descriptions should describe the architectural details of the implementation, for example if it is a one or two process design etc. For example: --! @brief This is the architecture of a reconfigurable multiplier (16-bit) --! @details In this version we are using a shift and ADD architecture instead of the --! conventional array multiplier, the multiplication is decomposed in to 4 smaller --! multipliers. The products of the smaller multiplication are shifted and then added --! to generate the final result. A sign extension is used to switch between the two modes ARCHITECTURE rtl OF conf_mul_Beh IS CONSTANT width2 : NATURAL := divUp(width, 2); --! Constant value for Width/2 SIGNAL temp_a1 : signed(width2 - 1 DOWNTO 0); --! MSBs of A SIGNAL temp_a0 : signed(width2 DOWNTO 0); --! LSBs of A BEGIN Processes Complex processes should have a description of what they are trying to implement --! This process checks if the loop should be executed (i.e. if number of iterations >0 ) zero_loop : PROCESS (instr, config) BEGIN <CODE BLOCK> END PROCESS zero_loop; Naming convention Keep the naming of your objects clear and descriptive. When multiple words are used in a name they should be seperated by _ . Avoid using names like north, south, east and west. Instead use names top, bottom, left and right. Variables, Signals and Constants All variables, signals and constnats should use clear and descriptive names. They should also have a comment describing what the do in their definition. Constants should use all capital letters, and variables and singals small letters. Entities, Files, Functions and Architectures Entities should have descriptive names, but simple and short. Each entity should be in one single file and followed by its architecture. The file name should be the same as the entity. The architecture name should be descriptive of the style, for example behavioral or structural. Functions should have clear descriptive names, it is ok if they are long. OTHER USEFULL TOOLS/PLUGINS VSCODE: VHDL specific https://marketplace.visualstudio.com/items?itemName=rjyoung.vscode-modern-vhdl-support : Highlight, Snippets and some autocompletion. https://marketplace.visualstudio.com/items?itemName=Vinrobot.vhdl-formatter : VHDL formatter Language servers: https://marketplace.visualstudio.com/items?itemName=hbohlin.vhdl-ls : Good but it has some small issues. https://marketplace.visualstudio.com/items?itemName=vhdl-tool.vhdl-tool : Good and multiplatform, free as of now (2023) https://marketplace.visualstudio.com/items?itemName=ViDE-Software.v4pvhdlforprofessionals : Extremely good, it requires a license. Does not work with modern-VHDL plugin. Productivity plugins https://marketplace.visualstudio.com/items?itemName=dkundel.vscode-new-file : Advance functions for creating new files. https://marketplace.visualstudio.com/items?itemName=bladnman.auto-align : Auto align https://marketplace.visualstudio.com/items?itemName=oderwat.indent-rainbow : Colors the indentation. https://marketplace.visualstudio.com/items?itemName=adammaras.overtype : Enables overtype using INS button. https://marketplace.visualstudio.com/items?itemName=2gua.rainbow-brackets : Colors the brackets https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker : Spell checker for your code and comments Shortcut keys and emulation https://marketplace.visualstudio.com/items?itemName=hiro-sun.vscode-emacs : Emacs keymap https://marketplace.visualstudio.com/items?itemName=vscodevim.vim : Vim emulator","title":"Coding Guidelines for RTL and VHDL coding"},{"location":"Guideline/Style-guide-rtl/#coding-guidelines-for-rtl-and-vhdl-coding","text":"","title":"Coding Guidelines for RTL and VHDL coding"},{"location":"Guideline/Style-guide-rtl/#file-header","text":"Each file in the SiLago project has to contain a header that includes the copyright, license, author and change log information. The header should have the following form: ------------------------------------------------------- --! @file <name of the file> --! @brief <Brief description of the file> --! @details <Detail description of the file (optional)> --! @author <Author\u2019s Name> --! @version <Version> --! @date <Date of last edit> --! @bug <Known Bugs (\u201cNONE\u201d if there are no bugs)> --! @todo <Todo, create one \u201c--! @todo\u201d for every todo> --! @copyright GNU Public License [GPL-3.0]. ------------------------------------------------------- ---------------- Copyright (c) notice ----------------------------------------- -- -- The VHDL code, the logic and concepts described in this file constitute -- the intellectual property of the authors listed below, who are affiliated -- to KTH(Kungliga Tekniska H\u00f6gskolan), School of EECS, Kista. -- Any unauthorised use, copy or distribution is strictly prohibited. -- Any authorised use, copy or distribution should carry this copyright notice -- unaltered. ------------------------------------------------------------------------------- -- Title : <Title of the Entity or Package> -- Project : <Project that file belongs to (e.g. SiLago, eBrain, etc)> ------------------------------------------------------------------------------- -- File : <name of the file> -- Library : <Name of the library that this file should be compiled in> -- Author : <Author\u2019s Name> -- Company : KTH -- Created : <Date of creation> -- Last update: <Date of last edit> -- Platform : SiLago -- Standard : VHDL'08 ------------------------------------------------------------------------------- -- Copyright (c) <year of creation> ------------------------------------------------------------------------------- -- Contact : <Main contact person eg. Dimitrios Stathis <stathis@kth.se>> ------------------------------------------------------------------------------- -- Revisions : -- Date Version Author Description -- 2020-12-07 1.0 <Authors Name> <description> ------------------------------------------------------------------------------- --~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# -- # --This file is part of SiLago. # -- # -- SiLago platform source code is distributed freely: you can # -- redistribute it and/or modify it under the terms of the GNU # -- General Public License as published by the Free Software Foundation, # -- either version 3 of the License, or (at your option) any # -- later version. # -- # -- SiLago is distributed in the hope that it will be useful, # -- but WITHOUT ANY WARRANTY; without even the implied warranty of # -- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # -- GNU General Public License for more details. # -- # -- You should have received a copy of the GNU General Public License # -- along with SiLago. If not, see <https://www.gnu.org/licenses/>. # -- # --~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#","title":"File Header"},{"location":"Guideline/Style-guide-rtl/#vscode-snippet","text":"This is the snippet code for vs-code. You can modify the code and add it as a snippet in your favorite editor. \"vhdl_notice\": { \"scope\": \"vhdl\", \"prefix\": \"note\", \"body\": [ \"-------------------------------------------------------\", \"--! @file $TM_FILENAME\", \"--! @brief ${1:UnitX}\", \"--! @details \", \"--! @author ${3:Dimitrios Stathis}\", \"--! @version 1.0\", \"--! @date $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"--! @bug NONE\", \"--! @todo NONE\", \"--! @copyright GNU Public License [GPL-3.0].\", \"-------------------------------------------------------\", \"---------------- Copyright (c) notice -----------------------------------------\", \"--\", \"-- The VHDL code, the logic and concepts described in this file constitute\", \"-- the intellectual property of the authors listed below, who are affiliated\", \"-- to KTH(Kungliga Tekniska H\u00f6gskolan), School of EECS, Kista.\", \"-- Any unauthorised use, copy or distribution is strictly prohibited.\", \"-- Any authorised use, copy or distribution should carry this copyright notice\", \"-- unaltered.\", \"-------------------------------------------------------------------------------\", \"-- Title : ${1:UnitX}\", \"-- Project : ${2:SiLago}\", \"-------------------------------------------------------------------------------\", \"-- File : $TM_FILENAME\", \"-- Library : ${4:work}$\" \"-- Author : ${3:Dimitrios Stathis}\", \"-- Company : KTH\", \"-- Created : $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"-- Last update: $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE\", \"-- Platform : ${2:SiLago}\", \"-- Standard : VHDL'08\", \"-------------------------------------------------------------------------------\", \"-- Copyright (c) $CURRENT_YEAR\", \"-------------------------------------------------------------------------------\", \"-- Contact : ${3:Dimitrios Stathis} ${4:<stathis@kth.se>}\", \"-------------------------------------------------------------------------------\", \"-- Revisions :\", \"-- Date Version Author Description\", \"-- $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DATE 1.0 ${3:Dimitrios Stathis} Created\", \"-------------------------------------------------------------------------------\", \"\", \"--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\", \"-- #\", \"--This file is part of ${2:SiLago}. #\", \"-- #\", \"-- ${2:SiLago} platform source code is distributed freely: you can #\", \"-- redistribute it and/or modify it under the terms of the GNU #\", \"-- General Public License as published by the Free Software Foundation, #\", \"-- either version 3 of the License, or (at your option) any #\", \"-- later version. #\", \"-- #\", \"-- ${2:SiLago} is distributed in the hope that it will be useful, #\", \"-- but WITHOUT ANY WARRANTY; without even the implied warranty of #\", \"-- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the #\", \"-- GNU General Public License for more details. #\", \"-- #\", \"-- You should have received a copy of the GNU General Public License #\", \"-- along with ${2:SiLago}. If not, see <https://www.gnu.org/licenses/>. #\", \"-- #\", \"--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\",","title":"VSCODE Snippet"},{"location":"Guideline/Style-guide-rtl/#style-and-formatting","text":"Tabs and indentation : Each indentation and tab should be 2 spaces. Remember to change the settings of your editor so that it adds 2 space characters when pressing tab, and not a \u2018tab\u2019 character. Keywords : All VHDL keywords, such as SIGNAL, VARIABLE, etc., should be capitalized. =, <=, =>, :, and := : All VHDL operands should be aligned as best as possible. Constant\u2019s name : The names of all constants should be capitalized. Signal\u2019s & variable\u2019s name : A Signal/Variable\u2019s name should be low-case. The name should be descriptive and multiple words should be separated with \u2018_\u2019. Type\u2019s name : A type or subtype name should be in low-case letters and end with the suffix _ty. For example conf_ty. Special suffix for signal names : When a signal is active on a negative level (for example a negative triggered reset) use the suffix _n. For example rst_n. Entity\u2019s name : The name of the entity should be the same as the name of the file and low-case. Architecture\u2019s name : The name of the architecture should be the name of the entity with the suffix \u2018_BEH\u2019, \u2018_STR\u2019 for behavioral or structural style. ENTITY : When defying an entity the GENERIC and PORT should always start in a new line. The declaration of the signals and generics should also start in a new line. For example: ENTITY <NAME> IS GENERIC ( width : NATURAL := 8 --! Input width (N) ); PORT ( in_a : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); in_b : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); conf : IN STD_LOGIC; out : OUT STD_LOGIC_VECTOR(2 * width - 1 DOWNTO 0) ); IF - THEN \u2026 ELSE \u2026 END : IF - THEN \u2026 ELSE statements should always start in a new line and comments should be added in the previous line, before the condition. Always leave an empty line before and after the code block for readability. For example: -- This if statement checks condition A, if True it does code A IF condition A THEN Code A -- IF condition B is true it does code B ELSIF condition B THEN Code B -- In other case do code other ELSE Code other END; CASE, FOR, etc. : Use the same guide as IF. WHEN \u2026 ELSE : When using WHEN \u2026 ELSE there should be a new line after the ELSE. For example: -- Description comment <signal> <= '1' WHEN <condition> ELSE '0'; IF/FOR \u2026 GENERATE : Generate statements should always have a descriptive name. PORT MAPS : When instantiating a component, the GENERIC/PORT MAP should always start in a new line and the port/generic connection should also start in a new line. The component should always have a descriptive name starting with U_. Also, it is recommended to instantiate using ENTITY instead of COMPONENT. Before the installation there should be a comment to describe the component. For example: --! This component is doing something DUT : ENTITY work.conf_mul_Beh GENERIC MAP( width => bit_width ) PORT MAP( in_a => STD_LOGIC_VECTOR(inst_a), in_b => STD_LOGIC_VECTOR(inst_b), conf => conf, prod => prod ); ASSERTIONS : ASSERT, REPORT and SEVERITY should always start in a new line. There should be a maximum of 1 empty line between code segments and comments should be directly above or next to the code that they comment.","title":"Style and Formatting"},{"location":"Guideline/Style-guide-rtl/#coding-style","text":"Each entity should implement a specific function of the design. It is not recommended to have large entities that implement complex functions. We recommend that when describing a complex function, you use one entity for each FSM of the design and a separate entity for each register files, data computation, etc.","title":"Coding style"},{"location":"Guideline/Style-guide-rtl/#libraries","text":"For all VHDL files always use numeric_std library and do not use std_logic_arith , std_logic_signed , or std_logic_unsigned .","title":"Libraries"},{"location":"Guideline/Style-guide-rtl/#clocking","text":"Always use the rising_edge or falling_edge for checking the clock edge and not clk=\u20191\u2019 and clk\u2019event .","title":"Clocking"},{"location":"Guideline/Style-guide-rtl/#fsm-description","text":"When describing in VHDL it is recommended that you use a two-process design. In the two process design each ARCHITECTURE has two processes. The first process is a clocked process and registers the state of the FSM and any other signal that is required. The second process is combinatorial, and it is used to describe the FSM, using a CASE statement. When writing the combinatorial process the designer needs to be careful to include all the required signals in the sensitivity list and make sure that no latches are generated. While debugging, the ALL keyword can be used in the sensitivity list to make sure that the behavior of the process is correct. To avoid any latches, all signals that are edited inside the combinatorial process should be assigned a default value in the beginning of the process (before the case statement). Alternatively, a single process design can be used. In a single process design, only one process is required in the entity. The process is clocked and it both describes the FSM and registers its state. The single process design should be used with care since it can only describe registered FSMs (i.e. the outputs of the FSM are always registered).","title":"FSM description"},{"location":"Guideline/Style-guide-rtl/#commenting-and-documentation","text":"Commenting in RTL is important for you as a designer, and for the people taking over your code. It is important to remember that RTL is not programming, when you code in RTL you describe something real. So you should add descriptions before your entities or modules and your architecture that describe what exactly your entity, module or architecture is meant to implement. If you can not describe it in words, then you can not implement it. In the following examples we follow the Doxygen commenting style, but this is not necessary.","title":"COMMENTING AND DOCUMENTATION"},{"location":"Guideline/Style-guide-rtl/#entities","text":"Each entity should have a brief and possible a detail description. The brief description should explain the basic function of the component. The detail description should describe its interface, such as special relation between signals, and a more detail view of its functionality. For example: --! This is a reconfigurable multiplier. It can operate in different fixed point precision. --! The input of the multiplier is a N-bit bit stream. The stream can be treated as a N-bit signed --! number, two N/2-bit signed numbers, or four N/4-bit signed numbers. The output is a 2N-bit bit stream. --! The output is splitted in one, two, or four, depending on the configuration. ENTITY conf_mul_Beh IS GENERIC ( width : NATURAL := 8 --! Input width (N) ); PORT ( in_a : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); --! Input A, N-bit in_b : IN STD_LOGIC_VECTOR(width - 1 DOWNTO 0); --! Input B, N-bit conf : IN STD_LOGIC; --! Configuration bits, define prod : OUT STD_LOGIC_VECTOR(2 * width - 1 DOWNTO 0) --! Product output, 2N-bit ); END ENTITY conf_mul_Beh;","title":"Entities"},{"location":"Guideline/Style-guide-rtl/#inoutsignalsvariablesgenerics","text":"All signals, variables, generics, etc. should include a description comment after its definition, see the code above.","title":"IN/OUT/SIGNALS/VARIABLES/GENERICS"},{"location":"Guideline/Style-guide-rtl/#architectures","text":"All architectures should have possible a brief and mandatory a detail description. The descriptions should describe the architectural details of the implementation, for example if it is a one or two process design etc. For example: --! @brief This is the architecture of a reconfigurable multiplier (16-bit) --! @details In this version we are using a shift and ADD architecture instead of the --! conventional array multiplier, the multiplication is decomposed in to 4 smaller --! multipliers. The products of the smaller multiplication are shifted and then added --! to generate the final result. A sign extension is used to switch between the two modes ARCHITECTURE rtl OF conf_mul_Beh IS CONSTANT width2 : NATURAL := divUp(width, 2); --! Constant value for Width/2 SIGNAL temp_a1 : signed(width2 - 1 DOWNTO 0); --! MSBs of A SIGNAL temp_a0 : signed(width2 DOWNTO 0); --! LSBs of A BEGIN","title":"Architectures"},{"location":"Guideline/Style-guide-rtl/#processes","text":"Complex processes should have a description of what they are trying to implement --! This process checks if the loop should be executed (i.e. if number of iterations >0 ) zero_loop : PROCESS (instr, config) BEGIN <CODE BLOCK> END PROCESS zero_loop;","title":"Processes"},{"location":"Guideline/Style-guide-rtl/#naming-convention","text":"Keep the naming of your objects clear and descriptive. When multiple words are used in a name they should be seperated by _ . Avoid using names like north, south, east and west. Instead use names top, bottom, left and right.","title":"Naming convention"},{"location":"Guideline/Style-guide-rtl/#variables-signals-and-constants","text":"All variables, signals and constnats should use clear and descriptive names. They should also have a comment describing what the do in their definition. Constants should use all capital letters, and variables and singals small letters.","title":"Variables, Signals and Constants"},{"location":"Guideline/Style-guide-rtl/#entities-files-functions-and-architectures","text":"Entities should have descriptive names, but simple and short. Each entity should be in one single file and followed by its architecture. The file name should be the same as the entity. The architecture name should be descriptive of the style, for example behavioral or structural. Functions should have clear descriptive names, it is ok if they are long.","title":"Entities, Files, Functions and Architectures"},{"location":"Guideline/Style-guide-rtl/#other-usefull-toolsplugins","text":"","title":"OTHER USEFULL TOOLS/PLUGINS"},{"location":"Guideline/Style-guide-rtl/#vscode","text":"","title":"VSCODE:"},{"location":"Guideline/Style-guide-rtl/#vhdl-specific","text":"https://marketplace.visualstudio.com/items?itemName=rjyoung.vscode-modern-vhdl-support : Highlight, Snippets and some autocompletion. https://marketplace.visualstudio.com/items?itemName=Vinrobot.vhdl-formatter : VHDL formatter","title":"VHDL specific"},{"location":"Guideline/Style-guide-rtl/#language-servers","text":"https://marketplace.visualstudio.com/items?itemName=hbohlin.vhdl-ls : Good but it has some small issues. https://marketplace.visualstudio.com/items?itemName=vhdl-tool.vhdl-tool : Good and multiplatform, free as of now (2023) https://marketplace.visualstudio.com/items?itemName=ViDE-Software.v4pvhdlforprofessionals : Extremely good, it requires a license. Does not work with modern-VHDL plugin.","title":"Language servers:"},{"location":"Guideline/Style-guide-rtl/#productivity-plugins","text":"https://marketplace.visualstudio.com/items?itemName=dkundel.vscode-new-file : Advance functions for creating new files. https://marketplace.visualstudio.com/items?itemName=bladnman.auto-align : Auto align https://marketplace.visualstudio.com/items?itemName=oderwat.indent-rainbow : Colors the indentation. https://marketplace.visualstudio.com/items?itemName=adammaras.overtype : Enables overtype using INS button. https://marketplace.visualstudio.com/items?itemName=2gua.rainbow-brackets : Colors the brackets https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker : Spell checker for your code and comments","title":"Productivity plugins"},{"location":"Guideline/Style-guide-rtl/#shortcut-keys-and-emulation","text":"https://marketplace.visualstudio.com/items?itemName=hiro-sun.vscode-emacs : Emacs keymap https://marketplace.visualstudio.com/items?itemName=vscodevim.vim : Vim emulator","title":"Shortcut keys and emulation"}]}